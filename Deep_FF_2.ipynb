{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be7433a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tarfile\n",
    "import urllib.request\n",
    "\n",
    "RES_PATH = os.path.join(\"res_datasets\",\"resourceing\")\n",
    "\n",
    "def fetch_resource_data(res_path=RES_PATH):\n",
    "    if not os.path.isdir(res_path):\n",
    "        os.makedirs(res_path)\n",
    "##创建文件夹路径函数\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def plot_learning_curves(model, X, y):\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    train_errors, val_errors = [], []\n",
    "    for m in range(1, len(X_train) + 1):\n",
    "        model.fit(X_train[:m], y_train[:m])\n",
    "        y_train_predict = model.predict(X_train[:m])\n",
    "        y_val_predict = model.predict(X_val)\n",
    "        train_errors.append(mean_squared_error(y_train[:m], y_train_predict))\n",
    "        val_errors.append(mean_squared_error(y_val, y_val_predict))\n",
    "\n",
    "    plt.plot(np.sqrt(train_errors), \"r-\", linewidth=2, label=\"train\")\n",
    "    plt.plot(np.sqrt(val_errors), \"b-\", linewidth=2, label=\"val\")\n",
    "    plt.legend(loc=\"upper right\", fontsize=14)   # not shown in the book\n",
    "    plt.xlabel(\"Training set size\", fontsize=14) # not shown\n",
    "    plt.ylabel(\"RMSE\", fontsize=14)              # not shown\n",
    "    \n",
    "fetch_resource_data() ##调用创建\n",
    "\n",
    "##读取CSV文件\n",
    "import pandas as pd\n",
    "\n",
    "def load_res_data(res_path = RES_PATH,file_name=\"new_feature_1214.csv\"):\n",
    "    csv_path = os.path.join(RES_PATH,file_name)\n",
    "    return pd.read_csv(csv_path) \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0bfef604",
   "metadata": {},
   "outputs": [],
   "source": [
    "##数据处理\n",
    "resource_origin_data = load_res_data()  #get origin csv data\n",
    "\n",
    "#%matplotlib inline\n",
    "#import matplotlib.pyplot as plt\n",
    "#resource_origin_data.hist(bins=50, figsize=(20,15))\n",
    "#plt.show() #data plot show\n",
    "\n",
    "resource_origin_data_lut = resource_origin_data.dropna(subset = [\"FF\"])\n",
    "resource_origin_data_lut=resource_origin_data_lut.drop(\"LUT\",axis=1)\n",
    "resource_origin_data_lut=resource_origin_data_lut.drop(\"BUFG\",axis=1)\n",
    "resource_origin_data_lut=resource_origin_data_lut.drop(\"IO\",axis=1)\n",
    "resource_origin_data_lut=resource_origin_data_lut.drop(\"ModuleName\",axis=1)\n",
    "resource_origin_data_lut=resource_origin_data_lut.drop(\"PARAMETERVALUE\",axis=1)\n",
    "resource_origin_data_lut=resource_origin_data_lut.drop(\"ModuleInsts\",axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25d04eab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 212 entries, 0 to 229\n",
      "Data columns (total 60 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   ARITLSHIFT                 212 non-null    int64  \n",
      " 1   ARITLSHIFT_PORT_NUM        212 non-null    int64  \n",
      " 2   ARITLSHIFT_PORT_WIDTH      212 non-null    int64  \n",
      " 3   ARITLSHIFT_VALUE           212 non-null    int64  \n",
      " 4   ARITRSHIFT                 212 non-null    int64  \n",
      " 5   ARITRSHIFT_PORT_NUM        212 non-null    int64  \n",
      " 6   ARITRSHIFT_PORT_WIDTH      212 non-null    int64  \n",
      " 7   ARITRSHIFT_VALUE           212 non-null    int64  \n",
      " 8   AlwaysConstructs           212 non-null    int64  \n",
      " 9   AssignLHSPortNum           212 non-null    int64  \n",
      " 10  AssignLHSWidth             212 non-null    int64  \n",
      " 11  AssignRHSPortNum           212 non-null    int64  \n",
      " 12  AssignRHSWidth             212 non-null    int64  \n",
      " 13  AssignStmts                212 non-null    int64  \n",
      " 14  BLOCKINGASSIGN             212 non-null    int64  \n",
      " 15  BlockAssign_Left_PortNum   212 non-null    int64  \n",
      " 16  BlockAssign_Left_Width     212 non-null    int64  \n",
      " 17  BlockAssign_Right_PortNum  212 non-null    int64  \n",
      " 18  BlockAssign_Right_Width    212 non-null    int64  \n",
      " 19  CASECONDITIONNUM           212 non-null    int64  \n",
      " 20  CASECONDITIONWIDTH         212 non-null    int64  \n",
      " 21  CASEITEMCONDITIONNUM       212 non-null    int64  \n",
      " 22  CASEITEMCONDITIOWIDTH      212 non-null    int64  \n",
      " 23  CASEITEMNUM                212 non-null    int64  \n",
      " 24  CONDITIONALELSE            212 non-null    int64  \n",
      " 25  CONDITIONALIF              212 non-null    int64  \n",
      " 26  CONDITIONALIFWIDTH         212 non-null    int64  \n",
      " 27  CONDITIONALTHEN            212 non-null    int64  \n",
      " 28  FORBLOCK                   212 non-null    int64  \n",
      " 29  FORTIMES                   212 non-null    int64  \n",
      " 30  FUNCTIONCALL               212 non-null    int64  \n",
      " 31  FUNCTIONNUM                212 non-null    int64  \n",
      " 32  INDEXMEMRORY               212 non-null    int64  \n",
      " 33  INOUT                      212 non-null    int64  \n",
      " 34  INOUTWIDTH                 212 non-null    int64  \n",
      " 35  INPUT                      212 non-null    int64  \n",
      " 36  INPUTWIDTH                 212 non-null    int64  \n",
      " 37  MIN                        212 non-null    int64  \n",
      " 38  NonBlockLeftWidth          212 non-null    int64  \n",
      " 39  NonBlockRightWidth         212 non-null    int64  \n",
      " 40  NonBlockingAssign          212 non-null    int64  \n",
      " 41  NonBlockingLeftPortNum     212 non-null    int64  \n",
      " 42  NonBlockingRightPortNum    212 non-null    int64  \n",
      " 43  OUTPUT                     212 non-null    int64  \n",
      " 44  OUTPUTWIDTH                212 non-null    int64  \n",
      " 45  PARAMETERNUM               212 non-null    int64  \n",
      " 46  PLUS                       212 non-null    int64  \n",
      " 47  QUESTIONCOLON              212 non-null    int64  \n",
      " 48  QUESTIONCOLONELSE          212 non-null    int64  \n",
      " 49  QUESTIONCOLONIF            212 non-null    int64  \n",
      " 50  QUESTIONCOLONTHEN          212 non-null    int64  \n",
      " 51  REDAND                     212 non-null    int64  \n",
      " 52  REDAOR                     212 non-null    int64  \n",
      " 53  REDXOR                     212 non-null    int64  \n",
      " 54  REG                        212 non-null    int64  \n",
      " 55  REGWIDTH                   212 non-null    int64  \n",
      " 56  UnaryOperator              212 non-null    int64  \n",
      " 57  WIRENUM                    212 non-null    int64  \n",
      " 58  WIREWIDTH                  212 non-null    int64  \n",
      " 59  FF                         212 non-null    float64\n",
      "dtypes: float64(1), int64(59)\n",
      "memory usage: 101.0 KB\n"
     ]
    }
   ],
   "source": [
    "#数据信息\n",
    "resource_origin_data_lut.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "81c08573",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ARITLSHIFT</th>\n",
       "      <th>ARITLSHIFT_PORT_NUM</th>\n",
       "      <th>ARITLSHIFT_PORT_WIDTH</th>\n",
       "      <th>ARITLSHIFT_VALUE</th>\n",
       "      <th>ARITRSHIFT</th>\n",
       "      <th>ARITRSHIFT_PORT_NUM</th>\n",
       "      <th>ARITRSHIFT_PORT_WIDTH</th>\n",
       "      <th>ARITRSHIFT_VALUE</th>\n",
       "      <th>AlwaysConstructs</th>\n",
       "      <th>AssignLHSPortNum</th>\n",
       "      <th>...</th>\n",
       "      <th>QUESTIONCOLONTHEN</th>\n",
       "      <th>REDAND</th>\n",
       "      <th>REDAOR</th>\n",
       "      <th>REDXOR</th>\n",
       "      <th>REG</th>\n",
       "      <th>REGWIDTH</th>\n",
       "      <th>UnaryOperator</th>\n",
       "      <th>WIRENUM</th>\n",
       "      <th>WIREWIDTH</th>\n",
       "      <th>FF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>212.0</td>\n",
       "      <td>212.0</td>\n",
       "      <td>212.0</td>\n",
       "      <td>212.0</td>\n",
       "      <td>212.000000</td>\n",
       "      <td>212.000000</td>\n",
       "      <td>212.000000</td>\n",
       "      <td>212.000000</td>\n",
       "      <td>212.000000</td>\n",
       "      <td>212.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>212.000000</td>\n",
       "      <td>212.000000</td>\n",
       "      <td>212.000000</td>\n",
       "      <td>212.000000</td>\n",
       "      <td>212.000000</td>\n",
       "      <td>212.000000</td>\n",
       "      <td>212.000000</td>\n",
       "      <td>212.000000</td>\n",
       "      <td>212.000000</td>\n",
       "      <td>212.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.113208</td>\n",
       "      <td>0.070755</td>\n",
       "      <td>0.674528</td>\n",
       "      <td>0.386792</td>\n",
       "      <td>2.287736</td>\n",
       "      <td>2.924528</td>\n",
       "      <td>...</td>\n",
       "      <td>0.523585</td>\n",
       "      <td>3.886792</td>\n",
       "      <td>0.495283</td>\n",
       "      <td>0.561321</td>\n",
       "      <td>3.783019</td>\n",
       "      <td>124.339623</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>2.844340</td>\n",
       "      <td>13.976415</td>\n",
       "      <td>22.627358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.758156</td>\n",
       "      <td>0.524014</td>\n",
       "      <td>4.576129</td>\n",
       "      <td>2.801728</td>\n",
       "      <td>3.237406</td>\n",
       "      <td>10.205192</td>\n",
       "      <td>...</td>\n",
       "      <td>2.526525</td>\n",
       "      <td>8.233927</td>\n",
       "      <td>4.434353</td>\n",
       "      <td>4.076405</td>\n",
       "      <td>5.397041</td>\n",
       "      <td>705.919378</td>\n",
       "      <td>2.236863</td>\n",
       "      <td>8.446055</td>\n",
       "      <td>52.403144</td>\n",
       "      <td>59.159899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.750000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>26.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>127.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>8202.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>575.000000</td>\n",
       "      <td>768.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ARITLSHIFT  ARITLSHIFT_PORT_NUM  ARITLSHIFT_PORT_WIDTH  \\\n",
       "count       212.0                212.0                  212.0   \n",
       "mean          0.0                  0.0                    0.0   \n",
       "std           0.0                  0.0                    0.0   \n",
       "min           0.0                  0.0                    0.0   \n",
       "25%           0.0                  0.0                    0.0   \n",
       "50%           0.0                  0.0                    0.0   \n",
       "75%           0.0                  0.0                    0.0   \n",
       "max           0.0                  0.0                    0.0   \n",
       "\n",
       "       ARITLSHIFT_VALUE  ARITRSHIFT  ARITRSHIFT_PORT_NUM  \\\n",
       "count             212.0  212.000000           212.000000   \n",
       "mean                0.0    0.113208             0.070755   \n",
       "std                 0.0    0.758156             0.524014   \n",
       "min                 0.0    0.000000             0.000000   \n",
       "25%                 0.0    0.000000             0.000000   \n",
       "50%                 0.0    0.000000             0.000000   \n",
       "75%                 0.0    0.000000             0.000000   \n",
       "max                 0.0    8.000000             7.000000   \n",
       "\n",
       "       ARITRSHIFT_PORT_WIDTH  ARITRSHIFT_VALUE  AlwaysConstructs  \\\n",
       "count             212.000000        212.000000        212.000000   \n",
       "mean                0.674528          0.386792          2.287736   \n",
       "std                 4.576129          2.801728          3.237406   \n",
       "min                 0.000000          0.000000          0.000000   \n",
       "25%                 0.000000          0.000000          1.000000   \n",
       "50%                 0.000000          0.000000          1.000000   \n",
       "75%                 0.000000          0.000000          2.000000   \n",
       "max                56.000000         28.000000         24.000000   \n",
       "\n",
       "       AssignLHSPortNum  ...  QUESTIONCOLONTHEN      REDAND      REDAOR  \\\n",
       "count        212.000000  ...         212.000000  212.000000  212.000000   \n",
       "mean           2.924528  ...           0.523585    3.886792    0.495283   \n",
       "std           10.205192  ...           2.526525    8.233927    4.434353   \n",
       "min            0.000000  ...           0.000000    0.000000    0.000000   \n",
       "25%            0.000000  ...           0.000000    0.000000    0.000000   \n",
       "50%            1.000000  ...           0.000000    0.500000    0.000000   \n",
       "75%            2.000000  ...           0.000000    4.000000    0.000000   \n",
       "max          127.000000  ...          31.000000   55.000000   62.000000   \n",
       "\n",
       "           REDXOR         REG     REGWIDTH  UnaryOperator     WIRENUM  \\\n",
       "count  212.000000  212.000000   212.000000     212.000000  212.000000   \n",
       "mean     0.561321    3.783019   124.339623       0.250000    2.844340   \n",
       "std      4.076405    5.397041   705.919378       2.236863    8.446055   \n",
       "min      0.000000    0.000000     0.000000       0.000000    0.000000   \n",
       "25%      0.000000    1.000000     1.750000       0.000000    0.000000   \n",
       "50%      0.000000    2.000000     8.000000       0.000000    0.000000   \n",
       "75%      0.000000    4.000000    31.000000       0.000000    1.250000   \n",
       "max     56.000000   32.000000  8202.000000      32.000000   65.000000   \n",
       "\n",
       "        WIREWIDTH          FF  \n",
       "count  212.000000  212.000000  \n",
       "mean    13.976415   22.627358  \n",
       "std     52.403144   59.159899  \n",
       "min      0.000000    0.000000  \n",
       "25%      0.000000    0.000000  \n",
       "50%      0.000000    4.500000  \n",
       "75%      2.000000   26.000000  \n",
       "max    575.000000  768.000000  \n",
       "\n",
       "[8 rows x 60 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resource_origin_data_lut.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "2f73c8ca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FF                           1.000000\n",
       "FORTIMES                     0.318122\n",
       "REG                          0.267595\n",
       "PLUS                         0.263268\n",
       "NonBlockLeftWidth            0.251252\n",
       "CONDITIONALTHEN              0.250369\n",
       "CONDITIONALIF                0.250369\n",
       "CONDITIONALELSE              0.248461\n",
       "NonBlockingLeftPortNum       0.246407\n",
       "NonBlockingAssign            0.246407\n",
       "NonBlockRightWidth           0.227492\n",
       "REDAND                       0.198197\n",
       "AlwaysConstructs             0.197609\n",
       "CONDITIONALIFWIDTH           0.194888\n",
       "OUTPUTWIDTH                  0.187606\n",
       "INPUTWIDTH                   0.177238\n",
       "AssignRHSWidth               0.143146\n",
       "CASECONDITIONNUM             0.136131\n",
       "CASECONDITIONWIDTH           0.132652\n",
       "ARITRSHIFT                   0.126581\n",
       "MIN                          0.119910\n",
       "CASEITEMNUM                  0.113249\n",
       "ARITRSHIFT_PORT_NUM          0.112609\n",
       "FORBLOCK                     0.106055\n",
       "ARITRSHIFT_VALUE             0.101036\n",
       "NonBlockingRightPortNum      0.099386\n",
       "AssignLHSWidth               0.098165\n",
       "INPUT                        0.097005\n",
       "ARITRSHIFT_PORT_WIDTH        0.095606\n",
       "WIRENUM                      0.091043\n",
       "PARAMETERNUM                 0.084119\n",
       "WIREWIDTH                    0.082084\n",
       "CASEITEMCONDITIONNUM         0.079593\n",
       "REGWIDTH                     0.077135\n",
       "OUTPUT                       0.062179\n",
       "BlockAssign_Right_Width      0.057024\n",
       "FUNCTIONCALL                 0.044638\n",
       "BlockAssign_Left_Width       0.041904\n",
       "BLOCKINGASSIGN               0.037881\n",
       "AssignRHSPortNum             0.036747\n",
       "INOUTWIDTH                   0.034033\n",
       "INDEXMEMRORY                 0.033222\n",
       "BlockAssign_Left_PortNum     0.030819\n",
       "BlockAssign_Right_PortNum    0.023448\n",
       "AssignStmts                  0.021894\n",
       "AssignLHSPortNum             0.020253\n",
       "CASEITEMCONDITIOWIDTH        0.015771\n",
       "QUESTIONCOLONTHEN            0.000392\n",
       "QUESTIONCOLONIF              0.000392\n",
       "QUESTIONCOLONELSE            0.000392\n",
       "QUESTIONCOLON                0.000392\n",
       "REDXOR                      -0.010016\n",
       "UnaryOperator               -0.027013\n",
       "REDAOR                      -0.028054\n",
       "FUNCTIONNUM                 -0.029040\n",
       "ARITLSHIFT                        NaN\n",
       "ARITLSHIFT_PORT_NUM               NaN\n",
       "ARITLSHIFT_PORT_WIDTH             NaN\n",
       "ARITLSHIFT_VALUE                  NaN\n",
       "INOUT                             NaN\n",
       "Name: FF, dtype: float64"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#相关性分析\n",
    "corr_matrix=resource_origin_data_lut.corr()\n",
    "corr_matrix[\"FF\"].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "2fd8d5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#特征优化\n",
    "resource_lut = resource_origin_data_lut[\"FF\"].copy() #label data\n",
    "resource_lut_data = resource_origin_data_lut.drop(\"FF\",axis=1) #feature data\n",
    "resource_label = list(resource_lut_data) #labal list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "f8e7acfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#数据分割\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "#训练集、测试集、验证集\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(resource_lut_data, resource_lut, test_size=0.2,random_state=42)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "7eecddc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#数据标准化\n",
    "scaler = StandardScaler() \n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_valid = scaler.transform(X_valid)\n",
    "X_test = scaler.transform(X_test)\n",
    "X_train_full = scaler.transform(X_train_full)\n",
    "X_data_full = scaler.transform(resource_lut_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "cf04fcac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#深度学习\n",
    "\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "ebc9345f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(126, 59)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "aba9a350",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "input_ = keras.layers.Input(shape=X_train.shape[1:])\n",
    "hidden1 = keras.layers.Dense(59, activation=\"relu\")(input_)\n",
    "#hidden2 = keras.layers.Dense(150, activation=\"relu\")(hidden1)\n",
    "concat = keras.layers.concatenate([input_, hidden1])\n",
    "output = keras.layers.Dense(1)(concat)\n",
    "model = keras.models.Model(inputs=[input_], outputs=[output])\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(monitor='val_loss',patience=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "252b1313",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Input(shape=X_train.shape[1:]),\n",
    "    keras.layers.Dense(59, activation=\"relu\"),\n",
    "    keras.layers.Dense(27, activation=\"relu\"),\n",
    "    keras.layers.Dense(162, activation=\"relu\"),\n",
    "    keras.layers.Dense(53, activation=\"relu\"),\n",
    "    keras.layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "3fe69cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Input(shape=X_train.shape[1:]),\n",
    "    keras.layers.Dense(59, activation=\"relu\"),\n",
    "    keras.layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "eae277e4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/235\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 1278.2708 - val_loss: 1615.6414\n",
      "Epoch 2/235\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1188.2742 - val_loss: 1484.4441\n",
      "Epoch 3/235\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1130.9529 - val_loss: 1380.9779\n",
      "Epoch 4/235\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1080.3850 - val_loss: 1284.5316\n",
      "Epoch 5/235\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1020.8812 - val_loss: 1202.9177\n",
      "Epoch 6/235\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 968.2764 - val_loss: 1134.3162\n",
      "Epoch 7/235\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 918.2999 - val_loss: 1073.7704\n",
      "Epoch 8/235\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 872.7980 - val_loss: 1017.3882\n",
      "Epoch 9/235\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 822.9366 - val_loss: 948.4166\n",
      "Epoch 10/235\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 764.6019 - val_loss: 898.8235\n",
      "Epoch 11/235\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 725.3267 - val_loss: 851.5640\n",
      "Epoch 12/235\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 681.8349 - val_loss: 814.4720\n",
      "Epoch 13/235\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 647.9105 - val_loss: 778.6281\n",
      "Epoch 14/235\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 612.5696 - val_loss: 750.2807\n",
      "Epoch 15/235\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 586.2239 - val_loss: 724.8811\n",
      "Epoch 16/235\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 560.9889 - val_loss: 706.7496\n",
      "Epoch 17/235\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 543.5113 - val_loss: 679.4321\n",
      "Epoch 18/235\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 519.5651 - val_loss: 666.0057\n",
      "Epoch 19/235\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 506.3757 - val_loss: 653.7491\n",
      "Epoch 20/235\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 495.4597 - val_loss: 640.8653\n",
      "Epoch 21/235\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 482.4505 - val_loss: 630.5557\n",
      "Epoch 22/235\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 473.1641 - val_loss: 622.0878\n",
      "Epoch 23/235\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 464.3965 - val_loss: 612.9495\n",
      "Epoch 24/235\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 455.6990 - val_loss: 603.3476\n",
      "Epoch 25/235\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 447.5336 - val_loss: 598.8007\n",
      "Epoch 26/235\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 442.2225 - val_loss: 588.5119\n",
      "Epoch 27/235\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 432.1558 - val_loss: 580.7632\n",
      "Epoch 28/235\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 426.0915 - val_loss: 574.2368\n",
      "Epoch 29/235\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 418.5276 - val_loss: 567.3579\n",
      "Epoch 30/235\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 412.4529 - val_loss: 561.6538\n",
      "Epoch 31/235\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 407.6893 - val_loss: 553.5383\n",
      "Epoch 32/235\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 399.9417 - val_loss: 547.3416\n",
      "Epoch 33/235\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 394.2110 - val_loss: 540.3784\n",
      "Epoch 34/235\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 386.9783 - val_loss: 533.2319\n",
      "Epoch 35/235\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 381.6185 - val_loss: 526.5511\n",
      "Epoch 36/235\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 376.4105 - val_loss: 520.0039\n",
      "Epoch 37/235\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 370.8244 - val_loss: 518.4639\n",
      "Epoch 38/235\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 366.4170 - val_loss: 512.6068\n",
      "Epoch 39/235\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 361.7006 - val_loss: 507.4298\n",
      "Epoch 40/235\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 357.0911 - val_loss: 500.1143\n",
      "Epoch 41/235\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 351.9345 - val_loss: 496.7450\n",
      "Epoch 42/235\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 346.0909 - val_loss: 486.3232\n",
      "Epoch 43/235\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 341.2547 - val_loss: 478.9420\n",
      "Epoch 44/235\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 334.5563 - val_loss: 474.1673\n",
      "Epoch 45/235\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 331.4158 - val_loss: 472.0834\n",
      "Epoch 46/235\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 326.9950 - val_loss: 465.8959\n",
      "Epoch 47/235\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 322.7151 - val_loss: 458.2626\n",
      "Epoch 48/235\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 316.6370 - val_loss: 453.0323\n",
      "Epoch 49/235\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 313.0093 - val_loss: 449.1255\n",
      "Epoch 50/235\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 309.0059 - val_loss: 444.2203\n",
      "Epoch 51/235\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 306.0103 - val_loss: 438.8985\n",
      "Epoch 52/235\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 301.9716 - val_loss: 431.5602\n",
      "Epoch 53/235\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 295.4611 - val_loss: 427.2571\n",
      "Epoch 54/235\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 291.0254 - val_loss: 420.8092\n",
      "Epoch 55/235\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 287.0503 - val_loss: 408.8855\n",
      "Epoch 56/235\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 284.4327 - val_loss: 406.2255\n",
      "Epoch 57/235\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 281.2368 - val_loss: 403.6654\n",
      "Epoch 58/235\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 277.8810 - val_loss: 399.1512\n",
      "Epoch 59/235\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 274.1334 - val_loss: 395.9863\n",
      "Epoch 60/235\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 271.8629 - val_loss: 391.6666\n",
      "Epoch 61/235\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 267.7389 - val_loss: 389.6793\n",
      "Epoch 62/235\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 264.8444 - val_loss: 384.3578\n",
      "Epoch 63/235\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 262.6095 - val_loss: 371.4265\n",
      "Epoch 64/235\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 261.1656 - val_loss: 372.4958\n",
      "Epoch 65/235\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 257.0511 - val_loss: 369.2457\n",
      "Epoch 66/235\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 254.7954 - val_loss: 365.5197\n",
      "Epoch 67/235\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 251.5482 - val_loss: 366.2511\n",
      "Epoch 68/235\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 249.4081 - val_loss: 371.5853\n",
      "Epoch 69/235\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 246.5855 - val_loss: 369.1923\n",
      "Epoch 70/235\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 244.3552 - val_loss: 367.8803\n",
      "Epoch 71/235\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 243.9708 - val_loss: 367.0776\n",
      "Epoch 72/235\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 240.7363 - val_loss: 360.4563\n",
      "Epoch 73/235\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 237.9166 - val_loss: 351.9360\n",
      "Epoch 74/235\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 235.0294 - val_loss: 351.0067\n",
      "Epoch 75/235\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 234.1977 - val_loss: 348.7859\n",
      "Epoch 76/235\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 231.1611 - val_loss: 346.1844\n",
      "Epoch 77/235\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 230.3230 - val_loss: 344.3918\n",
      "Epoch 78/235\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 227.5189 - val_loss: 341.5597\n",
      "Epoch 79/235\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 225.3477 - val_loss: 334.4340\n",
      "Epoch 80/235\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 224.2666 - val_loss: 331.7491\n",
      "Epoch 81/235\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 5ms/step - loss: 222.0339 - val_loss: 328.8887\n",
      "Epoch 82/235\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 220.2129 - val_loss: 328.3008\n",
      "Epoch 83/235\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 218.7426 - val_loss: 326.2459\n",
      "Epoch 84/235\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 217.3180 - val_loss: 317.1800\n",
      "Epoch 85/235\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 215.0140 - val_loss: 312.6311\n",
      "Epoch 86/235\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 213.4566 - val_loss: 311.9493\n",
      "Epoch 87/235\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 212.3834 - val_loss: 307.1684\n",
      "Epoch 88/235\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 209.5891 - val_loss: 313.1704\n",
      "Epoch 89/235\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 207.7968 - val_loss: 307.3568\n",
      "Epoch 90/235\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 206.7237 - val_loss: 309.8955\n",
      "Epoch 91/235\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 205.1349 - val_loss: 307.2787\n",
      "Epoch 92/235\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 204.6892 - val_loss: 308.9601\n",
      "Epoch 93/235\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 203.2776 - val_loss: 303.2811\n",
      "Epoch 94/235\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 201.6963 - val_loss: 298.7280\n",
      "Epoch 95/235\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 200.6643 - val_loss: 297.9767\n",
      "Epoch 96/235\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 199.1436 - val_loss: 297.9115\n",
      "Epoch 97/235\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 198.8552 - val_loss: 293.8104\n",
      "Epoch 98/235\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 198.0083 - val_loss: 294.0857\n",
      "Epoch 99/235\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 196.8915 - val_loss: 290.1095\n",
      "Epoch 100/235\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 194.8521 - val_loss: 284.5293\n",
      "Epoch 101/235\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 193.7651 - val_loss: 283.6129\n",
      "Epoch 102/235\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 193.2416 - val_loss: 283.6275\n",
      "Epoch 103/235\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 192.4492 - val_loss: 282.1878\n",
      "Epoch 104/235\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 191.8654 - val_loss: 282.3066\n",
      "Epoch 105/235\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 190.5288 - val_loss: 280.3755\n",
      "Epoch 106/235\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 189.6780 - val_loss: 284.1281\n",
      "Epoch 107/235\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 188.7673 - val_loss: 281.7303\n",
      "Epoch 108/235\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 188.5408 - val_loss: 279.5720\n",
      "Epoch 109/235\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 187.6216 - val_loss: 280.5979\n",
      "Epoch 110/235\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 186.8379 - val_loss: 282.6981\n",
      "Epoch 111/235\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 186.1526 - val_loss: 279.0957\n",
      "Epoch 112/235\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 185.6875 - val_loss: 278.5979\n",
      "Epoch 113/235\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 185.0259 - val_loss: 274.3780\n",
      "Epoch 114/235\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 184.8929 - val_loss: 272.1852\n",
      "Epoch 115/235\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 182.7677 - val_loss: 270.5157\n",
      "Epoch 116/235\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 182.5795 - val_loss: 267.0087\n",
      "Epoch 117/235\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 181.6854 - val_loss: 257.6587\n",
      "Epoch 118/235\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 180.9921 - val_loss: 264.2986\n",
      "Epoch 119/235\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 179.7690 - val_loss: 263.0391\n",
      "Epoch 120/235\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 179.1777 - val_loss: 262.9428\n",
      "Epoch 121/235\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 179.8153 - val_loss: 262.2023\n",
      "Epoch 122/235\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 178.5363 - val_loss: 268.6316\n",
      "Epoch 123/235\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 178.2296 - val_loss: 265.0876\n",
      "Epoch 124/235\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 177.5581 - val_loss: 255.9702\n",
      "Epoch 125/235\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 175.7612 - val_loss: 254.8511\n",
      "Epoch 126/235\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 175.6395 - val_loss: 255.6897\n",
      "Epoch 127/235\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 174.5193 - val_loss: 255.3684\n",
      "Epoch 128/235\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 174.4279 - val_loss: 253.3809\n",
      "Epoch 129/235\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 173.7917 - val_loss: 251.3604\n",
      "Epoch 130/235\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 173.8605 - val_loss: 250.6674\n",
      "Epoch 131/235\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 173.3912 - val_loss: 249.6186\n",
      "Epoch 132/235\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 172.7130 - val_loss: 248.6785\n",
      "Epoch 133/235\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 172.1413 - val_loss: 249.9051\n",
      "Epoch 134/235\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 170.9693 - val_loss: 248.4568\n",
      "Epoch 135/235\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 170.6322 - val_loss: 246.4032\n",
      "Epoch 136/235\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 170.1002 - val_loss: 245.2347\n",
      "Epoch 137/235\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 169.5222 - val_loss: 245.7051\n",
      "Epoch 138/235\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 169.8121 - val_loss: 247.8609\n",
      "Epoch 139/235\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 169.0922 - val_loss: 247.5807\n",
      "Epoch 140/235\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 168.1745 - val_loss: 246.2048\n",
      "Epoch 141/235\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 167.8324 - val_loss: 234.2103\n",
      "Epoch 142/235\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 167.3662 - val_loss: 235.1880\n",
      "Epoch 143/235\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 166.8459 - val_loss: 241.4701\n",
      "Epoch 144/235\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 166.1948 - val_loss: 240.6909\n",
      "Epoch 145/235\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 165.6615 - val_loss: 241.1238\n",
      "Epoch 146/235\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 165.4800 - val_loss: 239.8564\n",
      "Epoch 147/235\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 164.8317 - val_loss: 237.6270\n",
      "Epoch 148/235\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 164.3716 - val_loss: 242.6116\n",
      "Epoch 149/235\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 164.2261 - val_loss: 240.3856\n",
      "Epoch 150/235\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 163.9141 - val_loss: 241.8510\n",
      "Epoch 151/235\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 163.3161 - val_loss: 239.6200\n",
      "Epoch 152/235\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 163.0604 - val_loss: 237.2769\n",
      "Epoch 153/235\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 162.2996 - val_loss: 237.3960\n",
      "Epoch 154/235\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 162.1550 - val_loss: 235.7684\n",
      "Epoch 155/235\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 161.4079 - val_loss: 232.4622\n",
      "Epoch 156/235\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 161.2990 - val_loss: 230.9703\n",
      "Epoch 157/235\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 160.5224 - val_loss: 227.8863\n",
      "Epoch 158/235\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 159.9458 - val_loss: 225.6796\n",
      "Epoch 159/235\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 159.6249 - val_loss: 225.7998\n",
      "Epoch 160/235\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 159.4705 - val_loss: 217.7745\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 161/235\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 160.4051 - val_loss: 213.9681\n",
      "Epoch 162/235\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 160.2573 - val_loss: 215.6641\n",
      "Epoch 163/235\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 158.8291 - val_loss: 216.7173\n",
      "Epoch 164/235\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 158.1016 - val_loss: 217.3815\n",
      "Epoch 165/235\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 157.0271 - val_loss: 218.9687\n",
      "Epoch 166/235\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 156.8954 - val_loss: 221.4017\n",
      "Epoch 167/235\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 156.7295 - val_loss: 224.0312\n",
      "Epoch 168/235\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 156.7878 - val_loss: 226.3125\n",
      "Epoch 169/235\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 156.0405 - val_loss: 216.6859\n",
      "Epoch 170/235\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 155.4258 - val_loss: 214.9746\n",
      "Epoch 171/235\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 155.1858 - val_loss: 214.0302\n",
      "Epoch 172/235\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 154.8154 - val_loss: 214.7854\n",
      "Epoch 173/235\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 153.8753 - val_loss: 215.2811\n",
      "Epoch 174/235\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 154.5024 - val_loss: 214.9361\n",
      "Epoch 175/235\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 153.3405 - val_loss: 213.7431\n",
      "Epoch 176/235\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 153.0867 - val_loss: 214.0260\n",
      "Epoch 177/235\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 153.0390 - val_loss: 213.4120\n",
      "Epoch 178/235\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 152.5082 - val_loss: 206.8877\n",
      "Epoch 179/235\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 152.1212 - val_loss: 210.1184\n",
      "Epoch 180/235\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 151.9507 - val_loss: 211.4412\n",
      "Epoch 181/235\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 151.0761 - val_loss: 209.9692\n",
      "Epoch 182/235\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 151.3095 - val_loss: 211.1350\n",
      "Epoch 183/235\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 150.8806 - val_loss: 209.6869\n",
      "Epoch 184/235\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 150.0281 - val_loss: 206.6878\n",
      "Epoch 185/235\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 149.7680 - val_loss: 205.4929\n",
      "Epoch 186/235\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 149.3381 - val_loss: 205.0387\n",
      "Epoch 187/235\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 149.1905 - val_loss: 205.6693\n",
      "Epoch 188/235\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 149.1067 - val_loss: 205.2312\n",
      "Epoch 189/235\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 148.3995 - val_loss: 204.4068\n",
      "Epoch 190/235\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 148.2307 - val_loss: 206.1633\n",
      "Epoch 191/235\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 148.4710 - val_loss: 206.6281\n",
      "Epoch 192/235\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 148.1776 - val_loss: 204.9962\n",
      "Epoch 193/235\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 147.3951 - val_loss: 204.2686\n",
      "Epoch 194/235\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 146.8147 - val_loss: 202.0625\n",
      "Epoch 195/235\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 147.3037 - val_loss: 208.5518\n",
      "Epoch 196/235\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 146.6774 - val_loss: 205.7806\n",
      "Epoch 197/235\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 145.8148 - val_loss: 198.0732\n",
      "Epoch 198/235\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 145.8041 - val_loss: 197.4997\n",
      "Epoch 199/235\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 146.1112 - val_loss: 197.2643\n",
      "Epoch 200/235\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 145.0087 - val_loss: 197.8783\n",
      "Epoch 201/235\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 144.7767 - val_loss: 192.0094\n",
      "Epoch 202/235\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 144.4069 - val_loss: 193.4916\n",
      "Epoch 203/235\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 144.7841 - val_loss: 190.6552\n",
      "Epoch 204/235\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 144.2684 - val_loss: 191.3575\n",
      "Epoch 205/235\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 144.2444 - val_loss: 191.4960\n",
      "Epoch 206/235\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 143.7171 - val_loss: 190.9427\n",
      "Epoch 207/235\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 143.2365 - val_loss: 190.1082\n",
      "Epoch 208/235\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 142.6398 - val_loss: 190.8154\n",
      "Epoch 209/235\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 142.0907 - val_loss: 191.3367\n",
      "Epoch 210/235\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 142.2365 - val_loss: 196.1465\n",
      "Epoch 211/235\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 141.6149 - val_loss: 193.1514\n",
      "Epoch 212/235\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 141.4701 - val_loss: 185.8250\n",
      "Epoch 213/235\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 141.7023 - val_loss: 186.3212\n",
      "Epoch 214/235\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 140.7758 - val_loss: 179.1859\n",
      "Epoch 215/235\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 141.7436 - val_loss: 185.9326\n",
      "Epoch 216/235\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 140.3232 - val_loss: 186.3782\n",
      "Epoch 217/235\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 139.6066 - val_loss: 184.7550\n",
      "Epoch 218/235\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 139.4792 - val_loss: 180.6650\n",
      "Epoch 219/235\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 139.0909 - val_loss: 182.5757\n",
      "Epoch 220/235\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 139.2638 - val_loss: 178.6791\n",
      "Epoch 221/235\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 138.8965 - val_loss: 179.2230\n",
      "Epoch 222/235\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 138.7272 - val_loss: 179.4416\n",
      "Epoch 223/235\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 137.6137 - val_loss: 179.8131\n",
      "Epoch 224/235\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 137.6257 - val_loss: 174.4403\n",
      "Epoch 225/235\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 138.0978 - val_loss: 180.7173\n",
      "Epoch 226/235\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 137.3211 - val_loss: 181.6658\n",
      "Epoch 227/235\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 136.7547 - val_loss: 183.2366\n",
      "Epoch 228/235\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 136.4754 - val_loss: 180.8997\n",
      "Epoch 229/235\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 135.7425 - val_loss: 179.6517\n",
      "Epoch 230/235\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 135.7238 - val_loss: 179.6033\n",
      "Epoch 231/235\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 135.8825 - val_loss: 179.4706\n",
      "Epoch 232/235\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 135.0816 - val_loss: 176.1799\n",
      "Epoch 233/235\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 134.9814 - val_loss: 175.8223\n",
      "Epoch 234/235\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 134.2952 - val_loss: 177.7076\n",
      "Epoch 235/235\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 134.4662 - val_loss: 175.6024\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"mean_squared_error\", optimizer=keras.optimizers.SGD(learning_rate=0.0001343909963682435))\n",
    "history = model.fit(X_train_full, y_train_full, epochs=235, validation_data=(X_valid, y_valid))\n",
    "# 绘制训练 & 验证的损失值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6fb24b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "ea6d7457",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) ', 'for plot_model/model_to_dot to work.')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "keras.utils.plot_model(model, \"my_fashion_mnist_model.png\", show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "c18253f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 59)                3540      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 27)                1620      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 162)               4536      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 53)                8639      \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 54        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 18,389\n",
      "Trainable params: 18,389\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "fabbd76d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.588582411562266\n",
      "13.20758349740104\n",
      "(array([], dtype=int64),)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(np.min(np.sqrt(history.history['loss'])))\n",
    "print(np.min(np.sqrt(history.history['val_loss'])))\n",
    "test = np.sqrt(history.history['val_loss'])\n",
    "print(np.where(test==67.94991836823647))\n",
    "plt.plot(np.sqrt(history.history['loss']))\n",
    "plt.plot(np.sqrt(history.history['val_loss'])/2)\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('ANN_FF_RMSE')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "58d9d3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(n_hidden=1, n_neurons=30, learning_rate=1e-3, input_shape=[59]):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.InputLayer(input_shape=input_shape))\n",
    "    for layer in range(n_hidden):\n",
    "        model.add(keras.layers.Dense(n_neurons, activation=\"relu\"))\n",
    "    model.add(keras.layers.Dense(1))\n",
    "    optimizer = keras.optimizers.SGD(learning_rate=learning_rate)\n",
    "    model.compile(loss=\"mse\", optimizer=optimizer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "2547e47e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_3(n_neurons=30, learning_rate=1e-3, input_shape=[59],unit1=1,unit2=2,unit3=3):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.InputLayer(input_shape=input_shape))\n",
    "    model.add(keras.layers.Dense(unit1, activation=\"relu\"))\n",
    "    model.add(keras.layers.Dense(unit2, activation=\"relu\"))\n",
    "    model.add(keras.layers.Dense(unit3, activation=\"relu\"))\n",
    "    model.add(keras.layers.Dense(1))\n",
    "    optimizer = keras.optimizers.SGD(learning_rate=learning_rate)\n",
    "    model.compile(loss=\"mse\", optimizer=optimizer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "c8dac366",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-155-0c5b676cc640>:2: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead.\n",
      "  keras_reg = keras.wrappers.scikit_learn.KerasRegressor(build_model_3)\n"
     ]
    }
   ],
   "source": [
    "keras.backend.clear_session()\n",
    "keras_reg = keras.wrappers.scikit_learn.KerasRegressor(build_model_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "90b4b8af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.wrappers.scikit_learn.KerasRegressor at 0x18be90aae50>"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "706b07e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Epoch 1/1000\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 866.9620 - val_loss: 8764.0684\n",
      "Epoch 2/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 229232816412879224832.0000 - val_loss: inf\n",
      "Epoch 3/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: nan - val_loss: nan\n",
      "Epoch 4/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: nan - val_loss: nan\n",
      "Epoch 5/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: nan - val_loss: nan\n",
      "Epoch 6/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: nan - val_loss: nan\n",
      "Epoch 7/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: nan - val_loss: nan\n",
      "Epoch 8/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: nan - val_loss: nan\n",
      "Epoch 9/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: nan - val_loss: nan\n",
      "Epoch 11/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: nan - val_loss: nan\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan\n",
      "[CV] END learning_rate=0.008261212966815147, unit1=52, unit2=196, unit3=56; total time=   0.7s\n",
      "Epoch 1/1000\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 2498.0496 - val_loss: 4179.2661\n",
      "Epoch 2/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: inf - val_loss: nan\n",
      "Epoch 3/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: nan - val_loss: nan\n",
      "Epoch 4/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: nan - val_loss: nan\n",
      "Epoch 5/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: nan - val_loss: nan\n",
      "Epoch 6/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: nan - val_loss: nan\n",
      "Epoch 7/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: nan - val_loss: nan\n",
      "Epoch 8/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: nan - val_loss: nan\n",
      "Epoch 9/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: nan - val_loss: nan\n",
      "Epoch 11/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: nan - val_loss: nan\n",
      "2/2 [==============================] - 0s 3ms/step - loss: nan\n",
      "[CV] END learning_rate=0.008261212966815147, unit1=52, unit2=196, unit3=56; total time=   0.7s\n",
      "Epoch 1/1000\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 1004.1200 - val_loss: 125044.8516\n",
      "Epoch 2/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 41420161286144.0000 - val_loss: inf\n",
      "Epoch 3/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: nan - val_loss: nan\n",
      "Epoch 4/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: nan - val_loss: nan\n",
      "Epoch 5/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: nan - val_loss: nan\n",
      "Epoch 6/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: nan - val_loss: nan\n",
      "Epoch 7/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: nan - val_loss: nan\n",
      "Epoch 8/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: nan - val_loss: nan\n",
      "Epoch 9/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: nan - val_loss: nan\n",
      "Epoch 11/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: nan - val_loss: nan\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan\n",
      "[CV] END learning_rate=0.008261212966815147, unit1=52, unit2=196, unit3=56; total time=   0.6s\n",
      "Epoch 1/1000\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 983.8745 - val_loss: 1303.2338\n",
      "Epoch 2/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 981.6027 - val_loss: 1299.5038\n",
      "Epoch 3/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 979.4000 - val_loss: 1296.0469\n",
      "Epoch 4/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 977.3776 - val_loss: 1292.7401\n",
      "Epoch 5/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 975.4885 - val_loss: 1289.8188\n",
      "Epoch 6/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 973.6218 - val_loss: 1286.5654\n",
      "Epoch 7/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 971.6769 - val_loss: 1283.3569\n",
      "Epoch 8/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 969.7829 - val_loss: 1280.3466\n",
      "Epoch 9/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 967.9933 - val_loss: 1277.1202\n",
      "Epoch 10/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 966.0371 - val_loss: 1273.7404\n",
      "Epoch 11/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 963.9737 - val_loss: 1270.1331\n",
      "Epoch 12/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 961.8293 - val_loss: 1266.2485\n",
      "Epoch 13/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 959.5015 - val_loss: 1262.0531\n",
      "Epoch 14/1000\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 956.9250 - val_loss: 1257.4634\n",
      "Epoch 15/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 954.2952 - val_loss: 1252.5037\n",
      "Epoch 16/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 951.0376 - val_loss: 1247.0446\n",
      "Epoch 17/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 947.5125 - val_loss: 1239.3071\n",
      "Epoch 18/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 942.3807 - val_loss: 1232.1631\n",
      "Epoch 19/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 937.7990 - val_loss: 1224.1642\n",
      "Epoch 20/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 932.5175 - val_loss: 1213.7300\n",
      "Epoch 21/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 924.9304 - val_loss: 1200.6051\n",
      "Epoch 22/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 915.9370 - val_loss: 1185.8485\n",
      "Epoch 23/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 905.5252 - val_loss: 1168.8422\n",
      "Epoch 24/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 893.3091 - val_loss: 1147.9769\n",
      "Epoch 25/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 878.5678 - val_loss: 1125.9125\n",
      "Epoch 26/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 863.1138 - val_loss: 1101.1257\n",
      "Epoch 27/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 843.5728 - val_loss: 1068.6592\n",
      "Epoch 28/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 818.6609 - val_loss: 1030.8121\n",
      "Epoch 29/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 791.5536 - val_loss: 989.5948\n",
      "Epoch 30/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 757.8600 - val_loss: 930.1284\n",
      "Epoch 31/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 708.6480 - val_loss: 868.3193\n",
      "Epoch 32/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 660.7228 - val_loss: 807.8842\n",
      "Epoch 33/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 608.8326 - val_loss: 734.0768\n",
      "Epoch 34/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 547.5788 - val_loss: 665.0699\n",
      "Epoch 35/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 484.5226 - val_loss: 607.9409\n",
      "Epoch 36/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 435.3433 - val_loss: 560.8752\n",
      "Epoch 37/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 394.0434 - val_loss: 540.7097\n",
      "Epoch 38/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 369.3723 - val_loss: 521.1144\n",
      "Epoch 39/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 342.5627 - val_loss: 503.6782\n",
      "Epoch 40/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 323.3783 - val_loss: 493.5195\n",
      "Epoch 41/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 306.6892 - val_loss: 482.6490\n",
      "Epoch 42/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 296.6961 - val_loss: 473.1229\n",
      "Epoch 43/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 280.4847 - val_loss: 465.9844\n",
      "Epoch 44/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 13ms/step - loss: 268.8735 - val_loss: 456.5705\n",
      "Epoch 45/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 260.7849 - val_loss: 448.2722\n",
      "Epoch 46/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 248.1683 - val_loss: 441.5628\n",
      "Epoch 47/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 238.3057 - val_loss: 434.7107\n",
      "Epoch 48/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 230.7828 - val_loss: 428.9184\n",
      "Epoch 49/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 227.0184 - val_loss: 426.7997\n",
      "Epoch 50/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 217.0105 - val_loss: 421.3552\n",
      "Epoch 51/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 211.3706 - val_loss: 416.3040\n",
      "Epoch 52/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 203.9442 - val_loss: 405.7093\n",
      "Epoch 53/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 196.9110 - val_loss: 400.4590\n",
      "Epoch 54/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 190.9330 - val_loss: 395.5574\n",
      "Epoch 55/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 185.7640 - val_loss: 391.4717\n",
      "Epoch 56/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 185.3558 - val_loss: 389.0480\n",
      "Epoch 57/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 175.5886 - val_loss: 383.2481\n",
      "Epoch 58/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 170.4096 - val_loss: 378.2092\n",
      "Epoch 59/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 165.6264 - val_loss: 374.9985\n",
      "Epoch 60/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 163.0861 - val_loss: 370.7597\n",
      "Epoch 61/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 160.8223 - val_loss: 367.4423\n",
      "Epoch 62/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 153.1452 - val_loss: 365.1784\n",
      "Epoch 63/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 149.5282 - val_loss: 362.3912\n",
      "Epoch 64/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 148.6691 - val_loss: 360.7259\n",
      "Epoch 65/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 143.3988 - val_loss: 358.3995\n",
      "Epoch 66/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 139.6173 - val_loss: 355.8952\n",
      "Epoch 67/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 139.0242 - val_loss: 355.0500\n",
      "Epoch 68/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 133.5390 - val_loss: 351.9103\n",
      "Epoch 69/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 129.8710 - val_loss: 349.9395\n",
      "Epoch 70/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 126.5830 - val_loss: 348.0465\n",
      "Epoch 71/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 127.0091 - val_loss: 346.2394\n",
      "Epoch 72/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 122.8144 - val_loss: 344.9411\n",
      "Epoch 73/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 119.0620 - val_loss: 343.5956\n",
      "Epoch 74/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 115.9338 - val_loss: 341.8499\n",
      "Epoch 75/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 114.0855 - val_loss: 340.8552\n",
      "Epoch 76/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 111.2469 - val_loss: 339.8981\n",
      "Epoch 77/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 108.6297 - val_loss: 338.4727\n",
      "Epoch 78/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 109.1665 - val_loss: 337.5973\n",
      "Epoch 79/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 109.1477 - val_loss: 335.8948\n",
      "Epoch 80/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 103.2305 - val_loss: 335.4980\n",
      "Epoch 81/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 100.4091 - val_loss: 334.6227\n",
      "Epoch 82/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 100.2412 - val_loss: 334.2188\n",
      "Epoch 83/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 99.7985 - val_loss: 333.1262\n",
      "Epoch 84/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 95.5107 - val_loss: 332.2673\n",
      "Epoch 85/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 93.9268 - val_loss: 332.4764\n",
      "Epoch 86/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 90.8582 - val_loss: 331.1548\n",
      "Epoch 87/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 91.5920 - val_loss: 330.2390\n",
      "Epoch 88/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 87.6154 - val_loss: 330.0555\n",
      "Epoch 89/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 87.4051 - val_loss: 329.6872\n",
      "Epoch 90/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 85.2095 - val_loss: 330.1455\n",
      "Epoch 91/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 84.3141 - val_loss: 328.3755\n",
      "Epoch 92/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 82.3749 - val_loss: 328.0395\n",
      "Epoch 93/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 82.4991 - val_loss: 327.6123\n",
      "Epoch 94/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 80.8254 - val_loss: 327.4937\n",
      "Epoch 95/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 78.2780 - val_loss: 327.5072\n",
      "Epoch 96/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 78.0595 - val_loss: 327.2899\n",
      "Epoch 97/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 76.6870 - val_loss: 328.5187\n",
      "Epoch 98/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 75.3382 - val_loss: 327.8460\n",
      "Epoch 99/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 73.0600 - val_loss: 327.5455\n",
      "Epoch 100/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 72.6556 - val_loss: 327.9175\n",
      "Epoch 101/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 70.8283 - val_loss: 327.4799\n",
      "Epoch 102/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 70.4350 - val_loss: 327.5560\n",
      "Epoch 103/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 69.0336 - val_loss: 328.6812\n",
      "Epoch 104/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 67.7493 - val_loss: 329.2575\n",
      "Epoch 105/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 67.0281 - val_loss: 330.5797\n",
      "Epoch 106/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 66.6146 - val_loss: 328.7402\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 315.6461\n",
      "[CV] END learning_rate=0.00011860098412735948, unit1=98, unit2=61, unit3=9; total time=   3.7s\n",
      "Epoch 1/1000\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 1139.4608 - val_loss: 1260.3330\n",
      "Epoch 2/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 1116.9377 - val_loss: 1227.5878\n",
      "Epoch 3/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 1089.3925 - val_loss: 1191.8179\n",
      "Epoch 4/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 1058.8307 - val_loss: 1152.7456\n",
      "Epoch 5/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 1022.4507 - val_loss: 1105.5291\n",
      "Epoch 6/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 976.9874 - val_loss: 1046.6292\n",
      "Epoch 7/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 919.9826 - val_loss: 975.4597\n",
      "Epoch 8/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 845.2040 - val_loss: 889.8813\n",
      "Epoch 9/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 756.8524 - val_loss: 799.7764\n",
      "Epoch 10/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 659.4869 - val_loss: 695.3701\n",
      "Epoch 11/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 536.6815 - val_loss: 616.9570\n",
      "Epoch 12/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 442.7971 - val_loss: 571.9096\n",
      "Epoch 13/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 380.6883 - val_loss: 554.5864\n",
      "Epoch 14/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 349.4700 - val_loss: 550.1998\n",
      "Epoch 15/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 16ms/step - loss: 339.1441 - val_loss: 532.2388\n",
      "Epoch 16/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 320.4700 - val_loss: 523.1582\n",
      "Epoch 17/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 310.3034 - val_loss: 517.1072\n",
      "Epoch 18/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 304.2491 - val_loss: 513.8568\n",
      "Epoch 19/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 297.0456 - val_loss: 500.5042\n",
      "Epoch 20/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 284.7630 - val_loss: 496.6009\n",
      "Epoch 21/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 275.4106 - val_loss: 483.0760\n",
      "Epoch 22/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 264.9175 - val_loss: 476.1674\n",
      "Epoch 23/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 259.8665 - val_loss: 470.7567\n",
      "Epoch 24/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 251.9021 - val_loss: 463.6635\n",
      "Epoch 25/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 249.7426 - val_loss: 456.1078\n",
      "Epoch 26/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 239.4368 - val_loss: 451.2420\n",
      "Epoch 27/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 237.7446 - val_loss: 445.9578\n",
      "Epoch 28/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 228.8159 - val_loss: 442.6914\n",
      "Epoch 29/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 226.7055 - val_loss: 436.7242\n",
      "Epoch 30/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 218.8540 - val_loss: 431.4323\n",
      "Epoch 31/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 214.2269 - val_loss: 429.0666\n",
      "Epoch 32/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 209.8155 - val_loss: 424.8796\n",
      "Epoch 33/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 205.6014 - val_loss: 420.4473\n",
      "Epoch 34/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 200.0964 - val_loss: 416.6020\n",
      "Epoch 35/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 195.3544 - val_loss: 413.6582\n",
      "Epoch 36/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 194.3231 - val_loss: 412.5899\n",
      "Epoch 37/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 191.3367 - val_loss: 407.7514\n",
      "Epoch 38/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 184.8563 - val_loss: 404.1710\n",
      "Epoch 39/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 179.1660 - val_loss: 400.4749\n",
      "Epoch 40/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 177.8244 - val_loss: 399.0073\n",
      "Epoch 41/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 171.6786 - val_loss: 397.0111\n",
      "Epoch 42/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 169.3997 - val_loss: 393.5189\n",
      "Epoch 43/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 165.8182 - val_loss: 390.8384\n",
      "Epoch 44/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 163.0857 - val_loss: 391.3033\n",
      "Epoch 45/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 161.0538 - val_loss: 386.8841\n",
      "Epoch 46/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 157.7060 - val_loss: 387.1696\n",
      "Epoch 47/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 152.7471 - val_loss: 383.3206\n",
      "Epoch 48/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 148.9594 - val_loss: 381.9213\n",
      "Epoch 49/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 146.7463 - val_loss: 379.9149\n",
      "Epoch 50/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 143.5978 - val_loss: 379.6460\n",
      "Epoch 51/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 142.3243 - val_loss: 377.2887\n",
      "Epoch 52/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 139.8098 - val_loss: 376.4452\n",
      "Epoch 53/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 135.9209 - val_loss: 376.8285\n",
      "Epoch 54/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 135.2123 - val_loss: 375.4152\n",
      "Epoch 55/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 130.1593 - val_loss: 375.3867\n",
      "Epoch 56/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 127.6790 - val_loss: 375.7869\n",
      "Epoch 57/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 124.8713 - val_loss: 375.1923\n",
      "Epoch 58/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 123.9088 - val_loss: 373.5902\n",
      "Epoch 59/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 121.5686 - val_loss: 373.7021\n",
      "Epoch 60/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 119.6449 - val_loss: 374.1415\n",
      "Epoch 61/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 117.4261 - val_loss: 373.8614\n",
      "Epoch 62/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 115.5685 - val_loss: 372.9808\n",
      "Epoch 63/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 114.1264 - val_loss: 373.6924\n",
      "Epoch 64/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 111.9066 - val_loss: 375.5974\n",
      "Epoch 65/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 109.9708 - val_loss: 375.4151\n",
      "Epoch 66/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 108.5767 - val_loss: 375.7637\n",
      "Epoch 67/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 106.9731 - val_loss: 375.2204\n",
      "Epoch 68/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 107.1161 - val_loss: 375.3878\n",
      "Epoch 69/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 104.0382 - val_loss: 375.9643\n",
      "Epoch 70/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 103.2025 - val_loss: 379.0435\n",
      "Epoch 71/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 100.6485 - val_loss: 377.8981\n",
      "Epoch 72/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 100.2706 - val_loss: 379.2637\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 268.9617\n",
      "[CV] END learning_rate=0.00011860098412735948, unit1=98, unit2=61, unit3=9; total time=   2.6s\n",
      "Epoch 1/1000\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 1162.8542 - val_loss: 1259.1948\n",
      "Epoch 2/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1148.4865 - val_loss: 1238.7063\n",
      "Epoch 3/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 1131.8987 - val_loss: 1216.6565\n",
      "Epoch 4/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 1114.7881 - val_loss: 1192.4043\n",
      "Epoch 5/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 1094.5037 - val_loss: 1161.0006\n",
      "Epoch 6/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 1069.3857 - val_loss: 1126.1079\n",
      "Epoch 7/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 1040.6613 - val_loss: 1083.7198\n",
      "Epoch 8/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 1005.2286 - val_loss: 1029.6205\n",
      "Epoch 9/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 962.4413 - val_loss: 973.5809\n",
      "Epoch 10/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 912.4053 - val_loss: 902.5978\n",
      "Epoch 11/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 854.6284 - val_loss: 826.5720\n",
      "Epoch 12/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 786.5237 - val_loss: 743.1506\n",
      "Epoch 13/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 705.9659 - val_loss: 656.5869\n",
      "Epoch 14/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 625.9245 - val_loss: 579.5604\n",
      "Epoch 15/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 552.3897 - val_loss: 530.5052\n",
      "Epoch 16/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 500.8580 - val_loss: 506.8824\n",
      "Epoch 17/1000\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 474.9736 - val_loss: 494.5563\n",
      "Epoch 18/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 446.3172 - val_loss: 484.3520\n",
      "Epoch 19/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 424.0076 - val_loss: 478.6566\n",
      "Epoch 20/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 12ms/step - loss: 407.7916 - val_loss: 472.2810\n",
      "Epoch 21/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 385.5868 - val_loss: 466.5201\n",
      "Epoch 22/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 366.9352 - val_loss: 465.3280\n",
      "Epoch 23/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 348.1723 - val_loss: 458.2262\n",
      "Epoch 24/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 334.6813 - val_loss: 460.0474\n",
      "Epoch 25/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 318.9986 - val_loss: 455.4041\n",
      "Epoch 26/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 305.0497 - val_loss: 456.0833\n",
      "Epoch 27/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 293.5645 - val_loss: 460.2044\n",
      "Epoch 28/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 282.5469 - val_loss: 463.0121\n",
      "Epoch 29/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 271.5659 - val_loss: 470.0938\n",
      "Epoch 30/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 266.4022 - val_loss: 467.0386\n",
      "Epoch 31/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 256.4098 - val_loss: 461.2657\n",
      "Epoch 32/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 245.4158 - val_loss: 471.8995\n",
      "Epoch 33/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 236.6241 - val_loss: 482.7231\n",
      "Epoch 34/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 228.4228 - val_loss: 475.8179\n",
      "Epoch 35/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 227.8801 - val_loss: 485.7874\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 294.0620\n",
      "[CV] END learning_rate=0.00011860098412735948, unit1=98, unit2=61, unit3=9; total time=   1.3s\n",
      "Epoch 1/1000\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 860.4604 - val_loss: 5194.7446\n",
      "Epoch 2/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 924.6376 - val_loss: 1280.7844\n",
      "Epoch 3/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 953.1158 - val_loss: 1249.6644\n",
      "Epoch 4/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 910.6035 - val_loss: 917.2030\n",
      "Epoch 5/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 889.6435 - val_loss: 1248.3751\n",
      "Epoch 6/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 921.7323 - val_loss: 1221.7090\n",
      "Epoch 7/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 900.3973 - val_loss: 1171.9331\n",
      "Epoch 8/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 842.5829 - val_loss: 799.0795\n",
      "Epoch 9/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 362.2742 - val_loss: 547.1205\n",
      "Epoch 10/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 566.6513 - val_loss: 1212.4708\n",
      "Epoch 11/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 888.6543 - val_loss: 1194.6537\n",
      "Epoch 12/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 874.5487 - val_loss: 1181.0824\n",
      "Epoch 13/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 863.5428 - val_loss: 1167.8231\n",
      "Epoch 14/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 852.5485 - val_loss: 1152.5588\n",
      "Epoch 15/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 839.1993 - val_loss: 1126.0261\n",
      "Epoch 16/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 814.5790 - val_loss: 1049.2097\n",
      "Epoch 17/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 707.1399 - val_loss: 558.9891\n",
      "Epoch 18/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 250.1829 - val_loss: 18832.6367\n",
      "Epoch 19/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 4123.1670 - val_loss: 1103.2717\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 1135.8641\n",
      "[CV] END learning_rate=0.003956638500871096, unit1=83, unit2=166, unit3=28; total time=   0.8s\n",
      "Epoch 1/1000\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 840.1353 - val_loss: 104645.4453\n",
      "Epoch 2/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 13950616727361421312.0000 - val_loss: inf\n",
      "Epoch 3/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: nan - val_loss: nan\n",
      "Epoch 4/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: nan - val_loss: nan\n",
      "Epoch 5/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: nan - val_loss: nan\n",
      "Epoch 6/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: nan - val_loss: nan\n",
      "Epoch 7/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: nan - val_loss: nan\n",
      "Epoch 8/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: nan - val_loss: nan\n",
      "Epoch 9/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: nan - val_loss: nan\n",
      "Epoch 11/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: nan - val_loss: nan\n",
      "2/2 [==============================] - 0s 4ms/step - loss: nan\n",
      "[CV] END learning_rate=0.003956638500871096, unit1=83, unit2=166, unit3=28; total time=   0.6s\n",
      "Epoch 1/1000\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 1123.9941 - val_loss: 697.0807\n",
      "Epoch 2/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 589.3729 - val_loss: 1287.0771\n",
      "Epoch 3/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 1154.2340 - val_loss: 1232.9792\n",
      "Epoch 4/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 1072.5179 - val_loss: 697.3487\n",
      "Epoch 5/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 954.4002 - val_loss: 1255.3627\n",
      "Epoch 6/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 1129.6965 - val_loss: 1224.3966\n",
      "Epoch 7/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 1102.8044 - val_loss: 1155.1226\n",
      "Epoch 8/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 1038.5560 - val_loss: 837.9957\n",
      "Epoch 9/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 648.4193 - val_loss: 468.6770\n",
      "Epoch 10/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 659.3795 - val_loss: 2458.2163\n",
      "Epoch 11/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 1395.1647 - val_loss: 1195.3395\n",
      "Epoch 12/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1070.3346 - val_loss: 1174.6038\n",
      "Epoch 13/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 1050.2524 - val_loss: 1141.0590\n",
      "Epoch 14/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 1007.8820 - val_loss: 980.4258\n",
      "Epoch 15/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 632.1580 - val_loss: 82378.5234\n",
      "Epoch 16/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 1006010739497893888.0000 - val_loss: inf\n",
      "Epoch 17/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: nan - val_loss: nan\n",
      "Epoch 18/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: nan - val_loss: nan\n",
      "Epoch 19/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: nan - val_loss: nan\n",
      "2/2 [==============================] - 0s 10ms/step - loss: nan\n",
      "[CV] END learning_rate=0.003956638500871096, unit1=83, unit2=166, unit3=28; total time=   1.0s\n",
      "Epoch 1/1000\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 955.2115 - val_loss: 1173.0308\n",
      "Epoch 2/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 805.2503 - val_loss: 692.7430\n",
      "Epoch 3/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 551.8835 - val_loss: 498.7597\n",
      "Epoch 4/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 571.0596 - val_loss: 452.7567\n",
      "Epoch 5/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 550.9114 - val_loss: 700.3855\n",
      "Epoch 6/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 492.3542 - val_loss: 1147.7754\n",
      "Epoch 7/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 751.6596 - val_loss: 461.2152\n",
      "Epoch 8/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 266.6056 - val_loss: 1184.9399\n",
      "Epoch 9/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 14ms/step - loss: 832.0624 - val_loss: 827.1870\n",
      "Epoch 10/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 398.7788 - val_loss: 428.1668\n",
      "Epoch 11/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 184.2594 - val_loss: 366.3836\n",
      "Epoch 12/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 244.3325 - val_loss: 1173.7521\n",
      "Epoch 13/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 824.2765 - val_loss: 945.5073\n",
      "Epoch 14/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 515.2830 - val_loss: 681.5081\n",
      "Epoch 15/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 256.3962 - val_loss: 1080.2646\n",
      "Epoch 16/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 716.6954 - val_loss: 850.6245\n",
      "Epoch 17/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 501.4113 - val_loss: 1306.6614\n",
      "Epoch 18/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 955.3066 - val_loss: 1266.2953\n",
      "Epoch 19/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 924.4236 - val_loss: 1228.5667\n",
      "Epoch 20/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 884.6083 - val_loss: 1156.7987\n",
      "Epoch 21/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 756.8692 - val_loss: 692.7200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 756.1354\n",
      "[CV] END learning_rate=0.002223734074383608, unit1=6, unit2=12, unit3=47; total time=   1.0s\n",
      "Epoch 1/1000\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 1147.6633 - val_loss: 1261.8297\n",
      "Epoch 2/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 1106.6256 - val_loss: 1156.0376\n",
      "Epoch 3/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 934.3755 - val_loss: 680.5569\n",
      "Epoch 4/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 459.5449 - val_loss: 498.8295\n",
      "Epoch 5/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 505.9987 - val_loss: 503.6483\n",
      "Epoch 6/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 258.9966 - val_loss: 363.1090\n",
      "Epoch 7/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 231.8926 - val_loss: 408.4763\n",
      "Epoch 8/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 541.8987 - val_loss: 1223.6682\n",
      "Epoch 9/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1073.4681 - val_loss: 1139.3411\n",
      "Epoch 10/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 971.7658 - val_loss: 721.7592\n",
      "Epoch 11/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 1008.0049 - val_loss: 1352.3030\n",
      "Epoch 12/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 1150.4065 - val_loss: 1270.0907\n",
      "Epoch 13/1000\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 1100.4502 - val_loss: 1245.8796\n",
      "Epoch 14/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 1081.4911 - val_loss: 1229.3794\n",
      "Epoch 15/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 1066.4131 - val_loss: 1212.3813\n",
      "Epoch 16/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 1049.5667 - val_loss: 1190.0021\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 912.0132\n",
      "[CV] END learning_rate=0.002223734074383608, unit1=6, unit2=12, unit3=47; total time=   0.8s\n",
      "Epoch 1/1000\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 1155.6537 - val_loss: 1154.5128\n",
      "Epoch 2/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 851.3536 - val_loss: 2398.8298\n",
      "Epoch 3/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 2083.4246 - val_loss: 1292.0349\n",
      "Epoch 4/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 1148.0681 - val_loss: 1270.7708\n",
      "Epoch 5/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 1127.6083 - val_loss: 1244.1005\n",
      "Epoch 6/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 1099.2025 - val_loss: 1191.7920\n",
      "Epoch 7/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1016.2255 - val_loss: 875.5073\n",
      "Epoch 8/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 582.2738 - val_loss: 865.3863\n",
      "Epoch 9/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 462.1408 - val_loss: 429.7715\n",
      "Epoch 10/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 264.4688 - val_loss: 523.3890\n",
      "Epoch 11/1000\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 385.0139 - val_loss: 6066.2188\n",
      "Epoch 12/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 4712.8242 - val_loss: 1265.9768\n",
      "Epoch 13/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 1123.5145 - val_loss: 1246.2380\n",
      "Epoch 14/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1106.7915 - val_loss: 1231.7251\n",
      "Epoch 15/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1094.1434 - val_loss: 1217.8563\n",
      "Epoch 16/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 1081.0707 - val_loss: 1202.4023\n",
      "Epoch 17/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 1066.1920 - val_loss: 1183.8760\n",
      "Epoch 18/1000\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 1047.9897 - val_loss: 1160.1910\n",
      "Epoch 19/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 1024.4077 - val_loss: 1123.8687\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 770.5767\n",
      "[CV] END learning_rate=0.002223734074383608, unit1=6, unit2=12, unit3=47; total time=   0.9s\n",
      "Epoch 1/1000\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 948.9494 - val_loss: 1223.2106\n",
      "Epoch 2/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 935.9987 - val_loss: 1199.3058\n",
      "Epoch 3/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 920.5318 - val_loss: 1173.1572\n",
      "Epoch 4/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 903.6859 - val_loss: 1144.9476\n",
      "Epoch 5/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 884.2589 - val_loss: 1111.7703\n",
      "Epoch 6/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 861.7167 - val_loss: 1075.4274\n",
      "Epoch 7/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 834.5474 - val_loss: 1027.6570\n",
      "Epoch 8/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 798.6694 - val_loss: 974.2812\n",
      "Epoch 9/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 757.9374 - val_loss: 916.1275\n",
      "Epoch 10/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 710.9608 - val_loss: 845.7320\n",
      "Epoch 11/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 651.9662 - val_loss: 774.4373\n",
      "Epoch 12/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 586.7521 - val_loss: 695.4518\n",
      "Epoch 13/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 518.6944 - val_loss: 627.0431\n",
      "Epoch 14/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 451.8169 - val_loss: 573.4135\n",
      "Epoch 15/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 401.4083 - val_loss: 536.3682\n",
      "Epoch 16/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 359.6306 - val_loss: 508.0880\n",
      "Epoch 17/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 328.2692 - val_loss: 488.1780\n",
      "Epoch 18/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 306.4808 - val_loss: 476.6117\n",
      "Epoch 19/1000\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 293.6250 - val_loss: 461.6432\n",
      "Epoch 20/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 287.6598 - val_loss: 450.8598\n",
      "Epoch 21/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 272.3632 - val_loss: 440.4530\n",
      "Epoch 22/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 257.9653 - val_loss: 429.0844\n",
      "Epoch 23/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 246.9026 - val_loss: 421.7525\n",
      "Epoch 24/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 239.9081 - val_loss: 413.5167\n",
      "Epoch 25/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 230.9376 - val_loss: 405.0930\n",
      "Epoch 26/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 227.2076 - val_loss: 399.7028\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 216.6404 - val_loss: 392.0032\n",
      "Epoch 28/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 212.2114 - val_loss: 385.5506\n",
      "Epoch 29/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 204.6171 - val_loss: 380.3369\n",
      "Epoch 30/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 195.2156 - val_loss: 375.5313\n",
      "Epoch 31/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 190.2770 - val_loss: 368.9796\n",
      "Epoch 32/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 184.1757 - val_loss: 364.9610\n",
      "Epoch 33/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 179.6166 - val_loss: 359.3057\n",
      "Epoch 34/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 177.0064 - val_loss: 354.9570\n",
      "Epoch 35/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 169.8313 - val_loss: 352.2191\n",
      "Epoch 36/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 164.6818 - val_loss: 347.8149\n",
      "Epoch 37/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 162.9685 - val_loss: 345.8910\n",
      "Epoch 38/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 158.2438 - val_loss: 340.2992\n",
      "Epoch 39/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 153.1936 - val_loss: 336.2284\n",
      "Epoch 40/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 149.4946 - val_loss: 335.1586\n",
      "Epoch 41/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 144.9998 - val_loss: 332.6849\n",
      "Epoch 42/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 140.6622 - val_loss: 327.5824\n",
      "Epoch 43/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 137.0416 - val_loss: 325.3130\n",
      "Epoch 44/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 134.6867 - val_loss: 321.2303\n",
      "Epoch 45/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 133.4249 - val_loss: 318.4302\n",
      "Epoch 46/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 130.0896 - val_loss: 315.1822\n",
      "Epoch 47/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 125.6280 - val_loss: 312.7838\n",
      "Epoch 48/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 123.9548 - val_loss: 314.0132\n",
      "Epoch 49/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 122.4029 - val_loss: 311.5133\n",
      "Epoch 50/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 119.4224 - val_loss: 309.7884\n",
      "Epoch 51/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 115.0621 - val_loss: 306.3464\n",
      "Epoch 52/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 113.0403 - val_loss: 304.7838\n",
      "Epoch 53/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 114.7127 - val_loss: 302.4421\n",
      "Epoch 54/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 108.1447 - val_loss: 300.7313\n",
      "Epoch 55/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 105.3125 - val_loss: 298.3581\n",
      "Epoch 56/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 104.7768 - val_loss: 297.0708\n",
      "Epoch 57/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 104.2003 - val_loss: 296.3148\n",
      "Epoch 58/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 101.5264 - val_loss: 297.2750\n",
      "Epoch 59/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 100.7052 - val_loss: 296.9571\n",
      "Epoch 60/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 97.3861 - val_loss: 292.9025\n",
      "Epoch 61/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 95.2108 - val_loss: 291.6667\n",
      "Epoch 62/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 94.2017 - val_loss: 290.7390\n",
      "Epoch 63/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 91.5686 - val_loss: 290.7221\n",
      "Epoch 64/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 91.8229 - val_loss: 289.8041\n",
      "Epoch 65/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 88.5753 - val_loss: 289.6252\n",
      "Epoch 66/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 87.8409 - val_loss: 287.9861\n",
      "Epoch 67/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 85.9542 - val_loss: 287.2562\n",
      "Epoch 68/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 85.5532 - val_loss: 285.9124\n",
      "Epoch 69/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 82.7352 - val_loss: 285.4340\n",
      "Epoch 70/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 81.6930 - val_loss: 285.0846\n",
      "Epoch 71/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 80.5334 - val_loss: 284.6535\n",
      "Epoch 72/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 79.1862 - val_loss: 284.2058\n",
      "Epoch 73/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 78.6700 - val_loss: 283.7605\n",
      "Epoch 74/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 77.8485 - val_loss: 283.5172\n",
      "Epoch 75/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 75.3223 - val_loss: 283.1017\n",
      "Epoch 76/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 75.4273 - val_loss: 283.0193\n",
      "Epoch 77/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 75.7678 - val_loss: 283.2553\n",
      "Epoch 78/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 72.7744 - val_loss: 281.9932\n",
      "Epoch 79/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 71.0258 - val_loss: 281.5931\n",
      "Epoch 80/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 71.2620 - val_loss: 281.9310\n",
      "Epoch 81/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 69.7293 - val_loss: 281.0728\n",
      "Epoch 82/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 67.6942 - val_loss: 281.1163\n",
      "Epoch 83/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 67.4254 - val_loss: 281.2958\n",
      "Epoch 84/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 66.4119 - val_loss: 281.2614\n",
      "Epoch 85/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 65.2731 - val_loss: 281.1401\n",
      "Epoch 86/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 64.3519 - val_loss: 281.5608\n",
      "Epoch 87/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 63.3571 - val_loss: 280.8849\n",
      "Epoch 88/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 62.6322 - val_loss: 280.8613\n",
      "Epoch 89/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 61.2905 - val_loss: 281.3200\n",
      "Epoch 90/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 60.9894 - val_loss: 281.4322\n",
      "Epoch 91/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 62.1900 - val_loss: 281.0357\n",
      "Epoch 92/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 59.7166 - val_loss: 282.3608\n",
      "Epoch 93/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 58.3923 - val_loss: 281.7802\n",
      "Epoch 94/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 57.3433 - val_loss: 281.7732\n",
      "Epoch 95/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 57.2971 - val_loss: 282.2393\n",
      "Epoch 96/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 55.8299 - val_loss: 282.0225\n",
      "Epoch 97/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 56.2410 - val_loss: 282.0024\n",
      "Epoch 98/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 55.1898 - val_loss: 283.1745\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 336.4720\n",
      "[CV] END learning_rate=0.0001343909963682435, unit1=53, unit2=162, unit3=27; total time=   3.8s\n",
      "Epoch 1/1000\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 1145.0295 - val_loss: 1286.4843\n",
      "Epoch 2/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 1134.1846 - val_loss: 1271.3507\n",
      "Epoch 3/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1122.1526 - val_loss: 1255.4697\n",
      "Epoch 4/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1109.0148 - val_loss: 1236.2982\n",
      "Epoch 5/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 1093.0823 - val_loss: 1214.6488\n",
      "Epoch 6/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 14ms/step - loss: 1074.7791 - val_loss: 1188.7848\n",
      "Epoch 7/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 1052.4768 - val_loss: 1158.2959\n",
      "Epoch 8/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 1024.7888 - val_loss: 1119.7655\n",
      "Epoch 9/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 989.6466 - val_loss: 1071.1365\n",
      "Epoch 10/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 943.2113 - val_loss: 1008.5216\n",
      "Epoch 11/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 878.1147 - val_loss: 924.4029\n",
      "Epoch 12/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 791.2987 - val_loss: 829.1886\n",
      "Epoch 13/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 693.2860 - val_loss: 726.9880\n",
      "Epoch 14/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 582.4195 - val_loss: 642.8820\n",
      "Epoch 15/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 484.3514 - val_loss: 580.0671\n",
      "Epoch 16/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 419.3785 - val_loss: 558.7748\n",
      "Epoch 17/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 382.4073 - val_loss: 545.8044\n",
      "Epoch 18/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 362.4351 - val_loss: 536.2689\n",
      "Epoch 19/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 346.5467 - val_loss: 531.1121\n",
      "Epoch 20/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 331.0996 - val_loss: 526.7632\n",
      "Epoch 21/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 315.8624 - val_loss: 524.7831\n",
      "Epoch 22/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 302.6642 - val_loss: 517.8538\n",
      "Epoch 23/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 296.0842 - val_loss: 511.0134\n",
      "Epoch 24/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 280.1108 - val_loss: 503.7306\n",
      "Epoch 25/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 271.6143 - val_loss: 498.6264\n",
      "Epoch 26/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 265.6822 - val_loss: 490.3946\n",
      "Epoch 27/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 256.6564 - val_loss: 491.0745\n",
      "Epoch 28/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 249.1218 - val_loss: 490.4272\n",
      "Epoch 29/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 239.1361 - val_loss: 478.9706\n",
      "Epoch 30/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 232.4448 - val_loss: 474.4212\n",
      "Epoch 31/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 225.6407 - val_loss: 467.8485\n",
      "Epoch 32/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 218.9626 - val_loss: 467.1972\n",
      "Epoch 33/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 212.9224 - val_loss: 466.8322\n",
      "Epoch 34/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 207.6766 - val_loss: 464.1451\n",
      "Epoch 35/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 202.7634 - val_loss: 461.4222\n",
      "Epoch 36/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 197.4841 - val_loss: 458.7859\n",
      "Epoch 37/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 193.8904 - val_loss: 463.7904\n",
      "Epoch 38/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 188.9989 - val_loss: 461.6026\n",
      "Epoch 39/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 184.8692 - val_loss: 457.7254\n",
      "Epoch 40/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 178.4071 - val_loss: 451.4467\n",
      "Epoch 41/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 174.7357 - val_loss: 447.4182\n",
      "Epoch 42/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 170.6549 - val_loss: 447.5898\n",
      "Epoch 43/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 170.2729 - val_loss: 445.7157\n",
      "Epoch 44/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 164.6153 - val_loss: 443.9703\n",
      "Epoch 45/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 161.5516 - val_loss: 442.7054\n",
      "Epoch 46/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 163.3566 - val_loss: 438.3511\n",
      "Epoch 47/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 157.7132 - val_loss: 440.9689\n",
      "Epoch 48/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 152.4817 - val_loss: 441.1747\n",
      "Epoch 49/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 149.5245 - val_loss: 440.0020\n",
      "Epoch 50/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 147.2887 - val_loss: 440.0425\n",
      "Epoch 51/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 143.0511 - val_loss: 439.2001\n",
      "Epoch 52/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 141.0353 - val_loss: 438.8341\n",
      "Epoch 53/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 139.0689 - val_loss: 438.3938\n",
      "Epoch 54/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 136.6567 - val_loss: 436.5883\n",
      "Epoch 55/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 135.2065 - val_loss: 442.5164\n",
      "Epoch 56/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 132.6586 - val_loss: 446.8121\n",
      "Epoch 57/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 130.0633 - val_loss: 439.2874\n",
      "Epoch 58/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 126.7165 - val_loss: 439.4833\n",
      "Epoch 59/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 125.3045 - val_loss: 438.2245\n",
      "Epoch 60/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 122.8740 - val_loss: 441.7088\n",
      "Epoch 61/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 120.9419 - val_loss: 446.1986\n",
      "Epoch 62/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 119.4932 - val_loss: 447.6736\n",
      "Epoch 63/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 117.1151 - val_loss: 442.9636\n",
      "Epoch 64/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 115.0642 - val_loss: 444.1092\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 275.2003\n",
      "[CV] END learning_rate=0.0001343909963682435, unit1=53, unit2=162, unit3=27; total time=   2.5s\n",
      "Epoch 1/1000\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 1174.6490 - val_loss: 1297.8005\n",
      "Epoch 2/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 1164.8967 - val_loss: 1282.3383\n",
      "Epoch 3/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1154.4165 - val_loss: 1269.1847\n",
      "Epoch 4/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 1144.7021 - val_loss: 1250.7603\n",
      "Epoch 5/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 1130.6259 - val_loss: 1230.1293\n",
      "Epoch 6/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 1115.5020 - val_loss: 1207.9510\n",
      "Epoch 7/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 1098.1669 - val_loss: 1180.8862\n",
      "Epoch 8/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 1075.7600 - val_loss: 1147.2777\n",
      "Epoch 9/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 1048.3346 - val_loss: 1109.7330\n",
      "Epoch 10/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1016.4773 - val_loss: 1063.2379\n",
      "Epoch 11/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 978.2200 - val_loss: 1013.7451\n",
      "Epoch 12/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 933.7554 - val_loss: 940.6424\n",
      "Epoch 13/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 871.3427 - val_loss: 871.7714\n",
      "Epoch 14/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 803.6309 - val_loss: 792.4639\n",
      "Epoch 15/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 728.4907 - val_loss: 722.0244\n",
      "Epoch 16/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 662.4846 - val_loss: 667.8123\n",
      "Epoch 17/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 609.2250 - val_loss: 628.8914\n",
      "Epoch 18/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 566.7474 - val_loss: 606.3829\n",
      "Epoch 19/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 14ms/step - loss: 535.9048 - val_loss: 587.0679\n",
      "Epoch 20/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 508.8287 - val_loss: 567.1583\n",
      "Epoch 21/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 491.9495 - val_loss: 551.4498\n",
      "Epoch 22/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 456.1538 - val_loss: 537.2073\n",
      "Epoch 23/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 440.2617 - val_loss: 524.2262\n",
      "Epoch 24/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 416.3533 - val_loss: 505.7925\n",
      "Epoch 25/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 392.6152 - val_loss: 498.6674\n",
      "Epoch 26/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 373.4891 - val_loss: 494.0645\n",
      "Epoch 27/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 359.3380 - val_loss: 490.7957\n",
      "Epoch 28/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 340.0986 - val_loss: 486.6295\n",
      "Epoch 29/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 322.1046 - val_loss: 491.1519\n",
      "Epoch 30/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 307.8359 - val_loss: 479.2802\n",
      "Epoch 31/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 297.3958 - val_loss: 474.7828\n",
      "Epoch 32/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 282.4760 - val_loss: 482.3811\n",
      "Epoch 33/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 270.8563 - val_loss: 488.7286\n",
      "Epoch 34/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 265.4079 - val_loss: 485.5748\n",
      "Epoch 35/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 255.5587 - val_loss: 478.8934\n",
      "Epoch 36/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 244.6994 - val_loss: 483.8614\n",
      "Epoch 37/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 236.1408 - val_loss: 493.5782\n",
      "Epoch 38/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 230.6339 - val_loss: 480.9843\n",
      "Epoch 39/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 225.1819 - val_loss: 509.9836\n",
      "Epoch 40/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 215.7973 - val_loss: 513.7905\n",
      "Epoch 41/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 209.3369 - val_loss: 513.0325\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 227.3438\n",
      "[CV] END learning_rate=0.0001343909963682435, unit1=53, unit2=162, unit3=27; total time=   1.7s\n",
      "Epoch 1/1000\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 869.7255 - val_loss: 1304.8809\n",
      "Epoch 2/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 962.5096 - val_loss: 1235.0303\n",
      "Epoch 3/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 920.8649 - val_loss: 1058.8199\n",
      "Epoch 4/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 931.8795 - val_loss: 1242.9655\n",
      "Epoch 5/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 913.4654 - val_loss: 1184.9988\n",
      "Epoch 6/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 870.7565 - val_loss: 1141.2256\n",
      "Epoch 7/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 826.4634 - val_loss: 710.0504\n",
      "Epoch 8/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 10698.5273 - val_loss: 28139567104.0000\n",
      "Epoch 9/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 108775312384440697769426944.0000 - val_loss: 15086039812275469025280.0000\n",
      "Epoch 10/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 14720983655980350832640.0000 - val_loss: 13834471461430698704896.0000\n",
      "Epoch 11/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 13499704264429460783104.0000 - val_loss: 12686738103594582540288.0000\n",
      "Epoch 12/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 12379743479595431624704.0000 - val_loss: 11634223226780053929984.0000\n",
      "Epoch 13/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 11352697584573590011904.0000 - val_loss: 10669026391340798181376.0000\n",
      "Epoch 14/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 10410856416801877655552.0000 - val_loss: 9783903557276189851648.0000\n",
      "Epoch 15/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 9547150450765229719552.0000 - val_loss: 8972211915135857459200.0000\n",
      "Epoch 16/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 8755101258399673745408.0000 - val_loss: 8227859220523875565568.0000\n",
      "Epoch 17/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 8028760710497360150528.0000 - val_loss: 7545259884002397913088.0000\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 7545259884002397913088.0000\n",
      "[CV] END learning_rate=0.007165349974408226, unit1=84, unit2=182, unit3=25; total time=   0.8s\n",
      "Epoch 1/1000\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 726.9233 - val_loss: 312275.3750\n",
      "Epoch 2/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 144504879048556544.0000 - val_loss: inf\n",
      "Epoch 3/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: nan - val_loss: nan\n",
      "Epoch 4/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: nan - val_loss: nan\n",
      "Epoch 5/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: nan - val_loss: nan\n",
      "Epoch 6/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: nan - val_loss: nan\n",
      "Epoch 7/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: nan - val_loss: nan\n",
      "Epoch 8/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: nan - val_loss: nan\n",
      "Epoch 9/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: nan - val_loss: nan\n",
      "Epoch 11/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: nan - val_loss: nan\n",
      "2/2 [==============================] - 0s 3ms/step - loss: nan\n",
      "[CV] END learning_rate=0.007165349974408226, unit1=84, unit2=182, unit3=25; total time=   0.6s\n",
      "Epoch 1/1000\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 1242.2845 - val_loss: 1322.9615\n",
      "Epoch 2/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 1166.2660 - val_loss: 1227.0830\n",
      "Epoch 3/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 1412.0693 - val_loss: 1270.6002\n",
      "Epoch 4/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1124.0336 - val_loss: 570.2368\n",
      "Epoch 5/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 2399212.2500 - val_loss: 16236419458231030329114624.0000\n",
      "Epoch 6/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: nan - val_loss: nan      \n",
      "Epoch 7/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: nan - val_loss: nan\n",
      "Epoch 8/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: nan - val_loss: nan\n",
      "Epoch 9/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: nan - val_loss: nan\n",
      "Epoch 11/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: nan - val_loss: nan\n",
      "Epoch 12/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: nan - val_loss: nan\n",
      "Epoch 13/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: nan - val_loss: nan\n",
      "Epoch 14/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: nan - val_loss: nan\n",
      "2/2 [==============================] - 0s 10ms/step - loss: nan\n",
      "[CV] END learning_rate=0.007165349974408226, unit1=84, unit2=182, unit3=25; total time=   0.7s\n",
      "Epoch 1/1000\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 927.9249 - val_loss: 658.3914\n",
      "Epoch 2/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 2807.0256 - val_loss: 275394.6875\n",
      "Epoch 3/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: inf - val_loss: nan\n",
      "Epoch 4/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: nan - val_loss: nan\n",
      "Epoch 5/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: nan - val_loss: nan\n",
      "Epoch 6/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: nan - val_loss: nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: nan - val_loss: nan\n",
      "Epoch 8/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: nan - val_loss: nan\n",
      "Epoch 9/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: nan - val_loss: nan\n",
      "Epoch 11/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: nan - val_loss: nan\n",
      "2/2 [==============================] - 0s 4ms/step - loss: nan\n",
      "[CV] END learning_rate=0.004605652410721728, unit1=63, unit2=195, unit3=89; total time=   0.6s\n",
      "Epoch 1/1000\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 763.6678 - val_loss: 1302.6384\n",
      "Epoch 2/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 1122.3596 - val_loss: 1089.9724\n",
      "Epoch 3/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 1213.7970 - val_loss: 1258.7943\n",
      "Epoch 4/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1071.1980 - val_loss: 826.8456\n",
      "Epoch 5/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 3326.4006 - val_loss: 1739.7457\n",
      "Epoch 6/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 1382.3815 - val_loss: 1363.3319\n",
      "Epoch 7/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 61628.4297 - val_loss: 412163581623140352.0000\n",
      "Epoch 8/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: nan - val_loss: nan\n",
      "Epoch 9/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: nan - val_loss: nan\n",
      "Epoch 11/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: nan - val_loss: nan\n",
      "Epoch 12/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: nan - val_loss: nan\n",
      "Epoch 13/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: nan - val_loss: nan\n",
      "Epoch 14/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: nan - val_loss: nan\n",
      "2/2 [==============================] - 0s 4ms/step - loss: nan\n",
      "[CV] END learning_rate=0.004605652410721728, unit1=63, unit2=195, unit3=89; total time=   0.7s\n",
      "Epoch 1/1000\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 1077.0466 - val_loss: 1157.5444\n",
      "Epoch 2/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 1516.0736 - val_loss: 1410.7177\n",
      "Epoch 3/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 1117.6371 - val_loss: 28282.3789\n",
      "Epoch 4/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 21663.238 - 0s 14ms/step - loss: 11795.9736 - val_loss: 4331517467688960.0000\n",
      "Epoch 5/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: nan - val_loss: nan\n",
      "Epoch 6/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: nan - val_loss: nan\n",
      "Epoch 7/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: nan - val_loss: nan\n",
      "Epoch 8/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: nan - val_loss: nan\n",
      "Epoch 9/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: nan - val_loss: nan\n",
      "Epoch 11/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: nan - val_loss: nan\n",
      "2/2 [==============================] - 0s 10ms/step - loss: nan\n",
      "[CV] END learning_rate=0.004605652410721728, unit1=63, unit2=195, unit3=89; total time=   0.8s\n",
      "Epoch 1/1000\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 953.5402 - val_loss: 1086.0663\n",
      "Epoch 2/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 660.4888 - val_loss: 1115.7827\n",
      "Epoch 3/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 761.3542 - val_loss: 953.1740\n",
      "Epoch 4/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 621.0029 - val_loss: 1310.0281\n",
      "Epoch 5/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 965.6921 - val_loss: 1273.8230\n",
      "Epoch 6/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 941.0788 - val_loss: 1241.4155\n",
      "Epoch 7/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 914.9020 - val_loss: 1177.1575\n",
      "Epoch 8/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 858.8349 - val_loss: 974.2678\n",
      "Epoch 9/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 555.5380 - val_loss: 3731.6870\n",
      "Epoch 10/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 2906.9497 - val_loss: 1290.6998\n",
      "Epoch 11/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 920.1806 - val_loss: 1229.5098\n",
      "Epoch 12/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 902.6439 - val_loss: 1215.8987\n",
      "Epoch 13/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 890.2015 - val_loss: 1199.0699\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1237.3589\n",
      "[CV] END learning_rate=0.002576231704139902, unit1=48, unit2=21, unit3=82; total time=   0.7s\n",
      "Epoch 1/1000\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 1140.2113 - val_loss: 1066.7595\n",
      "Epoch 2/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 708.3276 - val_loss: 7489.9126\n",
      "Epoch 3/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 4185.8853 - val_loss: 947.6335\n",
      "Epoch 4/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 720.3867 - val_loss: 8849.6768\n",
      "Epoch 5/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 2497.4814 - val_loss: 1268.6366\n",
      "Epoch 6/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1110.7280 - val_loss: 1252.8752\n",
      "Epoch 7/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1095.9204 - val_loss: 1239.5028\n",
      "Epoch 8/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 1082.8564 - val_loss: 1225.5934\n",
      "Epoch 9/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 1068.7678 - val_loss: 1209.1057\n",
      "Epoch 10/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1051.9143 - val_loss: 1189.4847\n",
      "Epoch 11/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 1031.3157 - val_loss: 1163.5726\n",
      "Epoch 12/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 1004.8257 - val_loss: 1132.3123\n",
      "Epoch 13/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 972.2499 - val_loss: 1092.3888\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 830.0837\n",
      "[CV] END learning_rate=0.002576231704139902, unit1=48, unit2=21, unit3=82; total time=   0.7s\n",
      "Epoch 1/1000\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 1145.9467 - val_loss: 949.9402\n",
      "Epoch 2/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 702.8061 - val_loss: 430.2187\n",
      "Epoch 3/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 303.3000 - val_loss: 14728.6660\n",
      "Epoch 4/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 3726.3713 - val_loss: 1354.2452\n",
      "Epoch 5/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 1154.5742 - val_loss: 1261.6927\n",
      "Epoch 6/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1053.8607 - val_loss: 689.8364\n",
      "Epoch 7/1000\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 676.3996 - val_loss: 619.5782\n",
      "Epoch 8/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 706.0854 - val_loss: 1195.3635\n",
      "Epoch 9/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 914.9910 - val_loss: 1280.7322\n",
      "Epoch 10/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 1123.0323 - val_loss: 1256.8843\n",
      "Epoch 11/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 1101.1194 - val_loss: 1231.5454\n",
      "Epoch 12/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1075.0277 - val_loss: 1197.7983\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 831.5314\n",
      "[CV] END learning_rate=0.002576231704139902, unit1=48, unit2=21, unit3=82; total time=   0.6s\n",
      "Epoch 1/1000\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 958.2838 - val_loss: 1214.7458\n",
      "Epoch 2/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 918.9210 - val_loss: 1132.3162\n",
      "Epoch 3/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 16ms/step - loss: 857.1570 - val_loss: 1031.2457\n",
      "Epoch 4/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 769.8834 - val_loss: 857.7056\n",
      "Epoch 5/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 625.4624 - val_loss: 669.1790\n",
      "Epoch 6/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 464.7699 - val_loss: 519.3463\n",
      "Epoch 7/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 342.3276 - val_loss: 469.8207\n",
      "Epoch 8/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 287.0954 - val_loss: 461.2842\n",
      "Epoch 9/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 267.8290 - val_loss: 432.3808\n",
      "Epoch 10/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 224.3054 - val_loss: 403.4588\n",
      "Epoch 11/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 203.0193 - val_loss: 400.7192\n",
      "Epoch 12/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 190.5960 - val_loss: 383.6786\n",
      "Epoch 13/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 182.4797 - val_loss: 373.7559\n",
      "Epoch 14/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 166.0701 - val_loss: 369.8259\n",
      "Epoch 15/1000\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 149.2071 - val_loss: 352.3979\n",
      "Epoch 16/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 144.6853 - val_loss: 346.6734\n",
      "Epoch 17/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 128.3547 - val_loss: 358.8472\n",
      "Epoch 18/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 128.8504 - val_loss: 360.8727\n",
      "Epoch 19/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 117.3154 - val_loss: 341.4409\n",
      "Epoch 20/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 114.5831 - val_loss: 336.5984\n",
      "Epoch 21/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 103.7438 - val_loss: 333.3206\n",
      "Epoch 22/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 103.2759 - val_loss: 337.3054\n",
      "Epoch 23/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 100.2311 - val_loss: 328.1574\n",
      "Epoch 24/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 92.3872 - val_loss: 321.1141\n",
      "Epoch 25/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 92.7137 - val_loss: 329.9791\n",
      "Epoch 26/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 96.68 - 0s 12ms/step - loss: 102.8823 - val_loss: 330.1161\n",
      "Epoch 27/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 86.4640 - val_loss: 322.5586\n",
      "Epoch 28/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 76.6862 - val_loss: 318.4749\n",
      "Epoch 29/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 79.2957 - val_loss: 316.7916\n",
      "Epoch 30/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 79.4020 - val_loss: 311.4003\n",
      "Epoch 31/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 71.0679 - val_loss: 312.8138\n",
      "Epoch 32/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 77.3577 - val_loss: 315.2256\n",
      "Epoch 33/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 65.5206 - val_loss: 317.2810\n",
      "Epoch 34/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 67.3145 - val_loss: 310.4335\n",
      "Epoch 35/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 62.9692 - val_loss: 309.8241\n",
      "Epoch 36/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 58.6680 - val_loss: 305.7118\n",
      "Epoch 37/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 57.2618 - val_loss: 305.7849\n",
      "Epoch 38/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 55.8674 - val_loss: 304.5609\n",
      "Epoch 39/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 53.8925 - val_loss: 309.3333\n",
      "Epoch 40/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 56.7726 - val_loss: 306.4324\n",
      "Epoch 41/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 51.0775 - val_loss: 300.0696\n",
      "Epoch 42/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 50.3878 - val_loss: 302.1252\n",
      "Epoch 43/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 49.1392 - val_loss: 304.4061\n",
      "Epoch 44/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 50.6257 - val_loss: 303.6438\n",
      "Epoch 45/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 45.0359 - val_loss: 306.7121\n",
      "Epoch 46/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 47.0562 - val_loss: 301.9852\n",
      "Epoch 47/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 45.3121 - val_loss: 309.0397\n",
      "Epoch 48/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 41.7854 - val_loss: 301.7613\n",
      "Epoch 49/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 40.6915 - val_loss: 300.7959\n",
      "Epoch 50/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 40.9743 - val_loss: 305.6479\n",
      "Epoch 51/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 39.7764 - val_loss: 303.4406\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 441.4768\n",
      "[CV] END learning_rate=0.00041271597950230996, unit1=57, unit2=172, unit3=48; total time=   2.1s\n",
      "Epoch 1/1000\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 1115.6125 - val_loss: 1189.8832\n",
      "Epoch 2/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 1047.8591 - val_loss: 1069.0852\n",
      "Epoch 3/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 931.6614 - val_loss: 892.6983\n",
      "Epoch 4/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 731.1199 - val_loss: 720.5769\n",
      "Epoch 5/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 502.0731 - val_loss: 683.2853\n",
      "Epoch 6/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 395.6553 - val_loss: 790.7446\n",
      "Epoch 7/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 392.8696 - val_loss: 638.0663\n",
      "Epoch 8/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 290.5326 - val_loss: 566.7390\n",
      "Epoch 9/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 263.8791 - val_loss: 584.5105\n",
      "Epoch 10/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 250.3411 - val_loss: 527.9506\n",
      "Epoch 11/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 223.3310 - val_loss: 503.6397\n",
      "Epoch 12/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 211.6148 - val_loss: 484.6395\n",
      "Epoch 13/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 193.7938 - val_loss: 488.3340\n",
      "Epoch 14/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 179.6148 - val_loss: 466.5354\n",
      "Epoch 15/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 172.0917 - val_loss: 448.4667\n",
      "Epoch 16/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 170.0845 - val_loss: 445.7442\n",
      "Epoch 17/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 175.2738 - val_loss: 434.7694\n",
      "Epoch 18/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 141.2854 - val_loss: 428.2545\n",
      "Epoch 19/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 135.7526 - val_loss: 442.2245\n",
      "Epoch 20/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 129.0468 - val_loss: 425.6442\n",
      "Epoch 21/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 129.1919 - val_loss: 442.7790\n",
      "Epoch 22/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 126.3573 - val_loss: 431.6250\n",
      "Epoch 23/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 113.5263 - val_loss: 425.5788\n",
      "Epoch 24/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 109.8846 - val_loss: 431.6039\n",
      "Epoch 25/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 104.8376 - val_loss: 443.3726\n",
      "Epoch 26/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 102.8363 - val_loss: 438.5354\n",
      "Epoch 27/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 96.1631 - val_loss: 449.3775\n",
      "Epoch 28/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 95.1088 - val_loss: 451.2845\n",
      "Epoch 29/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 15ms/step - loss: 90.0809 - val_loss: 459.2046\n",
      "Epoch 30/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 89.5607 - val_loss: 499.7950\n",
      "Epoch 31/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 96.1513 - val_loss: 499.6559\n",
      "Epoch 32/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 82.8085 - val_loss: 470.5212\n",
      "Epoch 33/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 46.23 - 0s 13ms/step - loss: 83.1033 - val_loss: 480.4048\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 275.5636\n",
      "[CV] END learning_rate=0.00041271597950230996, unit1=57, unit2=172, unit3=48; total time=   1.4s\n",
      "Epoch 1/1000\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 1159.8516 - val_loss: 1243.2292\n",
      "Epoch 2/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 1130.6664 - val_loss: 1195.1368\n",
      "Epoch 3/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 1091.7031 - val_loss: 1119.4546\n",
      "Epoch 4/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1024.9456 - val_loss: 991.4037\n",
      "Epoch 5/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 907.0552 - val_loss: 787.2843\n",
      "Epoch 6/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 725.6423 - val_loss: 606.8707\n",
      "Epoch 7/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 524.1592 - val_loss: 567.0021\n",
      "Epoch 8/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 443.1483 - val_loss: 504.1957\n",
      "Epoch 9/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 402.2152 - val_loss: 522.7645\n",
      "Epoch 10/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 383.7496 - val_loss: 511.1834\n",
      "Epoch 11/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 308.5709 - val_loss: 454.7954\n",
      "Epoch 12/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 280.5536 - val_loss: 515.7000\n",
      "Epoch 13/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 256.9031 - val_loss: 494.8256\n",
      "Epoch 14/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 233.2955 - val_loss: 502.8335\n",
      "Epoch 15/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 220.6656 - val_loss: 515.5624\n",
      "Epoch 16/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 212.4146 - val_loss: 460.5961\n",
      "Epoch 17/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 200.6349 - val_loss: 474.1392\n",
      "Epoch 18/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 194.5589 - val_loss: 447.7033\n",
      "Epoch 19/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 180.7506 - val_loss: 501.9862\n",
      "Epoch 20/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 157.9512 - val_loss: 475.3951\n",
      "Epoch 21/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 147.3522 - val_loss: 487.0577\n",
      "Epoch 22/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 149.6603 - val_loss: 440.2363\n",
      "Epoch 23/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 175.2888 - val_loss: 583.3912\n",
      "Epoch 24/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 127.5294 - val_loss: 450.9572\n",
      "Epoch 25/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 146.4742 - val_loss: 459.2587\n",
      "Epoch 26/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 122.8135 - val_loss: 450.8967\n",
      "Epoch 27/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 103.6520 - val_loss: 616.0157\n",
      "Epoch 28/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 105.2500 - val_loss: 559.0852\n",
      "Epoch 29/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 100.7880 - val_loss: 620.1898\n",
      "Epoch 30/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 106.9486 - val_loss: 518.7137\n",
      "Epoch 31/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 87.2495 - val_loss: 635.8091\n",
      "Epoch 32/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 81.9958 - val_loss: 541.9888\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 382.1552\n",
      "[CV] END learning_rate=0.00041271597950230996, unit1=57, unit2=172, unit3=48; total time=   1.4s\n",
      "Epoch 1/1000\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 833.3753 - val_loss: 1323.8828\n",
      "Epoch 2/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 959.5477 - val_loss: 1248.1643\n",
      "Epoch 3/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 912.6376 - val_loss: 1156.2334\n",
      "Epoch 4/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 620.5172 - val_loss: 980830.8750\n",
      "Epoch 5/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 3016137847210558531883830819684352.0000 - val_loss: nan\n",
      "Epoch 6/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: nan - val_loss: nan\n",
      "Epoch 7/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: nan - val_loss: nan\n",
      "Epoch 8/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: nan - val_loss: nan\n",
      "Epoch 9/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: nan - val_loss: nan\n",
      "Epoch 11/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: nan - val_loss: nan\n",
      "Epoch 12/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: nan - val_loss: nan\n",
      "Epoch 13/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: nan - val_loss: nan\n",
      "2/2 [==============================] - 0s 10ms/step - loss: nan\n",
      "[CV] END learning_rate=0.009433467964733778, unit1=29, unit2=64, unit3=40; total time=   0.7s\n",
      "Epoch 1/1000\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 1083.0341 - val_loss: 1705.7026\n",
      "Epoch 2/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 11701.5732 - val_loss: 707493.5625\n",
      "Epoch 3/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: inf - val_loss: nan\n",
      "Epoch 4/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: nan - val_loss: nan\n",
      "Epoch 5/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: nan - val_loss: nan\n",
      "Epoch 6/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: nan - val_loss: nan\n",
      "Epoch 7/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: nan - val_loss: nan\n",
      "Epoch 8/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: nan - val_loss: nan\n",
      "Epoch 9/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: nan - val_loss: nan\n",
      "Epoch 11/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: nan - val_loss: nan\n",
      "2/2 [==============================] - 0s 7ms/step - loss: nan\n",
      "[CV] END learning_rate=0.009433467964733778, unit1=29, unit2=64, unit3=40; total time=   0.6s\n",
      "Epoch 1/1000\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 1147.6619 - val_loss: 1331.0493\n",
      "Epoch 2/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 1155.8326 - val_loss: 1191.2644\n",
      "Epoch 3/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 1062.6749 - val_loss: 1854.7679\n",
      "Epoch 4/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 46610.7227 - val_loss: 5833367673110528.0000\n",
      "Epoch 5/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: nan - val_loss: nan\n",
      "Epoch 6/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: nan - val_loss: nan\n",
      "Epoch 7/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: nan - val_loss: nan\n",
      "Epoch 8/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: nan - val_loss: nan\n",
      "Epoch 9/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: nan - val_loss: nan\n",
      "Epoch 11/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: nan - val_loss: nan\n",
      "Epoch 12/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: nan - val_loss: nan\n",
      "2/2 [==============================] - 0s 8ms/step - loss: nan\n",
      "[CV] END learning_rate=0.009433467964733778, unit1=29, unit2=64, unit3=40; total time=   0.7s\n",
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "H:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [          nan -292.8899231            nan -812.90844727 -279.67202759\n",
      "           nan           nan -966.324646   -366.39852905           nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 27ms/step - loss: 1091.6252 - val_loss: 1268.2126\n",
      "Epoch 2/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 1078.0178 - val_loss: 1247.1367\n",
      "Epoch 3/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 1064.6073 - val_loss: 1225.3020\n",
      "Epoch 4/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 1048.5090 - val_loss: 1198.9891\n",
      "Epoch 5/1000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 1029.0660 - val_loss: 1167.2762\n",
      "Epoch 6/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 1005.8030 - val_loss: 1128.5165\n",
      "Epoch 7/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 974.9099 - val_loss: 1079.5249\n",
      "Epoch 8/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 934.2357 - val_loss: 1018.6609\n",
      "Epoch 9/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 879.7979 - val_loss: 942.3195\n",
      "Epoch 10/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 809.3054 - val_loss: 852.5363\n",
      "Epoch 11/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 715.4658 - val_loss: 762.4418\n",
      "Epoch 12/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 609.9792 - val_loss: 695.9117\n",
      "Epoch 13/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 510.2531 - val_loss: 678.5667\n",
      "Epoch 14/1000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 436.9842 - val_loss: 696.3395\n",
      "Epoch 15/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 399.8684 - val_loss: 692.1583\n",
      "Epoch 16/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 376.9720 - val_loss: 680.8671\n",
      "Epoch 17/1000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 356.2216 - val_loss: 692.7255\n",
      "Epoch 18/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 340.5457 - val_loss: 663.7112\n",
      "Epoch 19/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 325.0004 - val_loss: 653.3713\n",
      "Epoch 20/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 308.3821 - val_loss: 633.6329\n",
      "Epoch 21/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 298.3134 - val_loss: 613.6181\n",
      "Epoch 22/1000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 286.2034 - val_loss: 602.5204\n",
      "Epoch 23/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 278.6339 - val_loss: 586.1140\n",
      "Epoch 24/1000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 266.7347 - val_loss: 575.5303\n",
      "Epoch 25/1000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 255.9579 - val_loss: 571.4916\n",
      "Epoch 26/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 256.6717 - val_loss: 550.8534\n",
      "Epoch 27/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 241.0082 - val_loss: 547.3693\n",
      "Epoch 28/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 234.6962 - val_loss: 521.5606\n",
      "Epoch 29/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 229.3014 - val_loss: 520.7531\n",
      "Epoch 30/1000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 219.6448 - val_loss: 504.8585\n",
      "Epoch 31/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 215.1505 - val_loss: 493.9778\n",
      "Epoch 32/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 206.2289 - val_loss: 489.5823\n",
      "Epoch 33/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 201.2122 - val_loss: 482.3214\n",
      "Epoch 34/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 199.1378 - val_loss: 459.8505\n",
      "Epoch 35/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 191.6331 - val_loss: 463.7180\n",
      "Epoch 36/1000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 185.8097 - val_loss: 452.0039\n",
      "Epoch 37/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 182.0816 - val_loss: 443.2458\n",
      "Epoch 38/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 179.3652 - val_loss: 431.7939\n",
      "Epoch 39/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 175.7141 - val_loss: 422.4896\n",
      "Epoch 40/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 172.7500 - val_loss: 416.9379\n",
      "Epoch 41/1000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 167.3701 - val_loss: 414.2777\n",
      "Epoch 42/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 163.9744 - val_loss: 407.4729\n",
      "Epoch 43/1000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 160.5101 - val_loss: 403.0940\n",
      "Epoch 44/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 156.0345 - val_loss: 404.9550\n",
      "Epoch 45/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 153.5349 - val_loss: 398.9622\n",
      "Epoch 46/1000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 149.7080 - val_loss: 390.9305\n",
      "Epoch 47/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 148.1629 - val_loss: 387.2027\n",
      "Epoch 48/1000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 144.8529 - val_loss: 381.7586\n",
      "Epoch 49/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 141.7731 - val_loss: 381.2358\n",
      "Epoch 50/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 140.1566 - val_loss: 374.8267\n",
      "Epoch 51/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 138.3287 - val_loss: 376.8481\n",
      "Epoch 52/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 135.9925 - val_loss: 370.1289\n",
      "Epoch 53/1000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 135.0180 - val_loss: 368.2253\n",
      "Epoch 54/1000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 130.7097 - val_loss: 366.6473\n",
      "Epoch 55/1000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 132.1247 - val_loss: 359.4957\n",
      "Epoch 56/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 127.9810 - val_loss: 357.9503\n",
      "Epoch 57/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 146.209 - 0s 9ms/step - loss: 125.3611 - val_loss: 358.6101\n",
      "Epoch 58/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 124.0150 - val_loss: 356.7822\n",
      "Epoch 59/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 122.1439 - val_loss: 354.8037\n",
      "Epoch 60/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 122.0433 - val_loss: 356.8687\n",
      "Epoch 61/1000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 119.2916 - val_loss: 351.3939\n",
      "Epoch 62/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 118.4333 - val_loss: 350.3702\n",
      "Epoch 63/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 116.5055 - val_loss: 351.2884\n",
      "Epoch 64/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 115.1837 - val_loss: 348.3066\n",
      "Epoch 65/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 113.5330 - val_loss: 344.5689\n",
      "Epoch 66/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 70.40 - 0s 9ms/step - loss: 112.8049 - val_loss: 347.3659\n",
      "Epoch 67/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 111.4231 - val_loss: 347.5276\n",
      "Epoch 68/1000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 110.7254 - val_loss: 341.2714\n",
      "Epoch 69/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 108.4874 - val_loss: 342.6100\n",
      "Epoch 70/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 107.8822 - val_loss: 338.4804\n",
      "Epoch 71/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 106.4373 - val_loss: 340.0367\n",
      "Epoch 72/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 105.7974 - val_loss: 337.1862\n",
      "Epoch 73/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 103.8698 - val_loss: 337.1546\n",
      "Epoch 74/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 103.1988 - val_loss: 336.4803\n",
      "Epoch 75/1000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 103.2850 - val_loss: 333.0715\n",
      "Epoch 76/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 101.9306 - val_loss: 336.2807\n",
      "Epoch 77/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 101.1753 - val_loss: 331.7254\n",
      "Epoch 78/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 100.3414 - val_loss: 331.8943\n",
      "Epoch 79/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 9ms/step - loss: 99.0090 - val_loss: 329.0634\n",
      "Epoch 80/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 98.0810 - val_loss: 328.9858\n",
      "Epoch 81/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 96.3780 - val_loss: 328.1242\n",
      "Epoch 82/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 97.1116 - val_loss: 331.4134\n",
      "Epoch 83/1000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 94.2417 - val_loss: 331.3982\n",
      "Epoch 84/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 94.9246 - val_loss: 331.0997\n",
      "Epoch 85/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 94.7790 - val_loss: 326.2401\n",
      "Epoch 86/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 91.4884 - val_loss: 329.1815\n",
      "Epoch 87/1000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 90.6018 - val_loss: 330.7342\n",
      "Epoch 88/1000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 90.5831 - val_loss: 328.4966\n",
      "Epoch 89/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 88.5527 - val_loss: 331.1874\n",
      "Epoch 90/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 88.3245 - val_loss: 327.7404\n",
      "Epoch 91/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 87.2452 - val_loss: 328.7439\n",
      "Epoch 92/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 87.2537 - val_loss: 328.2814\n",
      "Epoch 93/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 85.6902 - val_loss: 327.7169\n",
      "Epoch 94/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 84.9384 - val_loss: 325.1007\n",
      "Epoch 95/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 84.2707 - val_loss: 326.4725\n",
      "Epoch 96/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 83.8850 - val_loss: 326.3877\n",
      "Epoch 97/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 81.9694 - val_loss: 325.7735\n",
      "Epoch 98/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 80.8427 - val_loss: 324.0168\n",
      "Epoch 99/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 80.2333 - val_loss: 330.1582\n",
      "Epoch 100/1000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 78.9539 - val_loss: 326.0231\n",
      "Epoch 101/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 78.3782 - val_loss: 330.1454\n",
      "Epoch 102/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 77.1911 - val_loss: 325.1333\n",
      "Epoch 103/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 77.2721 - val_loss: 327.6396\n",
      "Epoch 104/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 76.8478 - val_loss: 330.2248\n",
      "Epoch 105/1000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 75.6684 - val_loss: 328.1404\n",
      "Epoch 106/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 74.0662 - val_loss: 324.2707\n",
      "Epoch 107/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 74.2682 - val_loss: 321.9106\n",
      "Epoch 108/1000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 72.2506 - val_loss: 321.9525\n",
      "Epoch 109/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 72.1552 - val_loss: 321.7477\n",
      "Epoch 110/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 72.9521 - val_loss: 320.1080\n",
      "Epoch 111/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 70.7276 - val_loss: 322.7204\n",
      "Epoch 112/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 69.4706 - val_loss: 321.5335\n",
      "Epoch 113/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 68.7523 - val_loss: 326.7104\n",
      "Epoch 114/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 67.6434 - val_loss: 326.6823\n",
      "Epoch 115/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 67.1599 - val_loss: 325.2238\n",
      "Epoch 116/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 67.7642 - val_loss: 326.2643\n",
      "Epoch 117/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 65.5503 - val_loss: 326.6649\n",
      "Epoch 118/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 65.3000 - val_loss: 327.5631\n",
      "Epoch 119/1000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 64.4161 - val_loss: 324.0948\n",
      "Epoch 120/1000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 63.8697 - val_loss: 323.6993\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3,\n",
       "                   estimator=<keras.wrappers.scikit_learn.KerasRegressor object at 0x0000018BE90AAE50>,\n",
       "                   param_distributions={'learning_rate': [0.009471840989813468,\n",
       "                                                          0.0017503230837679227,\n",
       "                                                          0.00015928254033628522,\n",
       "                                                          0.00015822421896988855,\n",
       "                                                          0.003954497409596563,\n",
       "                                                          0.000841881781433461,\n",
       "                                                          0.00017948368318133974,\n",
       "                                                          0.002624826778951884,\n",
       "                                                          0.0013194392339356158,\n",
       "                                                          0.00765168...\n",
       "                                                          0.0018063271080604076,\n",
       "                                                          0.0028257679527462906,\n",
       "                                                          0.007489258416877928, ...],\n",
       "                                        'unit1': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10,\n",
       "                                                  11, 12, 13, 14, 15, 16, 17,\n",
       "                                                  18, 19, 20, 21, 22, 23, 24,\n",
       "                                                  25, 26, 27, 28, 29, 30, ...],\n",
       "                                        'unit2': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10,\n",
       "                                                  11, 12, 13, 14, 15, 16, 17,\n",
       "                                                  18, 19, 20, 21, 22, 23, 24,\n",
       "                                                  25, 26, 27, 28, 29, 30, ...],\n",
       "                                        'unit3': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10,\n",
       "                                                  11, 12, 13, 14, 15, 16, 17,\n",
       "                                                  18, 19, 20, 21, 22, 23, 24,\n",
       "                                                  25, 26, 27, 28, 29, 30, ...]},\n",
       "                   verbose=2)"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import reciprocal\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "param_distribs = {\n",
    "    \"unit1\": np.arange(1,100) .tolist(),\n",
    "    \"unit2\": np.arange(1,200) .tolist(),\n",
    "    \"unit3\": np.arange(1,100) .tolist(),\n",
    "    \"learning_rate\": reciprocal(1e-4, 1e-2)      .rvs(1000).tolist(),\n",
    "}\n",
    "\n",
    "rnd_search_cv = RandomizedSearchCV(keras_reg, param_distribs, n_iter=10,cv=3, verbose=2)\n",
    "rnd_search_cv.fit(X_train, y_train, epochs=1000,\n",
    "                  validation_data=(X_train_full, y_train_full),\n",
    "                  callbacks=[keras.callbacks.EarlyStopping(patience=10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "60013e8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'unit3': 27,\n",
       " 'unit2': 162,\n",
       " 'unit1': 53,\n",
       " 'learning_rate': 0.0001343909963682435}"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "cfab9ece",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-279.6720275878906"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "2269fbf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = rnd_search_cv.best_estimator_.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "61578834",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 59)                3540      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 60        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,600\n",
      "Trainable params: 3,600\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "e3736d4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.69871918, 2.59909495, 0.87065721, 0.93897208, 2.70470794,\n",
       "        0.74808065, 0.76839336, 0.72326859, 1.69416658, 0.69851176]),\n",
       " 'std_fit_time': array([0.05058733, 0.9752382 , 0.18831132, 0.055787  , 0.85454295,\n",
       "        0.08513181, 0.06319922, 0.02660554, 0.34227011, 0.04236706]),\n",
       " 'mean_score_time': array([0.03545086, 0.03558707, 0.035743  , 0.04027438, 0.04008993,\n",
       "        0.04006259, 0.041116  , 0.03890316, 0.03908594, 0.03675469]),\n",
       " 'std_score_time': array([0.00077811, 0.00084424, 0.00125875, 0.00415359, 0.00156481,\n",
       "        0.00191007, 0.00134692, 0.00392411, 0.00362176, 0.00127689]),\n",
       " 'param_unit3': masked_array(data=[56, 9, 28, 47, 27, 25, 89, 82, 48, 40],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_unit2': masked_array(data=[196, 61, 166, 12, 162, 182, 195, 21, 172, 64],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_unit1': masked_array(data=[52, 98, 83, 6, 53, 84, 63, 48, 57, 29],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_learning_rate': masked_array(data=[0.008261212966815147, 0.00011860098412735948,\n",
       "                    0.003956638500871096, 0.002223734074383608,\n",
       "                    0.0001343909963682435, 0.007165349974408226,\n",
       "                    0.004605652410721728, 0.002576231704139902,\n",
       "                    0.00041271597950230996, 0.009433467964733778],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'unit3': 56,\n",
       "   'unit2': 196,\n",
       "   'unit1': 52,\n",
       "   'learning_rate': 0.008261212966815147},\n",
       "  {'unit3': 9,\n",
       "   'unit2': 61,\n",
       "   'unit1': 98,\n",
       "   'learning_rate': 0.00011860098412735948},\n",
       "  {'unit3': 28,\n",
       "   'unit2': 166,\n",
       "   'unit1': 83,\n",
       "   'learning_rate': 0.003956638500871096},\n",
       "  {'unit3': 47,\n",
       "   'unit2': 12,\n",
       "   'unit1': 6,\n",
       "   'learning_rate': 0.002223734074383608},\n",
       "  {'unit3': 27,\n",
       "   'unit2': 162,\n",
       "   'unit1': 53,\n",
       "   'learning_rate': 0.0001343909963682435},\n",
       "  {'unit3': 25,\n",
       "   'unit2': 182,\n",
       "   'unit1': 84,\n",
       "   'learning_rate': 0.007165349974408226},\n",
       "  {'unit3': 89,\n",
       "   'unit2': 195,\n",
       "   'unit1': 63,\n",
       "   'learning_rate': 0.004605652410721728},\n",
       "  {'unit3': 82,\n",
       "   'unit2': 21,\n",
       "   'unit1': 48,\n",
       "   'learning_rate': 0.002576231704139902},\n",
       "  {'unit3': 48,\n",
       "   'unit2': 172,\n",
       "   'unit1': 57,\n",
       "   'learning_rate': 0.00041271597950230996},\n",
       "  {'unit3': 40,\n",
       "   'unit2': 64,\n",
       "   'unit1': 29,\n",
       "   'learning_rate': 0.009433467964733778}],\n",
       " 'split0_test_score': array([            nan, -3.15646057e+02, -1.13586414e+03, -7.56135437e+02,\n",
       "        -3.36471985e+02, -7.54525988e+21,             nan, -1.23735889e+03,\n",
       "        -4.41476807e+02,             nan]),\n",
       " 'split1_test_score': array([          nan, -268.96173096,           nan, -912.01318359,\n",
       "        -275.2003479 ,           nan,           nan, -830.0836792 ,\n",
       "        -275.56362915,           nan]),\n",
       " 'split2_test_score': array([          nan, -294.0619812 ,           nan, -770.57672119,\n",
       "        -227.34375   ,           nan,           nan, -831.53137207,\n",
       "        -382.15515137,           nan]),\n",
       " 'mean_test_score': array([          nan, -292.8899231 ,           nan, -812.90844727,\n",
       "        -279.67202759,           nan,           nan, -966.324646  ,\n",
       "        -366.39852905,           nan]),\n",
       " 'std_test_score': array([         nan,  19.07680734,          nan,  70.32519342,\n",
       "         44.66348136,          nan,          nan, 191.65106085,\n",
       "         68.64400424,          nan]),\n",
       " 'rank_test_score': array([ 6,  2,  7,  4,  1,  8,  9,  5,  3, 10])}"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "86201809",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in rnd_search_cv.cv_results_[\"param_learning_rate\"]:\n",
    "    plt.plot(rnd_search_cv.cv_results_[\"\"],rnd_search_cv.cv_results_[\"std_test_score\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "84c130a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "deep_predict = model.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "709e1ea2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8506712651764239"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "r2_score(y_valid,deep_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "410da835",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "140      0.0\n",
       "120     21.0\n",
       "80      30.0\n",
       "95       0.0\n",
       "109     51.0\n",
       "       ...  \n",
       "118      8.0\n",
       "17     104.0\n",
       "104      0.0\n",
       "195      0.0\n",
       "114     30.0\n",
       "Name: FF, Length: 169, dtype: float64"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "6d695f1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 6ms/step - loss: 21.8767\n",
      "1/1 [==============================] - 0s 0s/step - loss: 81.3528\n",
      "1/1 [==============================] - 0s 0s/step - loss: 157.9191\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 47.1743\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 13.8286\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 6.9441\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 5.5979\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 4.1144\n",
      "1/1 [==============================] - 0s 0s/step - loss: 3.9653\n",
      "1/1 [==============================] - 0s 0s/step - loss: 3.2580\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.7685\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 3.1554\n",
      "1/1 [==============================] - 0s 0s/step - loss: 8.4528\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 7.3820\n",
      "1/1 [==============================] - 0s 0s/step - loss: 7.4886\n",
      "1/1 [==============================] - 0s 0s/step - loss: 22.0788\n",
      "1/1 [==============================] - 0s 0s/step - loss: 19.6829\n",
      "1/1 [==============================] - 0s 0s/step - loss: 27.5850\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 26.1668\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 24.5745\n",
      "1/1 [==============================] - 0s 0s/step - loss: 23.0496\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 27.0075\n",
      "1/1 [==============================] - 0s 0s/step - loss: 25.3019\n",
      "1/1 [==============================] - 0s 0s/step - loss: 31.2647\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 31.6582\n",
      "1/1 [==============================] - 0s 0s/step - loss: 30.0295\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 28.6246\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 27.2627\n",
      "1/1 [==============================] - 0s 0s/step - loss: 28.2708\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 26.3779\n",
      "1/1 [==============================] - 0s 0s/step - loss: 24.9166\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 23.6592\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 27.2478\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 25.9616\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 25.8133\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 25.5757\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 27.6713\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 26.4549\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 25.3665\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 302.5700\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 53.2746\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 50.7858\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 49.4544\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 47.9079\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 46.2955\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 143.9357\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 134.2260\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 116.0934\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 102.4393\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 89.8178\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 74.5417\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 57.5689\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 51.9816\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 46.0779\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 42.8370\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 43.9440\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 40.5913\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 45.6118\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 185.7545\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 171.1139\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 168.2652\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 155.8090\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 147.6298\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 189.7763\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 293.3410\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 2405.9517\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 908.7262\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 957.8542\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1038.8053\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 855.7377\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 817.2143\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1921.2986\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 1085.1509\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1418.6825\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1147.2212\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 982.2951\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 839.3991\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 721.4561\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 487.6180\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 398.8039\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 354.8455\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 324.1866\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 290.0740\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 276.8040\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 279.9089\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 258.5142\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 250.8047\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 245.1609\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 234.4025\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 228.2140\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 219.7557\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 212.2826\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 200.8262\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 200.0459\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 199.7856\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 194.7633\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 194.1803\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 455.6065\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 358.4045\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 190.2811\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 281.2959\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 497.3625\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 2036.5094\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 690.2735\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 494.1169\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 427.7382\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 416.4939\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 307.9565\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 219.7809\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 188.0407\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 184.4736\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 201.0799\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 197.3596\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 170.2552\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 168.2236\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 165.2579\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 155.1238\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 155.4194\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 164.7482\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 156.3259\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 152.1620\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step - loss: 144.4920\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 142.2078\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 138.7938\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 146.7408\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 137.9348\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 136.5493\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 130.3613\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 135.7892\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 124.3526\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 129.3826\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 145.0392\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 131.5135\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 144.0502\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 134.4281\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_learning_curves(model, X_train_full, y_train_full)\n",
    "#plt.axis([0, 200, 0, 200])                         # not shown in the book\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "80d0ad85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.2359591e+00],\n",
       "       [1.3632851e+01],\n",
       "       [4.8989056e+01],\n",
       "       [2.1680448e+00],\n",
       "       [1.1528804e+01],\n",
       "       [1.1583439e+01],\n",
       "       [1.3770494e+01],\n",
       "       [4.2734283e+01],\n",
       "       [8.9432365e+01],\n",
       "       [1.5546970e+00],\n",
       "       [2.9836563e+01],\n",
       "       [2.5677956e+01],\n",
       "       [3.1908007e+00],\n",
       "       [3.1953632e+01],\n",
       "       [3.8558395e+00],\n",
       "       [1.4238472e+01],\n",
       "       [1.8821957e+00],\n",
       "       [1.2999111e+01],\n",
       "       [3.4223132e+00],\n",
       "       [5.9464679e+00],\n",
       "       [3.3418465e+00],\n",
       "       [3.2911293e+01],\n",
       "       [2.1162806e+00],\n",
       "       [2.7812593e+00],\n",
       "       [1.5375492e+01],\n",
       "       [4.1285038e+01],\n",
       "       [1.3295522e+00],\n",
       "       [3.8558395e+00],\n",
       "       [8.1520967e+00],\n",
       "       [7.1382355e+01],\n",
       "       [4.2017961e+00],\n",
       "       [6.4948334e+01],\n",
       "       [1.7120163e+00],\n",
       "       [2.1065126e+01],\n",
       "       [3.4329822e+00],\n",
       "       [3.7857018e+01],\n",
       "       [5.3551140e+00],\n",
       "       [1.4600938e+02],\n",
       "       [7.7471939e+01],\n",
       "       [3.5127754e+00],\n",
       "       [5.6931796e+00],\n",
       "       [2.4309900e+01],\n",
       "       [8.1437886e-02]], dtype=float32)"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict = model.predict(X_valid)\n",
    "predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "f1500aa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48       4.0\n",
       "164     16.0\n",
       "213     27.0\n",
       "88       2.0\n",
       "67      24.0\n",
       "81      16.0\n",
       "44      16.0\n",
       "71      64.0\n",
       "156    117.0\n",
       "142      0.0\n",
       "168     16.0\n",
       "224     20.0\n",
       "14       0.0\n",
       "11      45.0\n",
       "136      0.0\n",
       "218     17.0\n",
       "140      0.0\n",
       "157     24.0\n",
       "29       4.0\n",
       "118      8.0\n",
       "186      2.0\n",
       "101     33.0\n",
       "92       0.0\n",
       "201      1.0\n",
       "159     15.0\n",
       "214     37.0\n",
       "103      0.0\n",
       "137      0.0\n",
       "198      2.0\n",
       "107     72.0\n",
       "61       0.0\n",
       "8       64.0\n",
       "208      0.0\n",
       "76       0.0\n",
       "117      0.0\n",
       "1       56.0\n",
       "87       2.0\n",
       "85     145.0\n",
       "56     147.0\n",
       "151      1.0\n",
       "52       8.0\n",
       "220      4.0\n",
       "191      0.0\n",
       "Name: FF, dtype: float64"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "4d9a0ba2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(1)\n",
    "plt.clf()\n",
    "ax=plt.axes(aspect='equal')\n",
    "plt.scatter(y_valid,predict)\n",
    "plt.xlabel('True Values')\n",
    "plt.ylabel('ANN_FF_Predictions')\n",
    "Lims=[0,200]\n",
    "plt.xlim(Lims)\n",
    "plt.ylim(Lims)\n",
    "plt.plot(Lims,Lims)\n",
    "plt.grid(False)\n",
    "    \n",
    "plt.figure(2)\n",
    "plt.clf()\n",
    "plt.hist(predict,bins=30)\n",
    "plt.xlabel('LUT_ANN_Prediction')\n",
    "plt.ylabel('Count')\n",
    "plt.grid(False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33806898",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
