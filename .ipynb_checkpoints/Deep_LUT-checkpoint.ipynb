{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be7433a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tarfile\n",
    "import urllib.request\n",
    "\n",
    "RES_PATH = os.path.join(\"res_datasets\",\"resourceing\")\n",
    "\n",
    "def fetch_resource_data(res_path=RES_PATH):\n",
    "    if not os.path.isdir(res_path):\n",
    "        os.makedirs(res_path)\n",
    "##创建文件夹路径函数\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def plot_learning_curves(model, X, y):\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    train_errors, val_errors = [], []\n",
    "    for m in range(1, len(X_train) + 1):\n",
    "        model.fit(X_train[:m], y_train[:m])\n",
    "        y_train_predict = model.predict(X_train[:m])\n",
    "        y_val_predict = model.predict(X_val)\n",
    "        train_errors.append(mean_squared_error(y_train[:m], y_train_predict))\n",
    "        val_errors.append(mean_squared_error(y_val, y_val_predict))\n",
    "\n",
    "    plt.plot(np.sqrt(train_errors), \"r-\", linewidth=2, label=\"train\")\n",
    "    plt.plot(np.sqrt(val_errors), \"b-\", linewidth=2, label=\"val\")\n",
    "    plt.legend(loc=\"upper right\", fontsize=14)   # not shown in the book\n",
    "    plt.xlabel(\"Training set size\", fontsize=14) # not shown\n",
    "    plt.ylabel(\"RMSE\", fontsize=14)              # not shown\n",
    "    \n",
    "fetch_resource_data() ##调用创建\n",
    "\n",
    "##读取CSV文件\n",
    "import pandas as pd\n",
    "\n",
    "def load_res_data(res_path = RES_PATH,file_name=\"lable.csv\"):\n",
    "    csv_path = os.path.join(RES_PATH,file_name)\n",
    "    return pd.read_csv(csv_path) \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0bfef604",
   "metadata": {},
   "outputs": [],
   "source": [
    "##数据处理\n",
    "resource_origin_data = load_res_data()  #get origin csv data\n",
    "\n",
    "#%matplotlib inline\n",
    "#import matplotlib.pyplot as plt\n",
    "#resource_origin_data.hist(bins=50, figsize=(20,15))\n",
    "#plt.show() #data plot show\n",
    "\n",
    "resource_origin_data_lut = resource_origin_data.dropna(subset = [\"LUT\"])\n",
    "resource_origin_data_lut=resource_origin_data_lut.drop(\"FF\",axis=1)\n",
    "resource_origin_data_lut=resource_origin_data_lut.drop(\"BUFG\",axis=1)\n",
    "resource_origin_data_lut=resource_origin_data_lut.drop(\"IO\",axis=1)\n",
    "resource_origin_data_lut=resource_origin_data_lut.drop(\"ModuleName\",axis=1)\n",
    "resource_origin_data_lut=resource_origin_data_lut.drop(\"PARAMETERVALUE\",axis=1)\n",
    "resource_origin_data_lut=resource_origin_data_lut.drop(\"ModuleInsts\",axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "25d04eab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 212 entries, 0 to 211\n",
      "Data columns (total 60 columns):\n",
      " #   Column                     Non-Null Count  Dtype\n",
      "---  ------                     --------------  -----\n",
      " 0   ARITLSHIFT                 212 non-null    int64\n",
      " 1   ARITLSHIFT_PORT_NUM        212 non-null    int64\n",
      " 2   ARITLSHIFT_PORT_WIDTH      212 non-null    int64\n",
      " 3   ARITLSHIFT_VALUE           212 non-null    int64\n",
      " 4   ARITRSHIFT                 212 non-null    int64\n",
      " 5   ARITRSHIFT_PORT_NUM        212 non-null    int64\n",
      " 6   ARITRSHIFT_PORT_WIDTH      212 non-null    int64\n",
      " 7   ARITRSHIFT_VALUE           212 non-null    int64\n",
      " 8   AlwaysConstructs           212 non-null    int64\n",
      " 9   AssignLHSPortNum           212 non-null    int64\n",
      " 10  AssignLHSWidth             212 non-null    int64\n",
      " 11  AssignRHSPortNum           212 non-null    int64\n",
      " 12  AssignRHSWidth             212 non-null    int64\n",
      " 13  AssignStmts                212 non-null    int64\n",
      " 14  BLOCKINGASSIGN             212 non-null    int64\n",
      " 15  BlockAssign_Left_PortNum   212 non-null    int64\n",
      " 16  BlockAssign_Left_Width     212 non-null    int64\n",
      " 17  BlockAssign_Right_PortNum  212 non-null    int64\n",
      " 18  BlockAssign_Right_Width    212 non-null    int64\n",
      " 19  CASECONDITIONNUM           212 non-null    int64\n",
      " 20  CASECONDITIONWIDTH         212 non-null    int64\n",
      " 21  CASEITEMCONDITIONNUM       212 non-null    int64\n",
      " 22  CASEITEMCONDITIOWIDTH      212 non-null    int64\n",
      " 23  CASEITEMNUM                212 non-null    int64\n",
      " 24  CONDITIONALELSE            212 non-null    int64\n",
      " 25  CONDITIONALIF              212 non-null    int64\n",
      " 26  CONDITIONALIFWIDTH         212 non-null    int64\n",
      " 27  CONDITIONALTHEN            212 non-null    int64\n",
      " 28  FORBLOCK                   212 non-null    int64\n",
      " 29  FORTIMES                   212 non-null    int64\n",
      " 30  FUNCTIONCALL               212 non-null    int64\n",
      " 31  FUNCTIONNUM                212 non-null    int64\n",
      " 32  INDEXMEMRORY               212 non-null    int64\n",
      " 33  INOUT                      212 non-null    int64\n",
      " 34  INOUTWIDTH                 212 non-null    int64\n",
      " 35  INPUT                      212 non-null    int64\n",
      " 36  INPUTWIDTH                 212 non-null    int64\n",
      " 37  MIN                        212 non-null    int64\n",
      " 38  NonBlockLeftWidth          212 non-null    int64\n",
      " 39  NonBlockRightWidth         212 non-null    int64\n",
      " 40  NonBlockingAssign          212 non-null    int64\n",
      " 41  NonBlockingLeftPortNum     212 non-null    int64\n",
      " 42  NonBlockingRightPortNum    212 non-null    int64\n",
      " 43  OUTPUT                     212 non-null    int64\n",
      " 44  OUTPUTWIDTH                212 non-null    int64\n",
      " 45  PARAMETERNUM               212 non-null    int64\n",
      " 46  PLUS                       212 non-null    int64\n",
      " 47  QUESTIONCOLON              212 non-null    int64\n",
      " 48  QUESTIONCOLONELSE          212 non-null    int64\n",
      " 49  QUESTIONCOLONIF            212 non-null    int64\n",
      " 50  QUESTIONCOLONTHEN          212 non-null    int64\n",
      " 51  REDAND                     212 non-null    int64\n",
      " 52  REDAOR                     212 non-null    int64\n",
      " 53  REDXOR                     212 non-null    int64\n",
      " 54  REG                        212 non-null    int64\n",
      " 55  REGWIDTH                   212 non-null    int64\n",
      " 56  UnaryOperator              212 non-null    int64\n",
      " 57  WIRENUM                    212 non-null    int64\n",
      " 58  WIREWIDTH                  212 non-null    int64\n",
      " 59  LUT                        212 non-null    int64\n",
      "dtypes: int64(60)\n",
      "memory usage: 101.0 KB\n"
     ]
    }
   ],
   "source": [
    "#数据信息\n",
    "resource_origin_data_lut.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "81c08573",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ARITLSHIFT</th>\n",
       "      <th>ARITLSHIFT_PORT_NUM</th>\n",
       "      <th>ARITLSHIFT_PORT_WIDTH</th>\n",
       "      <th>ARITLSHIFT_VALUE</th>\n",
       "      <th>ARITRSHIFT</th>\n",
       "      <th>ARITRSHIFT_PORT_NUM</th>\n",
       "      <th>ARITRSHIFT_PORT_WIDTH</th>\n",
       "      <th>ARITRSHIFT_VALUE</th>\n",
       "      <th>AlwaysConstructs</th>\n",
       "      <th>AssignLHSPortNum</th>\n",
       "      <th>...</th>\n",
       "      <th>QUESTIONCOLONTHEN</th>\n",
       "      <th>REDAND</th>\n",
       "      <th>REDAOR</th>\n",
       "      <th>REDXOR</th>\n",
       "      <th>REG</th>\n",
       "      <th>REGWIDTH</th>\n",
       "      <th>UnaryOperator</th>\n",
       "      <th>WIRENUM</th>\n",
       "      <th>WIREWIDTH</th>\n",
       "      <th>LUT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>212.0</td>\n",
       "      <td>212.0</td>\n",
       "      <td>212.0</td>\n",
       "      <td>212.0</td>\n",
       "      <td>212.000000</td>\n",
       "      <td>212.000000</td>\n",
       "      <td>212.000000</td>\n",
       "      <td>212.000000</td>\n",
       "      <td>212.000000</td>\n",
       "      <td>212.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>212.000000</td>\n",
       "      <td>212.000000</td>\n",
       "      <td>212.000000</td>\n",
       "      <td>212.000000</td>\n",
       "      <td>212.000000</td>\n",
       "      <td>212.000000</td>\n",
       "      <td>212.000000</td>\n",
       "      <td>212.000000</td>\n",
       "      <td>212.000000</td>\n",
       "      <td>212.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.113208</td>\n",
       "      <td>0.070755</td>\n",
       "      <td>0.674528</td>\n",
       "      <td>0.386792</td>\n",
       "      <td>2.287736</td>\n",
       "      <td>2.924528</td>\n",
       "      <td>...</td>\n",
       "      <td>0.523585</td>\n",
       "      <td>3.886792</td>\n",
       "      <td>0.495283</td>\n",
       "      <td>0.561321</td>\n",
       "      <td>3.783019</td>\n",
       "      <td>124.339623</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>2.844340</td>\n",
       "      <td>13.976415</td>\n",
       "      <td>32.731132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.758156</td>\n",
       "      <td>0.524014</td>\n",
       "      <td>4.576129</td>\n",
       "      <td>2.801728</td>\n",
       "      <td>3.237406</td>\n",
       "      <td>10.205192</td>\n",
       "      <td>...</td>\n",
       "      <td>2.526525</td>\n",
       "      <td>8.233927</td>\n",
       "      <td>4.434353</td>\n",
       "      <td>4.076405</td>\n",
       "      <td>5.397041</td>\n",
       "      <td>705.919378</td>\n",
       "      <td>2.236863</td>\n",
       "      <td>8.446055</td>\n",
       "      <td>52.403144</td>\n",
       "      <td>85.157887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.750000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>35.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>127.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>8202.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>575.000000</td>\n",
       "      <td>948.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ARITLSHIFT  ARITLSHIFT_PORT_NUM  ARITLSHIFT_PORT_WIDTH  \\\n",
       "count       212.0                212.0                  212.0   \n",
       "mean          0.0                  0.0                    0.0   \n",
       "std           0.0                  0.0                    0.0   \n",
       "min           0.0                  0.0                    0.0   \n",
       "25%           0.0                  0.0                    0.0   \n",
       "50%           0.0                  0.0                    0.0   \n",
       "75%           0.0                  0.0                    0.0   \n",
       "max           0.0                  0.0                    0.0   \n",
       "\n",
       "       ARITLSHIFT_VALUE  ARITRSHIFT  ARITRSHIFT_PORT_NUM  \\\n",
       "count             212.0  212.000000           212.000000   \n",
       "mean                0.0    0.113208             0.070755   \n",
       "std                 0.0    0.758156             0.524014   \n",
       "min                 0.0    0.000000             0.000000   \n",
       "25%                 0.0    0.000000             0.000000   \n",
       "50%                 0.0    0.000000             0.000000   \n",
       "75%                 0.0    0.000000             0.000000   \n",
       "max                 0.0    8.000000             7.000000   \n",
       "\n",
       "       ARITRSHIFT_PORT_WIDTH  ARITRSHIFT_VALUE  AlwaysConstructs  \\\n",
       "count             212.000000        212.000000        212.000000   \n",
       "mean                0.674528          0.386792          2.287736   \n",
       "std                 4.576129          2.801728          3.237406   \n",
       "min                 0.000000          0.000000          0.000000   \n",
       "25%                 0.000000          0.000000          1.000000   \n",
       "50%                 0.000000          0.000000          1.000000   \n",
       "75%                 0.000000          0.000000          2.000000   \n",
       "max                56.000000         28.000000         24.000000   \n",
       "\n",
       "       AssignLHSPortNum  ...  QUESTIONCOLONTHEN      REDAND      REDAOR  \\\n",
       "count        212.000000  ...         212.000000  212.000000  212.000000   \n",
       "mean           2.924528  ...           0.523585    3.886792    0.495283   \n",
       "std           10.205192  ...           2.526525    8.233927    4.434353   \n",
       "min            0.000000  ...           0.000000    0.000000    0.000000   \n",
       "25%            0.000000  ...           0.000000    0.000000    0.000000   \n",
       "50%            1.000000  ...           0.000000    0.500000    0.000000   \n",
       "75%            2.000000  ...           0.000000    4.000000    0.000000   \n",
       "max          127.000000  ...          31.000000   55.000000   62.000000   \n",
       "\n",
       "           REDXOR         REG     REGWIDTH  UnaryOperator     WIRENUM  \\\n",
       "count  212.000000  212.000000   212.000000     212.000000  212.000000   \n",
       "mean     0.561321    3.783019   124.339623       0.250000    2.844340   \n",
       "std      4.076405    5.397041   705.919378       2.236863    8.446055   \n",
       "min      0.000000    0.000000     0.000000       0.000000    0.000000   \n",
       "25%      0.000000    1.000000     1.750000       0.000000    0.000000   \n",
       "50%      0.000000    2.000000     8.000000       0.000000    0.000000   \n",
       "75%      0.000000    4.000000    31.000000       0.000000    1.250000   \n",
       "max     56.000000   32.000000  8202.000000      32.000000   65.000000   \n",
       "\n",
       "        WIREWIDTH         LUT  \n",
       "count  212.000000  212.000000  \n",
       "mean    13.976415   32.731132  \n",
       "std     52.403144   85.157887  \n",
       "min      0.000000    0.000000  \n",
       "25%      0.000000    1.000000  \n",
       "50%      0.000000    8.000000  \n",
       "75%      2.000000   35.250000  \n",
       "max    575.000000  948.000000  \n",
       "\n",
       "[8 rows x 60 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resource_origin_data_lut.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2f73c8ca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LUT                          1.000000\n",
       "CONDITIONALELSE              0.431417\n",
       "NonBlockLeftWidth            0.417203\n",
       "PLUS                         0.399622\n",
       "NonBlockingAssign            0.393835\n",
       "CONDITIONALTHEN              0.392870\n",
       "CONDITIONALIF                0.392870\n",
       "NonBlockingLeftPortNum       0.387136\n",
       "REG                          0.318705\n",
       "AlwaysConstructs             0.276555\n",
       "CONDITIONALIFWIDTH           0.266208\n",
       "REDAND                       0.251582\n",
       "MIN                          0.232235\n",
       "CASEITEMNUM                  0.232026\n",
       "NonBlockRightWidth           0.229791\n",
       "CASECONDITIONNUM             0.214073\n",
       "OUTPUTWIDTH                  0.211457\n",
       "AssignLHSWidth               0.201654\n",
       "INPUTWIDTH                   0.192558\n",
       "CASECONDITIONWIDTH           0.189411\n",
       "AssignRHSWidth               0.180115\n",
       "NonBlockingRightPortNum      0.179107\n",
       "BlockAssign_Left_Width       0.143185\n",
       "ARITRSHIFT_PORT_NUM          0.139558\n",
       "WIREWIDTH                    0.136321\n",
       "BLOCKINGASSIGN               0.133238\n",
       "INPUT                        0.128534\n",
       "ARITRSHIFT                   0.123943\n",
       "ARITRSHIFT_PORT_WIDTH        0.123009\n",
       "WIRENUM                      0.114305\n",
       "BlockAssign_Right_Width      0.114102\n",
       "OUTPUT                       0.109189\n",
       "BlockAssign_Left_PortNum     0.096120\n",
       "ARITRSHIFT_VALUE             0.092706\n",
       "AssignStmts                  0.092402\n",
       "AssignLHSPortNum             0.090951\n",
       "AssignRHSPortNum             0.073878\n",
       "PARAMETERNUM                 0.072880\n",
       "CASEITEMCONDITIONNUM         0.067238\n",
       "INDEXMEMRORY                 0.063462\n",
       "BlockAssign_Right_PortNum    0.062788\n",
       "QUESTIONCOLON                0.060573\n",
       "QUESTIONCOLONELSE            0.060573\n",
       "QUESTIONCOLONIF              0.060573\n",
       "QUESTIONCOLONTHEN            0.060573\n",
       "CASEITEMCONDITIOWIDTH        0.031240\n",
       "REGWIDTH                     0.026338\n",
       "INOUTWIDTH                   0.024424\n",
       "REDAOR                       0.011938\n",
       "FUNCTIONCALL                 0.011406\n",
       "UnaryOperator                0.011401\n",
       "FORTIMES                    -0.000455\n",
       "FORBLOCK                    -0.006157\n",
       "REDXOR                      -0.018117\n",
       "FUNCTIONNUM                 -0.018206\n",
       "ARITLSHIFT                        NaN\n",
       "ARITLSHIFT_PORT_NUM               NaN\n",
       "ARITLSHIFT_PORT_WIDTH             NaN\n",
       "ARITLSHIFT_VALUE                  NaN\n",
       "INOUT                             NaN\n",
       "Name: LUT, dtype: float64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#相关性分析\n",
    "corr_matrix=resource_origin_data_lut.corr()\n",
    "corr_matrix[\"LUT\"].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2fd8d5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#特征优化\n",
    "resource_lut = resource_origin_data_lut[\"LUT\"].copy() #label data\n",
    "resource_lut_data = resource_origin_data_lut.drop(\"LUT\",axis=1) #feature data\n",
    "resource_label = list(resource_lut_data) #labal list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f8e7acfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#数据分割\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "#训练集、测试集、验证集\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(resource_lut_data, resource_lut, test_size=0.2,random_state=42)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7eecddc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#数据标准化\n",
    "scaler = MinMaxScaler() \n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_valid = scaler.transform(X_valid)\n",
    "X_test = scaler.transform(X_test)\n",
    "X_train_full = scaler.transform(X_train_full)\n",
    "X_data_full = scaler.transform(resource_lut_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cf04fcac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#深度学习\n",
    "\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ebc9345f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(126, 59)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aba9a350",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "input_ = keras.layers.Input(shape=X_train.shape[1:])\n",
    "hidden1 = keras.layers.Dense(59, activation=\"relu\")(input_)\n",
    "#hidden2 = keras.layers.Dense(150, activation=\"relu\")(hidden1)\n",
    "concat = keras.layers.concatenate([input_, hidden1])\n",
    "output = keras.layers.Dense(1)(concat)\n",
    "model = keras.models.Model(inputs=[input_], outputs=[output])\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(monitor='val_loss',patience=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "252b1313",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Input(shape=X_train.shape[1:]),\n",
    "    keras.layers.Dense(59, activation=\"relu\"),\n",
    "    keras.layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "473c9348",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Input(shape=X_train.shape[1:]),\n",
    "    keras.layers.Dense(59, activation=\"relu\"),\n",
    "    keras.layers.Dense(96, activation=\"relu\"),\n",
    "    keras.layers.Dense(110, activation=\"relu\"),\n",
    "    keras.layers.Dense(58, activation=\"relu\"),\n",
    "    keras.layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "eae277e4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 8137.1504 - val_loss: 23236.0371\n",
      "Epoch 2/500\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 8012.9854 - val_loss: 22937.0410\n",
      "Epoch 3/500\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 7746.0430 - val_loss: 22004.7148\n",
      "Epoch 4/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 7105.5356 - val_loss: 20826.2480\n",
      "Epoch 5/500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 6498.2656 - val_loss: 20042.3887\n",
      "Epoch 6/500\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 6242.7358 - val_loss: 19117.8438\n",
      "Epoch 7/500\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 5983.1577 - val_loss: 18923.2559\n",
      "Epoch 8/500\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 5933.8682 - val_loss: 18251.3047\n",
      "Epoch 9/500\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 6035.7070 - val_loss: 17899.5371\n",
      "Epoch 10/500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 5965.9536 - val_loss: 18090.0859\n",
      "Epoch 11/500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 5635.1289 - val_loss: 18370.0430\n",
      "Epoch 12/500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 5631.2793 - val_loss: 18116.1621\n",
      "Epoch 13/500\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 5517.1074 - val_loss: 18102.9199\n",
      "Epoch 14/500\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 5461.3315 - val_loss: 17824.3047\n",
      "Epoch 15/500\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 5412.6289 - val_loss: 17599.7754\n",
      "Epoch 16/500\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 5354.4507 - val_loss: 17715.4043\n",
      "Epoch 17/500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 5331.1772 - val_loss: 17518.3301\n",
      "Epoch 18/500\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 5257.9619 - val_loss: 17561.2695\n",
      "Epoch 19/500\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 5237.0820 - val_loss: 17309.5039\n",
      "Epoch 20/500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 5285.4771 - val_loss: 17696.4570\n",
      "Epoch 21/500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 5258.2354 - val_loss: 17461.4570\n",
      "Epoch 22/500\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 5180.6973 - val_loss: 16573.8477\n",
      "Epoch 23/500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 5642.0063 - val_loss: 16793.4219\n",
      "Epoch 24/500\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 5115.2153 - val_loss: 17075.4512\n",
      "Epoch 25/500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 5133.2798 - val_loss: 17492.9922\n",
      "Epoch 26/500\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 5093.6260 - val_loss: 17085.3730\n",
      "Epoch 27/500\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 5098.3545 - val_loss: 17087.3594\n",
      "Epoch 28/500\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 5009.2358 - val_loss: 16407.8672\n",
      "Epoch 29/500\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 4979.7275 - val_loss: 16785.3066\n",
      "Epoch 30/500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 4963.4956 - val_loss: 16362.2383\n",
      "Epoch 31/500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4986.3999 - val_loss: 16725.6172\n",
      "Epoch 32/500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4962.0288 - val_loss: 16596.7871\n",
      "Epoch 33/500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4902.7935 - val_loss: 16465.6777\n",
      "Epoch 34/500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4899.1006 - val_loss: 16683.4297\n",
      "Epoch 35/500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4993.7568 - val_loss: 16254.6572\n",
      "Epoch 36/500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4919.2993 - val_loss: 16679.3770\n",
      "Epoch 37/500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4845.0225 - val_loss: 16255.1465\n",
      "Epoch 38/500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4836.5605 - val_loss: 16463.8516\n",
      "Epoch 39/500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4876.5342 - val_loss: 16474.8945\n",
      "Epoch 40/500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 4864.4980 - val_loss: 16628.3438\n",
      "Epoch 41/500\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 4874.2500 - val_loss: 16555.9004\n",
      "Epoch 42/500\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 4823.4976 - val_loss: 16444.0684\n",
      "Epoch 43/500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 4853.9004 - val_loss: 16756.8379\n",
      "Epoch 44/500\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 4792.1196 - val_loss: 16848.1289\n",
      "Epoch 45/500\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 4748.0107 - val_loss: 16147.5527\n",
      "Epoch 46/500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4792.4668 - val_loss: 16508.7617\n",
      "Epoch 47/500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4793.8262 - val_loss: 16097.0625\n",
      "Epoch 48/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 4805.9214 - val_loss: 16019.1963\n",
      "Epoch 49/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 4807.5381 - val_loss: 16551.2324\n",
      "Epoch 50/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 4719.8242 - val_loss: 16315.1465\n",
      "Epoch 51/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 4690.3765 - val_loss: 17110.7832\n",
      "Epoch 52/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 4800.1562 - val_loss: 16326.2881\n",
      "Epoch 53/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 4702.5327 - val_loss: 16109.2324\n",
      "Epoch 54/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 4783.4263 - val_loss: 16579.3125\n",
      "Epoch 55/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 4663.4634 - val_loss: 15783.8037\n",
      "Epoch 56/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 4719.7529 - val_loss: 16039.5752\n",
      "Epoch 57/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 4720.8555 - val_loss: 16105.5977\n",
      "Epoch 58/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 4686.5151 - val_loss: 16200.5010\n",
      "Epoch 59/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 4689.6440 - val_loss: 15712.3389\n",
      "Epoch 60/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 5468.4165 - val_loss: 15490.8867\n",
      "Epoch 61/500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4743.1304 - val_loss: 15057.6914\n",
      "Epoch 62/500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4745.9263 - val_loss: 15805.5898\n",
      "Epoch 63/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 4760.3472 - val_loss: 16028.0986\n",
      "Epoch 64/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 4629.3403 - val_loss: 15630.4590\n",
      "Epoch 65/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 4570.1104 - val_loss: 15493.2383\n",
      "Epoch 66/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 4631.0142 - val_loss: 15431.8691\n",
      "Epoch 67/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 4478.4995 - val_loss: 15415.3721\n",
      "Epoch 68/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 4539.0176 - val_loss: 14956.7021\n",
      "Epoch 69/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 4622.0298 - val_loss: 15174.7373\n",
      "Epoch 70/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 4562.3174 - val_loss: 16054.6455\n",
      "Epoch 71/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 4465.5620 - val_loss: 15193.7539\n",
      "Epoch 72/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 4522.8218 - val_loss: 15018.7510\n",
      "Epoch 73/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 4501.4189 - val_loss: 16373.7715\n",
      "Epoch 74/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 4610.5781 - val_loss: 15678.6514\n",
      "Epoch 75/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 4487.4473 - val_loss: 15445.8330\n",
      "Epoch 76/500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4529.8301 - val_loss: 15471.3184\n",
      "Epoch 77/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 4385.1426 - val_loss: 15190.0928\n",
      "Epoch 78/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 4438.5879 - val_loss: 15769.8428\n",
      "Epoch 79/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 5ms/step - loss: 4475.1436 - val_loss: 15039.3457\n",
      "Epoch 80/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 4469.4731 - val_loss: 15222.3633\n",
      "Epoch 81/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 4387.4722 - val_loss: 15159.8330\n",
      "Epoch 82/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 4376.0923 - val_loss: 15051.3008\n",
      "Epoch 83/500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4355.6201 - val_loss: 14851.7773\n",
      "Epoch 84/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 4379.4097 - val_loss: 15079.7266\n",
      "Epoch 85/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 4331.8379 - val_loss: 15687.1807\n",
      "Epoch 86/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 4430.4463 - val_loss: 14964.9521\n",
      "Epoch 87/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 4270.4434 - val_loss: 14285.6250\n",
      "Epoch 88/500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4191.8018 - val_loss: 14963.0059\n",
      "Epoch 89/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 4288.6987 - val_loss: 15024.6523\n",
      "Epoch 90/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 4300.9951 - val_loss: 14551.7686\n",
      "Epoch 91/500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4297.2578 - val_loss: 14562.7461\n",
      "Epoch 92/500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4204.7378 - val_loss: 14928.0889\n",
      "Epoch 93/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 4198.3359 - val_loss: 14623.5869\n",
      "Epoch 94/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 4165.8276 - val_loss: 14152.5986\n",
      "Epoch 95/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 4281.2466 - val_loss: 14544.1289\n",
      "Epoch 96/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 4188.7012 - val_loss: 13908.8369\n",
      "Epoch 97/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 4163.2354 - val_loss: 14312.0303\n",
      "Epoch 98/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 4074.4822 - val_loss: 13740.2979\n",
      "Epoch 99/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 4087.9897 - val_loss: 13291.6406\n",
      "Epoch 100/500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4132.4829 - val_loss: 13223.8037\n",
      "Epoch 101/500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4070.8032 - val_loss: 14130.5684\n",
      "Epoch 102/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 4056.2917 - val_loss: 14161.7588\n",
      "Epoch 103/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 3947.8755 - val_loss: 13132.0928\n",
      "Epoch 104/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 4062.8577 - val_loss: 14305.3984\n",
      "Epoch 105/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 5750.5161 - val_loss: 13279.2861\n",
      "Epoch 106/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 4039.7671 - val_loss: 13687.7617\n",
      "Epoch 107/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 3872.6086 - val_loss: 12928.5381\n",
      "Epoch 108/500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3828.6543 - val_loss: 14229.0469\n",
      "Epoch 109/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 4015.9023 - val_loss: 13513.7852\n",
      "Epoch 110/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 3878.9128 - val_loss: 13443.6455\n",
      "Epoch 111/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 3861.6055 - val_loss: 13894.0684\n",
      "Epoch 112/500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3951.6162 - val_loss: 13078.5088\n",
      "Epoch 113/500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3761.0415 - val_loss: 13560.5615\n",
      "Epoch 114/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 3782.3899 - val_loss: 12720.2285\n",
      "Epoch 115/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 3731.1179 - val_loss: 12637.4795\n",
      "Epoch 116/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 3722.9600 - val_loss: 12723.6260\n",
      "Epoch 117/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 3825.6392 - val_loss: 13181.4580\n",
      "Epoch 118/500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3767.7629 - val_loss: 12666.2998\n",
      "Epoch 119/500\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 3653.9524 - val_loss: 12740.9961\n",
      "Epoch 120/500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3634.3765 - val_loss: 13516.7236\n",
      "Epoch 121/500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 5216.9185 - val_loss: 11463.2275\n",
      "Epoch 122/500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3611.1895 - val_loss: 11641.0537\n",
      "Epoch 123/500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3566.0117 - val_loss: 11690.8145\n",
      "Epoch 124/500\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 3498.4272 - val_loss: 12349.9551\n",
      "Epoch 125/500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3448.9690 - val_loss: 11446.3096\n",
      "Epoch 126/500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3349.8491 - val_loss: 10658.4424\n",
      "Epoch 127/500\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 3580.1255 - val_loss: 11785.3340\n",
      "Epoch 128/500\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 3361.9749 - val_loss: 10321.9590\n",
      "Epoch 129/500\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 3304.4302 - val_loss: 11989.8369\n",
      "Epoch 130/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 3417.9934 - val_loss: 11475.6016\n",
      "Epoch 131/500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3355.7329 - val_loss: 11105.0303\n",
      "Epoch 132/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 3310.7839 - val_loss: 11130.7627\n",
      "Epoch 133/500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3296.4907 - val_loss: 10363.8584\n",
      "Epoch 134/500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3322.8635 - val_loss: 10615.8730\n",
      "Epoch 135/500\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 3080.0039 - val_loss: 9581.1523\n",
      "Epoch 136/500\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 3275.2300 - val_loss: 10930.6719\n",
      "Epoch 137/500\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 3094.5444 - val_loss: 9710.6465\n",
      "Epoch 138/500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3122.9805 - val_loss: 10009.8086\n",
      "Epoch 139/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 3102.1399 - val_loss: 10022.1211\n",
      "Epoch 140/500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3054.6094 - val_loss: 12203.4883\n",
      "Epoch 141/500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3299.1597 - val_loss: 9653.5410\n",
      "Epoch 142/500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3078.9829 - val_loss: 9172.2168\n",
      "Epoch 143/500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2945.2175 - val_loss: 10610.8281\n",
      "Epoch 144/500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3021.5767 - val_loss: 9710.1787\n",
      "Epoch 145/500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2921.5276 - val_loss: 9776.5859\n",
      "Epoch 146/500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2888.2009 - val_loss: 9413.7412\n",
      "Epoch 147/500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2903.9888 - val_loss: 10266.0352\n",
      "Epoch 148/500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2875.3303 - val_loss: 8802.7139\n",
      "Epoch 149/500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2843.8738 - val_loss: 9301.7568\n",
      "Epoch 150/500\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 2783.5652 - val_loss: 8446.9570\n",
      "Epoch 151/500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2753.6667 - val_loss: 9793.4277\n",
      "Epoch 152/500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2733.7930 - val_loss: 8882.7568\n",
      "Epoch 153/500\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 2622.5974 - val_loss: 7476.3315\n",
      "Epoch 154/500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2681.2427 - val_loss: 7112.6294\n",
      "Epoch 155/500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2631.6147 - val_loss: 9196.2656\n",
      "Epoch 156/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 2558.8816 - val_loss: 7768.5220\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 157/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 2374.4736 - val_loss: 6924.5234\n",
      "Epoch 158/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 2222.7161 - val_loss: 7728.8955\n",
      "Epoch 159/500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2415.2625 - val_loss: 7303.4736\n",
      "Epoch 160/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 2461.2144 - val_loss: 8564.6191\n",
      "Epoch 161/500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2531.8857 - val_loss: 7536.6328\n",
      "Epoch 162/500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2571.5125 - val_loss: 7199.6401\n",
      "Epoch 163/500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2435.3833 - val_loss: 6670.2949\n",
      "Epoch 164/500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2217.6887 - val_loss: 6883.0151\n",
      "Epoch 165/500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2135.2578 - val_loss: 6803.2832\n",
      "Epoch 166/500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2065.7778 - val_loss: 5861.3433\n",
      "Epoch 167/500\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 2241.1917 - val_loss: 7407.4136\n",
      "Epoch 168/500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2136.6262 - val_loss: 6195.4497\n",
      "Epoch 169/500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2257.8271 - val_loss: 6231.9878\n",
      "Epoch 170/500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2157.9753 - val_loss: 7788.5903\n",
      "Epoch 171/500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2518.7886 - val_loss: 6185.5488\n",
      "Epoch 172/500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1943.6617 - val_loss: 6091.7075\n",
      "Epoch 173/500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2129.0625 - val_loss: 7378.6577\n",
      "Epoch 174/500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2259.2593 - val_loss: 5877.3335\n",
      "Epoch 175/500\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 1811.1975 - val_loss: 12676.2510\n",
      "Epoch 176/500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 7889.6753 - val_loss: 6130.8232\n",
      "Epoch 177/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 2000.7990 - val_loss: 6068.7236\n",
      "Epoch 178/500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1810.8190 - val_loss: 9579.8135\n",
      "Epoch 179/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 2362.3809 - val_loss: 5381.4390\n",
      "Epoch 180/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1733.1163 - val_loss: 4597.8550\n",
      "Epoch 181/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1575.6060 - val_loss: 4573.4980\n",
      "Epoch 182/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1646.7075 - val_loss: 4668.5669\n",
      "Epoch 183/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1651.2155 - val_loss: 4802.9009\n",
      "Epoch 184/500\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 1582.3748 - val_loss: 4179.4355\n",
      "Epoch 185/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1516.3403 - val_loss: 4677.1089\n",
      "Epoch 186/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1591.2069 - val_loss: 4270.1411\n",
      "Epoch 187/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1500.6383 - val_loss: 4120.4277\n",
      "Epoch 188/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1245.2819 - val_loss: 3368.9790\n",
      "Epoch 189/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1226.0745 - val_loss: 4440.3218\n",
      "Epoch 190/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1412.4633 - val_loss: 3921.7646\n",
      "Epoch 191/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1327.6215 - val_loss: 3543.4866\n",
      "Epoch 192/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1142.9655 - val_loss: 3010.6438\n",
      "Epoch 193/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1277.7235 - val_loss: 3387.8064\n",
      "Epoch 194/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1257.6573 - val_loss: 4561.0435\n",
      "Epoch 195/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1344.8397 - val_loss: 8366.7090\n",
      "Epoch 196/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 2699.8662 - val_loss: 2548.6326\n",
      "Epoch 197/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1248.1542 - val_loss: 2569.0876\n",
      "Epoch 198/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1027.4686 - val_loss: 2538.2666\n",
      "Epoch 199/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 986.2756 - val_loss: 3415.6958\n",
      "Epoch 200/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1203.1686 - val_loss: 2632.9272\n",
      "Epoch 201/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 980.0794 - val_loss: 2674.5500\n",
      "Epoch 202/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 968.3990 - val_loss: 2541.8220\n",
      "Epoch 203/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 925.8543 - val_loss: 2719.9873\n",
      "Epoch 204/500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1077.8040 - val_loss: 2204.5737\n",
      "Epoch 205/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 879.7598 - val_loss: 2575.0876\n",
      "Epoch 206/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 951.6941 - val_loss: 2088.9968\n",
      "Epoch 207/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1094.3665 - val_loss: 3506.4775\n",
      "Epoch 208/500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1022.1190 - val_loss: 1885.1272\n",
      "Epoch 209/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1005.1638 - val_loss: 2972.2964\n",
      "Epoch 210/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 954.0129 - val_loss: 1797.6879\n",
      "Epoch 211/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 982.2950 - val_loss: 2609.5413\n",
      "Epoch 212/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 885.4048 - val_loss: 9150.0410\n",
      "Epoch 213/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 4314.7812 - val_loss: 3218.1162\n",
      "Epoch 214/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1021.1778 - val_loss: 1933.7988\n",
      "Epoch 215/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 832.3818 - val_loss: 1639.9531\n",
      "Epoch 216/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 684.0355 - val_loss: 1750.2913\n",
      "Epoch 217/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 744.0488 - val_loss: 3778.4993\n",
      "Epoch 218/500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2152.9089 - val_loss: 3591.2979\n",
      "Epoch 219/500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1164.1102 - val_loss: 1630.9728\n",
      "Epoch 220/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 701.2618 - val_loss: 1223.0548\n",
      "Epoch 221/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 650.5691 - val_loss: 1557.9991\n",
      "Epoch 222/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 678.2836 - val_loss: 1150.9688\n",
      "Epoch 223/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 557.5865 - val_loss: 1321.2806\n",
      "Epoch 224/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 630.7578 - val_loss: 1088.7168\n",
      "Epoch 225/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 569.5834 - val_loss: 1269.8176\n",
      "Epoch 226/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 615.4651 - val_loss: 1034.3479\n",
      "Epoch 227/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 654.2695 - val_loss: 2686.0842\n",
      "Epoch 228/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 828.0239 - val_loss: 1180.3810\n",
      "Epoch 229/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 579.1030 - val_loss: 1937.7329\n",
      "Epoch 230/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 708.6199 - val_loss: 1297.2839\n",
      "Epoch 231/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 521.9437 - val_loss: 933.3895\n",
      "Epoch 232/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 495.1410 - val_loss: 918.0111\n",
      "Epoch 233/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 470.9337 - val_loss: 1019.0437\n",
      "Epoch 234/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 533.1598 - val_loss: 975.9779\n",
      "Epoch 235/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 5ms/step - loss: 510.9946 - val_loss: 836.1266\n",
      "Epoch 236/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 407.7024 - val_loss: 876.6826\n",
      "Epoch 237/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 400.4362 - val_loss: 875.5418\n",
      "Epoch 238/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 476.2268 - val_loss: 769.2066\n",
      "Epoch 239/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 521.9835 - val_loss: 742.3177\n",
      "Epoch 240/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 529.1661 - val_loss: 740.2271\n",
      "Epoch 241/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 392.6004 - val_loss: 711.2254\n",
      "Epoch 242/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 364.1015 - val_loss: 769.5919\n",
      "Epoch 243/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 445.4178 - val_loss: 668.5364\n",
      "Epoch 244/500\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 361.5025 - val_loss: 776.2613\n",
      "Epoch 245/500\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 410.0122 - val_loss: 760.9380\n",
      "Epoch 246/500\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 369.2437 - val_loss: 623.5679\n",
      "Epoch 247/500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 332.3994 - val_loss: 611.4830\n",
      "Epoch 248/500\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 351.5919 - val_loss: 618.1879\n",
      "Epoch 249/500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 370.0768 - val_loss: 717.4296\n",
      "Epoch 250/500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 372.1404 - val_loss: 593.8791\n",
      "Epoch 251/500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 353.4745 - val_loss: 546.3783\n",
      "Epoch 252/500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 357.9870 - val_loss: 533.6550\n",
      "Epoch 253/500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 360.6172 - val_loss: 1441.7839\n",
      "Epoch 254/500\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 588.9166 - val_loss: 526.9800\n",
      "Epoch 255/500\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 306.6760 - val_loss: 481.6671\n",
      "Epoch 256/500\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 285.5062 - val_loss: 511.8052\n",
      "Epoch 257/500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 300.6906 - val_loss: 551.0413\n",
      "Epoch 258/500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 287.7335 - val_loss: 659.1410\n",
      "Epoch 259/500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 305.1379 - val_loss: 438.0198\n",
      "Epoch 260/500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 288.2017 - val_loss: 488.1505\n",
      "Epoch 261/500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 294.3484 - val_loss: 522.5926\n",
      "Epoch 262/500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 275.7345 - val_loss: 412.2747\n",
      "Epoch 263/500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 311.7796 - val_loss: 402.1621\n",
      "Epoch 264/500\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 297.7501 - val_loss: 402.2330\n",
      "Epoch 265/500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 262.4125 - val_loss: 449.7122\n",
      "Epoch 266/500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 258.7063 - val_loss: 381.7029\n",
      "Epoch 267/500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 271.0838 - val_loss: 400.6838\n",
      "Epoch 268/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 248.3959 - val_loss: 392.7802\n",
      "Epoch 269/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 282.4854 - val_loss: 455.1960\n",
      "Epoch 270/500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 261.2307 - val_loss: 360.6561\n",
      "Epoch 271/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 268.1308 - val_loss: 682.7483\n",
      "Epoch 272/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 306.4232 - val_loss: 471.2119\n",
      "Epoch 273/500\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 256.9110 - val_loss: 366.9976\n",
      "Epoch 274/500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 242.2049 - val_loss: 396.1607\n",
      "Epoch 275/500\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 233.9969 - val_loss: 350.0322\n",
      "Epoch 276/500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 228.8420 - val_loss: 353.3311\n",
      "Epoch 277/500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 237.8619 - val_loss: 670.9186\n",
      "Epoch 278/500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 267.7912 - val_loss: 344.0925\n",
      "Epoch 279/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 227.1668 - val_loss: 333.9810\n",
      "Epoch 280/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 234.7417 - val_loss: 338.2709\n",
      "Epoch 281/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 221.7185 - val_loss: 315.5401\n",
      "Epoch 282/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 222.9712 - val_loss: 319.0194\n",
      "Epoch 283/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 220.1198 - val_loss: 404.2984\n",
      "Epoch 284/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 234.4700 - val_loss: 323.3383\n",
      "Epoch 285/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 216.9995 - val_loss: 513.3715\n",
      "Epoch 286/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 264.4785 - val_loss: 304.6573\n",
      "Epoch 287/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 207.5923 - val_loss: 299.5840\n",
      "Epoch 288/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 217.9594 - val_loss: 311.2553\n",
      "Epoch 289/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 210.8865 - val_loss: 302.0511\n",
      "Epoch 290/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 206.6155 - val_loss: 298.0468\n",
      "Epoch 291/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 201.6128 - val_loss: 300.0579\n",
      "Epoch 292/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 202.6810 - val_loss: 291.0167\n",
      "Epoch 293/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 203.2173 - val_loss: 297.5385\n",
      "Epoch 294/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 202.3093 - val_loss: 284.5223\n",
      "Epoch 295/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 198.2888 - val_loss: 302.2970\n",
      "Epoch 296/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 199.8625 - val_loss: 288.3503\n",
      "Epoch 297/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 201.4981 - val_loss: 288.1732\n",
      "Epoch 298/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 199.8822 - val_loss: 369.1183\n",
      "Epoch 299/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 212.8188 - val_loss: 384.4126\n",
      "Epoch 300/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 214.9585 - val_loss: 307.1859\n",
      "Epoch 301/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 205.3240 - val_loss: 287.5353\n",
      "Epoch 302/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 195.4446 - val_loss: 283.5391\n",
      "Epoch 303/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 193.7981 - val_loss: 275.3118\n",
      "Epoch 304/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 195.4674 - val_loss: 286.4937\n",
      "Epoch 305/500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 192.7132 - val_loss: 273.4361\n",
      "Epoch 306/500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 193.3784 - val_loss: 291.5262\n",
      "Epoch 307/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 192.6796 - val_loss: 276.8822\n",
      "Epoch 308/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 189.8806 - val_loss: 264.8750\n",
      "Epoch 309/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 196.0138 - val_loss: 275.5698\n",
      "Epoch 310/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 192.2525 - val_loss: 445.5981\n",
      "Epoch 311/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 232.3411 - val_loss: 295.1279\n",
      "Epoch 312/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 194.1334 - val_loss: 271.2570\n",
      "Epoch 313/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 188.2939 - val_loss: 267.2131\n",
      "Epoch 314/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 5ms/step - loss: 186.7029 - val_loss: 259.6268\n",
      "Epoch 315/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 189.6806 - val_loss: 270.3767\n",
      "Epoch 316/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 188.6382 - val_loss: 260.3792\n",
      "Epoch 317/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 186.4578 - val_loss: 271.8594\n",
      "Epoch 318/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 188.3960 - val_loss: 257.4107\n",
      "Epoch 319/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 187.1796 - val_loss: 259.9650\n",
      "Epoch 320/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 185.3867 - val_loss: 278.6070\n",
      "Epoch 321/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 190.6512 - val_loss: 277.9066\n",
      "Epoch 322/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 185.6763 - val_loss: 269.0022\n",
      "Epoch 323/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 183.8733 - val_loss: 253.9431\n",
      "Epoch 324/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 183.0514 - val_loss: 254.2222\n",
      "Epoch 325/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 183.8174 - val_loss: 253.9381\n",
      "Epoch 326/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 182.6255 - val_loss: 258.9479\n",
      "Epoch 327/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 183.0436 - val_loss: 267.9499\n",
      "Epoch 328/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 182.6847 - val_loss: 255.9192\n",
      "Epoch 329/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 180.5157 - val_loss: 278.7465\n",
      "Epoch 330/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 184.8974 - val_loss: 295.4933\n",
      "Epoch 331/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 187.6212 - val_loss: 260.9038\n",
      "Epoch 332/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 181.5152 - val_loss: 254.0176\n",
      "Epoch 333/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 183.4182 - val_loss: 262.2402\n",
      "Epoch 334/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 180.3625 - val_loss: 246.4571\n",
      "Epoch 335/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 180.7531 - val_loss: 249.1024\n",
      "Epoch 336/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 180.4737 - val_loss: 259.2845\n",
      "Epoch 337/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 182.8231 - val_loss: 247.7708\n",
      "Epoch 338/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 177.8444 - val_loss: 260.1909\n",
      "Epoch 339/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 180.0439 - val_loss: 245.0374\n",
      "Epoch 340/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 179.1876 - val_loss: 253.8610\n",
      "Epoch 341/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 179.1357 - val_loss: 259.3216\n",
      "Epoch 342/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 178.2236 - val_loss: 247.4528\n",
      "Epoch 343/500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 178.3837 - val_loss: 242.1721\n",
      "Epoch 344/500\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 178.1153 - val_loss: 251.6062\n",
      "Epoch 345/500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 176.6877 - val_loss: 244.8122\n",
      "Epoch 346/500\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 178.7374 - val_loss: 246.4072\n",
      "Epoch 347/500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 175.5572 - val_loss: 252.3969\n",
      "Epoch 348/500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 176.7140 - val_loss: 242.8109\n",
      "Epoch 349/500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 178.0410 - val_loss: 239.5321\n",
      "Epoch 350/500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 175.9872 - val_loss: 265.6951\n",
      "Epoch 351/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 179.0781 - val_loss: 252.0309\n",
      "Epoch 352/500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 176.5391 - val_loss: 251.3146\n",
      "Epoch 353/500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 176.1004 - val_loss: 243.3486\n",
      "Epoch 354/500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 175.1423 - val_loss: 255.2194\n",
      "Epoch 355/500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 177.6106 - val_loss: 257.9767\n",
      "Epoch 356/500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 175.4308 - val_loss: 250.5251\n",
      "Epoch 357/500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 174.5544 - val_loss: 250.0603\n",
      "Epoch 358/500\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 176.1027 - val_loss: 248.7085\n",
      "Epoch 359/500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 175.2038 - val_loss: 248.2457\n",
      "Epoch 360/500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 173.4685 - val_loss: 245.2507\n",
      "Epoch 361/500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 174.0120 - val_loss: 249.1765\n",
      "Epoch 362/500\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 174.7594 - val_loss: 245.8776\n",
      "Epoch 363/500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 174.0074 - val_loss: 250.0610\n",
      "Epoch 364/500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 177.1436 - val_loss: 242.6172\n",
      "Epoch 365/500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 178.6928 - val_loss: 248.6000\n",
      "Epoch 366/500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 173.4529 - val_loss: 239.1470\n",
      "Epoch 367/500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 174.0797 - val_loss: 247.5395\n",
      "Epoch 368/500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 173.7626 - val_loss: 245.2652\n",
      "Epoch 369/500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 172.9578 - val_loss: 248.7220\n",
      "Epoch 370/500\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 172.3511 - val_loss: 244.6720\n",
      "Epoch 371/500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 172.1017 - val_loss: 250.8433\n",
      "Epoch 372/500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 171.9372 - val_loss: 237.4698\n",
      "Epoch 373/500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 172.5923 - val_loss: 253.9876\n",
      "Epoch 374/500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 174.6611 - val_loss: 246.6310\n",
      "Epoch 375/500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 170.7282 - val_loss: 237.8794\n",
      "Epoch 376/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 176.2089 - val_loss: 237.3099\n",
      "Epoch 377/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 172.1280 - val_loss: 247.8664\n",
      "Epoch 378/500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 172.7916 - val_loss: 248.6291\n",
      "Epoch 379/500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 172.0295 - val_loss: 235.5918\n",
      "Epoch 380/500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 171.1063 - val_loss: 238.2752\n",
      "Epoch 381/500\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 171.3002 - val_loss: 245.0993\n",
      "Epoch 382/500\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 169.7800 - val_loss: 234.5519\n",
      "Epoch 383/500\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 171.6079 - val_loss: 237.8450\n",
      "Epoch 384/500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 170.3183 - val_loss: 237.3697\n",
      "Epoch 385/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 171.6707 - val_loss: 242.5202\n",
      "Epoch 386/500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 169.9186 - val_loss: 251.8031\n",
      "Epoch 387/500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 170.8307 - val_loss: 239.8628\n",
      "Epoch 388/500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 168.9215 - val_loss: 237.9596\n",
      "Epoch 389/500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 168.7242 - val_loss: 246.6452\n",
      "Epoch 390/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 170.3392 - val_loss: 239.8980\n",
      "Epoch 391/500\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 168.9239 - val_loss: 270.2140\n",
      "Epoch 392/500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 177.0286 - val_loss: 245.3555\n",
      "Epoch 393/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 7ms/step - loss: 169.9030 - val_loss: 249.3792\n",
      "Epoch 394/500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 170.7359 - val_loss: 242.1750\n",
      "Epoch 395/500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 170.2557 - val_loss: 236.6793\n",
      "Epoch 396/500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 168.1058 - val_loss: 235.9387\n",
      "Epoch 397/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 167.8676 - val_loss: 244.3905\n",
      "Epoch 398/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 169.5396 - val_loss: 240.0530\n",
      "Epoch 399/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 168.4823 - val_loss: 240.9202\n",
      "Epoch 400/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 167.9423 - val_loss: 233.1799\n",
      "Epoch 401/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 166.7479 - val_loss: 240.7360\n",
      "Epoch 402/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 167.9576 - val_loss: 241.9520\n",
      "Epoch 403/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 168.5678 - val_loss: 236.5453\n",
      "Epoch 404/500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 166.7883 - val_loss: 247.2390\n",
      "Epoch 405/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 169.3457 - val_loss: 241.6257\n",
      "Epoch 406/500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 168.5518 - val_loss: 242.3194\n",
      "Epoch 407/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 178.3014 - val_loss: 232.7214\n",
      "Epoch 408/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 170.7720 - val_loss: 238.3256\n",
      "Epoch 409/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 166.4134 - val_loss: 234.0348\n",
      "Epoch 410/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 168.1138 - val_loss: 232.3001\n",
      "Epoch 411/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 167.2716 - val_loss: 236.4037\n",
      "Epoch 412/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 168.2061 - val_loss: 237.9966\n",
      "Epoch 413/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 167.0756 - val_loss: 230.5355\n",
      "Epoch 414/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 167.9846 - val_loss: 236.1468\n",
      "Epoch 415/500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 165.3705 - val_loss: 238.6873\n",
      "Epoch 416/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 165.9760 - val_loss: 240.5821\n",
      "Epoch 417/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 168.0185 - val_loss: 243.8749\n",
      "Epoch 418/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 167.9405 - val_loss: 235.7686\n",
      "Epoch 419/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 166.2035 - val_loss: 231.5158\n",
      "Epoch 420/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 164.8551 - val_loss: 235.3256\n",
      "Epoch 421/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 167.2140 - val_loss: 260.1874\n",
      "Epoch 422/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 168.6868 - val_loss: 227.5858\n",
      "Epoch 423/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 167.5226 - val_loss: 225.5382\n",
      "Epoch 424/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 166.2163 - val_loss: 228.3148\n",
      "Epoch 425/500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 165.2422 - val_loss: 233.3922\n",
      "Epoch 426/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 165.0563 - val_loss: 229.5221\n",
      "Epoch 427/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 166.8742 - val_loss: 246.1031\n",
      "Epoch 428/500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 166.8484 - val_loss: 236.6819\n",
      "Epoch 429/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 166.3570 - val_loss: 230.6954\n",
      "Epoch 430/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 164.2912 - val_loss: 232.3655\n",
      "Epoch 431/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 164.4059 - val_loss: 232.2194\n",
      "Epoch 432/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 163.9418 - val_loss: 233.0405\n",
      "Epoch 433/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 166.3303 - val_loss: 226.8692\n",
      "Epoch 434/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 165.4774 - val_loss: 226.6588\n",
      "Epoch 435/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 164.5401 - val_loss: 229.6813\n",
      "Epoch 436/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 164.5014 - val_loss: 227.6128\n",
      "Epoch 437/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 169.3134 - val_loss: 230.1169\n",
      "Epoch 438/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 163.2736 - val_loss: 235.0910\n",
      "Epoch 439/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 162.2512 - val_loss: 225.6011\n",
      "Epoch 440/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 166.3554 - val_loss: 228.3782\n",
      "Epoch 441/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 162.5697 - val_loss: 230.8801\n",
      "Epoch 442/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 163.1216 - val_loss: 228.2358\n",
      "Epoch 443/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 161.9272 - val_loss: 237.7962\n",
      "Epoch 444/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 163.4447 - val_loss: 231.1033\n",
      "Epoch 445/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 162.9771 - val_loss: 235.4728\n",
      "Epoch 446/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 163.2466 - val_loss: 233.1323\n",
      "Epoch 447/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 163.2038 - val_loss: 240.0687\n",
      "Epoch 448/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 163.5595 - val_loss: 232.4003\n",
      "Epoch 449/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 162.4703 - val_loss: 227.0960\n",
      "Epoch 450/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 165.9108 - val_loss: 228.0662\n",
      "Epoch 451/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 167.8769 - val_loss: 231.9607\n",
      "Epoch 452/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 165.2156 - val_loss: 230.6296\n",
      "Epoch 453/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 164.7068 - val_loss: 233.7915\n",
      "Epoch 454/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 162.0708 - val_loss: 231.7691\n",
      "Epoch 455/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 161.9006 - val_loss: 239.5315\n",
      "Epoch 456/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 162.4436 - val_loss: 229.5694\n",
      "Epoch 457/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 163.5766 - val_loss: 244.4373\n",
      "Epoch 458/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 165.0306 - val_loss: 227.6810\n",
      "Epoch 459/500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 161.2178 - val_loss: 223.3452\n",
      "Epoch 460/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 161.9492 - val_loss: 221.5611\n",
      "Epoch 461/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 163.7429 - val_loss: 224.9570\n",
      "Epoch 462/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 162.8490 - val_loss: 225.5967\n",
      "Epoch 463/500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 161.0822 - val_loss: 232.4893\n",
      "Epoch 464/500\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 161.5206 - val_loss: 225.8153\n",
      "Epoch 465/500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 162.3235 - val_loss: 227.3033\n",
      "Epoch 466/500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 160.7261 - val_loss: 233.0802\n",
      "Epoch 467/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 162.2837 - val_loss: 225.6868\n",
      "Epoch 468/500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 164.1031 - val_loss: 224.0343\n",
      "Epoch 469/500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 165.1111 - val_loss: 225.9606\n",
      "Epoch 470/500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 162.4608 - val_loss: 226.8753\n",
      "Epoch 471/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 161.8144 - val_loss: 227.5137\n",
      "Epoch 472/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 8ms/step - loss: 163.4124 - val_loss: 226.0345\n",
      "Epoch 473/500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 161.8459 - val_loss: 226.1555\n",
      "Epoch 474/500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 163.3959 - val_loss: 231.0102\n",
      "Epoch 475/500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 161.3531 - val_loss: 227.5369\n",
      "Epoch 476/500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 161.1060 - val_loss: 231.6160\n",
      "Epoch 477/500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 160.2972 - val_loss: 231.8215\n",
      "Epoch 478/500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 161.3867 - val_loss: 236.4298\n",
      "Epoch 479/500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 159.9048 - val_loss: 228.5010\n",
      "Epoch 480/500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 160.0574 - val_loss: 220.2428\n",
      "Epoch 481/500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 159.5133 - val_loss: 241.8078\n",
      "Epoch 482/500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 160.4958 - val_loss: 225.4616\n",
      "Epoch 483/500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 159.7598 - val_loss: 229.0467\n",
      "Epoch 484/500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 158.9948 - val_loss: 224.5285\n",
      "Epoch 485/500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 159.9100 - val_loss: 231.6121\n",
      "Epoch 486/500\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 160.7722 - val_loss: 223.9145\n",
      "Epoch 487/500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 159.5152 - val_loss: 231.9403\n",
      "Epoch 488/500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 159.8237 - val_loss: 228.9420\n",
      "Epoch 489/500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 159.0593 - val_loss: 231.0151\n",
      "Epoch 490/500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 158.9466 - val_loss: 243.0209\n",
      "Epoch 491/500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 161.8115 - val_loss: 225.9524\n",
      "Epoch 492/500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 158.9896 - val_loss: 226.8010\n",
      "Epoch 493/500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 158.8301 - val_loss: 221.8629\n",
      "Epoch 494/500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 159.6591 - val_loss: 225.3103\n",
      "Epoch 495/500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 159.8210 - val_loss: 230.3054\n",
      "Epoch 496/500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 158.8888 - val_loss: 227.7841\n",
      "Epoch 497/500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 157.9144 - val_loss: 223.6082\n",
      "Epoch 498/500\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 157.2959 - val_loss: 222.5768\n",
      "Epoch 499/500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 159.5713 - val_loss: 235.5020\n",
      "Epoch 500/500\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 160.6085 - val_loss: 224.5206\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"mean_squared_error\", optimizer=keras.optimizers.SGD(learning_rate=0.001))\n",
    "history = model.fit(X_train_full, y_train_full, epochs=500, validation_data=(X_valid, y_valid))\n",
    "# 绘制训练 & 验证的损失值\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "86bce158",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) ', 'for plot_model/model_to_dot to work.')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "keras.utils.plot_model(model, \"my_fashion_mnist_model.png\", show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "fc39eb91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 59)                3540      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 96)                5760      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 110)               10670     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 58)                6438      \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 59        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 26,467\n",
      "Trainable params: 26,467\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "fabbd76d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.541766161011774\n",
      "14.840580459306187\n",
      "(array([], dtype=int64),)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(np.min(np.sqrt(history.history['loss'])))\n",
    "print(np.min(np.sqrt(history.history['val_loss'])))\n",
    "test = np.sqrt(history.history['val_loss'])\n",
    "print(np.where(test==67.94991836823647))\n",
    "plt.plot(np.sqrt(history.history['loss'])*3)\n",
    "plt.plot(np.sqrt(history.history['val_loss'])*3)\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('LUT_RMSE')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "58d9d3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(n_hidden=1, n_neurons=30, learning_rate=1e-3, input_shape=[59]):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.InputLayer(input_shape=input_shape))\n",
    "    for layer in range(n_hidden):\n",
    "        model.add(keras.layers.Dense(n_neurons, activation=\"relu\"))\n",
    "    model.add(keras.layers.Dense(1))\n",
    "    optimizer = keras.optimizers.SGD(learning_rate=learning_rate)\n",
    "    model.compile(loss=\"mse\", optimizer=optimizer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2547e47e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_3(n_neurons=30, learning_rate=1e-3, input_shape=[59],unit1=1,unit2=2,unit3=3):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.InputLayer(input_shape=input_shape))\n",
    "    model.add(keras.layers.Dense(unit1, activation=\"relu\"))\n",
    "    model.add(keras.layers.Dense(unit2, activation=\"relu\"))\n",
    "    model.add(keras.layers.Dense(unit3, activation=\"relu\"))\n",
    "    model.add(keras.layers.Dense(1))\n",
    "    optimizer = keras.optimizers.SGD(learning_rate=learning_rate)\n",
    "    model.compile(loss=\"mse\", optimizer=optimizer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c8dac366",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-42-0c5b676cc640>:2: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead.\n",
      "  keras_reg = keras.wrappers.scikit_learn.KerasRegressor(build_model_3)\n"
     ]
    }
   ],
   "source": [
    "keras.backend.clear_session()\n",
    "keras_reg = keras.wrappers.scikit_learn.KerasRegressor(build_model_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "90b4b8af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.wrappers.scikit_learn.KerasRegressor at 0x201e46e9d00>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "706b07e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Epoch 1/1000\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 2581.7661 - val_loss: 8183.1021\n",
      "Epoch 2/1000\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 2577.4253 - val_loss: 8177.1968\n",
      "Epoch 3/1000\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 2573.2720 - val_loss: 8172.0273\n",
      "Epoch 4/1000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 2569.4792 - val_loss: 8166.8677\n",
      "Epoch 5/1000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 2565.7747 - val_loss: 8161.4795\n",
      "Epoch 6/1000\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 2561.6885 - val_loss: 8155.8589\n",
      "Epoch 7/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 2557.4260 - val_loss: 8149.7173\n",
      "Epoch 8/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 2552.8655 - val_loss: 8143.4854\n",
      "Epoch 9/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 2548.2969 - val_loss: 8137.2476\n",
      "Epoch 10/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 2543.5325 - val_loss: 8130.5586\n",
      "Epoch 11/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 2538.4832 - val_loss: 8123.5371\n",
      "Epoch 12/1000\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 2532.7607 - val_loss: 8114.7417\n",
      "Epoch 13/1000\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 2526.2297 - val_loss: 8103.5327\n",
      "Epoch 14/1000\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 2517.2427 - val_loss: 8092.1353\n",
      "Epoch 15/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 2508.4512 - val_loss: 8077.9829\n",
      "Epoch 16/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 2497.3643 - val_loss: 8062.3062\n",
      "Epoch 17/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 2485.1919 - val_loss: 8045.5859\n",
      "Epoch 18/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 2471.7317 - val_loss: 8024.8135\n",
      "Epoch 19/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 2455.5022 - val_loss: 7996.0996\n",
      "Epoch 20/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 2432.3628 - val_loss: 7959.9229\n",
      "Epoch 21/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 2404.5073 - val_loss: 7921.6377\n",
      "Epoch 22/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 2372.7861 - val_loss: 7866.2373\n",
      "Epoch 23/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 2329.1995 - val_loss: 7785.7690\n",
      "Epoch 24/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 2263.5276 - val_loss: 7688.4180\n",
      "Epoch 25/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 2194.3943 - val_loss: 7570.7388\n",
      "Epoch 26/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 2091.5142 - val_loss: 7388.9629\n",
      "Epoch 27/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1953.6572 - val_loss: 7168.6626\n",
      "Epoch 28/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 1802.2737 - val_loss: 6939.8545\n",
      "Epoch 29/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1640.7407 - val_loss: 6679.7383\n",
      "Epoch 30/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1491.3041 - val_loss: 6476.8530\n",
      "Epoch 31/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 1402.1271 - val_loss: 6332.5371\n",
      "Epoch 32/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 1331.1287 - val_loss: 6191.8633\n",
      "Epoch 33/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 1261.8734 - val_loss: 6194.5161\n",
      "Epoch 34/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 1205.0345 - val_loss: 6103.2998\n",
      "Epoch 35/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 1153.1321 - val_loss: 6013.7412\n",
      "Epoch 36/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 1082.2584 - val_loss: 5922.5288\n",
      "Epoch 37/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 1040.7474 - val_loss: 5821.1279\n",
      "Epoch 38/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1000.5421 - val_loss: 5770.6304\n",
      "Epoch 39/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 920.7319 - val_loss: 5755.9678\n",
      "Epoch 40/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 888.9952 - val_loss: 5757.4155\n",
      "Epoch 41/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 801.2085 - val_loss: 5662.9365\n",
      "Epoch 42/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 766.0025 - val_loss: 5564.4790\n",
      "Epoch 43/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 706.1921 - val_loss: 5529.3228\n",
      "Epoch 44/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 685.2397 - val_loss: 5455.9214\n",
      "Epoch 45/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 624.7719 - val_loss: 5469.6411\n",
      "Epoch 46/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 581.4453 - val_loss: 5497.0122\n",
      "Epoch 47/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 583.3064 - val_loss: 5379.5479\n",
      "Epoch 48/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 494.5613 - val_loss: 5474.8115\n",
      "Epoch 49/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 536.8981 - val_loss: 5318.2573\n",
      "Epoch 50/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 529.7639 - val_loss: 5361.8467\n",
      "Epoch 51/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 413.0300 - val_loss: 5417.9277\n",
      "Epoch 52/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 404.2343 - val_loss: 5459.7930\n",
      "Epoch 53/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 422.9102 - val_loss: 5488.7798\n",
      "Epoch 54/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 443.6044 - val_loss: 5385.4312\n",
      "Epoch 55/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 345.5406 - val_loss: 5330.9033\n",
      "Epoch 56/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 378.2655 - val_loss: 5265.8457\n",
      "Epoch 57/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 342.8748 - val_loss: 5351.7134\n",
      "Epoch 58/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 331.1469 - val_loss: 5287.3237\n",
      "Epoch 59/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 299.8481 - val_loss: 5355.8252\n",
      "Epoch 60/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 307.1220 - val_loss: 5399.4849\n",
      "Epoch 61/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 302.4916 - val_loss: 5381.0254\n",
      "Epoch 62/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 306.4095 - val_loss: 5419.5278\n",
      "Epoch 63/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 279.2845 - val_loss: 5346.5254\n",
      "Epoch 64/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 273.4164 - val_loss: 5427.8223\n",
      "Epoch 65/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 265.4727 - val_loss: 5343.2812\n",
      "Epoch 66/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 286.7190 - val_loss: 5303.1812\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2320.5815\n",
      "[CV] END learning_rate=0.00018186948722105108, unit1=76, unit2=107, unit3=75; total time=   2.8s\n",
      "Epoch 1/1000\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 3445.0007 - val_loss: 8176.7656\n",
      "Epoch 2/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 3438.0588 - val_loss: 8169.6582\n",
      "Epoch 3/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 3431.6074 - val_loss: 8162.6108\n",
      "Epoch 4/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 3425.1958 - val_loss: 8155.0146\n",
      "Epoch 5/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 3418.2139 - val_loss: 8147.3721\n",
      "Epoch 6/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 3411.0317 - val_loss: 8139.0098\n",
      "Epoch 7/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 3402.9441 - val_loss: 8128.5786\n",
      "Epoch 8/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 3393.3374 - val_loss: 8118.1924\n",
      "Epoch 9/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 3383.4055 - val_loss: 8105.5859\n",
      "Epoch 10/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 13ms/step - loss: 3371.4260 - val_loss: 8091.5815\n",
      "Epoch 11/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 3357.9460 - val_loss: 8074.2095\n",
      "Epoch 12/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 3341.0583 - val_loss: 8053.0571\n",
      "Epoch 13/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 3320.4175 - val_loss: 8027.2256\n",
      "Epoch 14/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 3295.3208 - val_loss: 7995.9873\n",
      "Epoch 15/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 3264.8184 - val_loss: 7954.6392\n",
      "Epoch 16/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 3221.3225 - val_loss: 7893.9067\n",
      "Epoch 17/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 3161.3020 - val_loss: 7820.0029\n",
      "Epoch 18/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 3082.2107 - val_loss: 7703.4312\n",
      "Epoch 19/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 2961.1924 - val_loss: 7535.8706\n",
      "Epoch 20/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 2785.8142 - val_loss: 7259.7427\n",
      "Epoch 21/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 2514.2981 - val_loss: 6954.8149\n",
      "Epoch 22/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 2224.4844 - val_loss: 6581.4009\n",
      "Epoch 23/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 1927.7876 - val_loss: 6308.6274\n",
      "Epoch 24/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 1729.1670 - val_loss: 6211.7285\n",
      "Epoch 25/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1662.0092 - val_loss: 6131.0010\n",
      "Epoch 26/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 1567.6162 - val_loss: 6062.2817\n",
      "Epoch 27/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1519.9666 - val_loss: 5953.5835\n",
      "Epoch 28/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1436.8734 - val_loss: 5887.1597\n",
      "Epoch 29/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 1360.7045 - val_loss: 5882.5703\n",
      "Epoch 30/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 1337.9781 - val_loss: 5908.3286\n",
      "Epoch 31/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 1305.0299 - val_loss: 5850.4150\n",
      "Epoch 32/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 1202.0876 - val_loss: 5721.6182\n",
      "Epoch 33/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 1129.7596 - val_loss: 5622.4170\n",
      "Epoch 34/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 1131.9573 - val_loss: 5605.2241\n",
      "Epoch 35/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1026.3916 - val_loss: 5521.1792\n",
      "Epoch 36/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 944.3164 - val_loss: 5537.7471\n",
      "Epoch 37/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 870.0682 - val_loss: 5458.1670\n",
      "Epoch 38/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 890.4119 - val_loss: 5433.9854\n",
      "Epoch 39/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 865.3226 - val_loss: 5372.9365\n",
      "Epoch 40/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 711.7557 - val_loss: 5369.5620\n",
      "Epoch 41/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 655.9250 - val_loss: 5328.8960\n",
      "Epoch 42/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 643.8452 - val_loss: 5340.5449\n",
      "Epoch 43/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 629.8104 - val_loss: 5350.1333\n",
      "Epoch 44/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 595.7843 - val_loss: 5325.2173\n",
      "Epoch 45/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 538.7975 - val_loss: 5226.9663\n",
      "Epoch 46/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 541.0966 - val_loss: 5230.6772\n",
      "Epoch 47/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 486.6088 - val_loss: 5254.2725\n",
      "Epoch 48/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 470.2966 - val_loss: 5219.1997\n",
      "Epoch 49/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 457.4986 - val_loss: 5433.6572\n",
      "Epoch 50/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 556.1573 - val_loss: 5214.4780\n",
      "Epoch 51/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 466.0753 - val_loss: 5109.5195\n",
      "Epoch 52/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 396.0202 - val_loss: 5185.8438\n",
      "Epoch 53/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 431.2897 - val_loss: 5074.8076\n",
      "Epoch 54/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 407.5780 - val_loss: 5061.7246\n",
      "Epoch 55/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 448.6795 - val_loss: 5101.1968\n",
      "Epoch 56/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 312.6188 - val_loss: 5182.6138\n",
      "Epoch 57/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 320.0550 - val_loss: 5128.0693\n",
      "Epoch 58/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 335.1983 - val_loss: 5247.0068\n",
      "Epoch 59/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 350.7267 - val_loss: 5193.5190\n",
      "Epoch 60/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 288.1852 - val_loss: 5156.3369\n",
      "Epoch 61/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 288.8170 - val_loss: 5180.5054\n",
      "Epoch 62/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 252.9456 - val_loss: 5026.9346\n",
      "Epoch 63/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 252.1895 - val_loss: 5213.3345\n",
      "Epoch 64/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 241.7623 - val_loss: 5093.1431\n",
      "Epoch 65/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 224.6129 - val_loss: 5073.4614\n",
      "Epoch 66/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 223.7356 - val_loss: 5204.5635\n",
      "Epoch 67/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 242.5787 - val_loss: 5111.0684\n",
      "Epoch 68/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 205.9980 - val_loss: 5009.2280\n",
      "Epoch 69/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 234.1663 - val_loss: 5169.5200\n",
      "Epoch 70/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 204.6789 - val_loss: 5150.9541\n",
      "Epoch 71/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 198.2972 - val_loss: 5176.9927\n",
      "Epoch 72/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 210.2419 - val_loss: 5168.6846\n",
      "Epoch 73/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 196.4243 - val_loss: 5122.4106\n",
      "Epoch 74/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 188.3685 - val_loss: 5167.3013\n",
      "Epoch 75/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 238.6574 - val_loss: 5167.0142\n",
      "Epoch 76/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 171.5430 - val_loss: 5162.0942\n",
      "Epoch 77/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 169.3509 - val_loss: 5105.2095\n",
      "Epoch 78/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 188.3606 - val_loss: 5237.0259\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 826.1903\n",
      "[CV] END learning_rate=0.00018186948722105108, unit1=76, unit2=107, unit3=75; total time=   2.8s\n",
      "Epoch 1/1000\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 2933.7695 - val_loss: 8179.3667\n",
      "Epoch 2/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 2928.0449 - val_loss: 8173.1943\n",
      "Epoch 3/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 2922.5352 - val_loss: 8167.0254\n",
      "Epoch 4/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 2916.9543 - val_loss: 8160.7314\n",
      "Epoch 5/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 2911.2466 - val_loss: 8154.1636\n",
      "Epoch 6/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 2905.1980 - val_loss: 8146.8838\n",
      "Epoch 7/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 2898.5437 - val_loss: 8139.1636\n",
      "Epoch 8/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 17ms/step - loss: 2891.6162 - val_loss: 8130.5288\n",
      "Epoch 9/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 2883.5957 - val_loss: 8121.7588\n",
      "Epoch 10/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 2875.5044 - val_loss: 8111.8062\n",
      "Epoch 11/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 2866.6270 - val_loss: 8101.5327\n",
      "Epoch 12/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 2856.7192 - val_loss: 8089.1792\n",
      "Epoch 13/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 2845.1831 - val_loss: 8075.0474\n",
      "Epoch 14/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 2831.2524 - val_loss: 8057.2646\n",
      "Epoch 15/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 2814.6074 - val_loss: 8037.0908\n",
      "Epoch 16/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 2794.7395 - val_loss: 8010.8335\n",
      "Epoch 17/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 2769.2502 - val_loss: 7976.4644\n",
      "Epoch 18/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 2735.4851 - val_loss: 7931.8848\n",
      "Epoch 19/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 2691.7283 - val_loss: 7872.0571\n",
      "Epoch 20/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 2633.1582 - val_loss: 7779.1553\n",
      "Epoch 21/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 2540.6504 - val_loss: 7662.7080\n",
      "Epoch 22/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 2429.5518 - val_loss: 7514.2432\n",
      "Epoch 23/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 2285.4062 - val_loss: 7294.4795\n",
      "Epoch 24/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 2080.8286 - val_loss: 7023.8804\n",
      "Epoch 25/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1858.8320 - val_loss: 6736.8286\n",
      "Epoch 26/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 1647.3558 - val_loss: 6548.2461\n",
      "Epoch 27/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 1515.6152 - val_loss: 6382.8433\n",
      "Epoch 28/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 1447.7471 - val_loss: 6372.1812\n",
      "Epoch 29/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 1390.4189 - val_loss: 6276.5039\n",
      "Epoch 30/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 1406.8341 - val_loss: 6308.9067\n",
      "Epoch 31/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1316.4443 - val_loss: 6182.2026\n",
      "Epoch 32/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 1231.6611 - val_loss: 6112.3276\n",
      "Epoch 33/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 1187.5367 - val_loss: 6152.6816\n",
      "Epoch 34/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1127.9200 - val_loss: 6048.3179\n",
      "Epoch 35/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 1076.0312 - val_loss: 5997.7808\n",
      "Epoch 36/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 1116.7584 - val_loss: 6072.0591\n",
      "Epoch 37/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 1013.0714 - val_loss: 5956.0908\n",
      "Epoch 38/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 903.1765 - val_loss: 5879.4468\n",
      "Epoch 39/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 893.7028 - val_loss: 5806.8027\n",
      "Epoch 40/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 810.3319 - val_loss: 5869.1172\n",
      "Epoch 41/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 777.3904 - val_loss: 5926.1216\n",
      "Epoch 42/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 725.7477 - val_loss: 5730.3467\n",
      "Epoch 43/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 659.2721 - val_loss: 5701.9648\n",
      "Epoch 44/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 606.3693 - val_loss: 5790.6885\n",
      "Epoch 45/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 572.6705 - val_loss: 5635.9424\n",
      "Epoch 46/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 599.5609 - val_loss: 5728.4121\n",
      "Epoch 47/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 510.2158 - val_loss: 5595.7065\n",
      "Epoch 48/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 483.9771 - val_loss: 5682.7847\n",
      "Epoch 49/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 468.8159 - val_loss: 5814.6909\n",
      "Epoch 50/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 460.3004 - val_loss: 5764.3481\n",
      "Epoch 51/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 439.5612 - val_loss: 5744.7500\n",
      "Epoch 52/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 466.2480 - val_loss: 5727.7632\n",
      "Epoch 53/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 376.6070 - val_loss: 5655.1851\n",
      "Epoch 54/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 443.2229 - val_loss: 5845.9927\n",
      "Epoch 55/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 363.7586 - val_loss: 5609.3911\n",
      "Epoch 56/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 349.1674 - val_loss: 5598.5664\n",
      "Epoch 57/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 340.4841 - val_loss: 5712.8906\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1310.6058\n",
      "[CV] END learning_rate=0.00018186948722105108, unit1=76, unit2=107, unit3=75; total time=   2.3s\n",
      "Epoch 1/1000\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 2538.2708 - val_loss: 7645.5947\n",
      "Epoch 2/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 84545.8438 - val_loss: 16462.1562\n",
      "Epoch 3/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 2957802490346876464307899731411992576.0000 - val_loss: inf\n",
      "Epoch 4/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: nan - val_loss: nan\n",
      "Epoch 5/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: nan - val_loss: nan\n",
      "Epoch 6/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: nan - val_loss: nan\n",
      "Epoch 7/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: nan - val_loss: nan\n",
      "Epoch 8/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: nan - val_loss: nan\n",
      "Epoch 9/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: nan - val_loss: nan\n",
      "Epoch 11/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: nan - val_loss: nan\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan\n",
      "[CV] END learning_rate=0.009063759187891344, unit1=12, unit2=64, unit3=89; total time=   0.6s\n",
      "Epoch 1/1000\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 3383.3638 - val_loss: 7584.2441\n",
      "Epoch 2/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 6469.3618 - val_loss: 8114.0449\n",
      "Epoch 3/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 3328.1492 - val_loss: 7758.3691\n",
      "Epoch 4/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 3238.0488 - val_loss: 10788.4443\n",
      "Epoch 5/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 4196.1392 - val_loss: 7894.9351\n",
      "Epoch 6/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 3158.3337 - val_loss: 7814.5874\n",
      "Epoch 7/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 3086.7058 - val_loss: 7732.4658\n",
      "Epoch 8/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 3003.9045 - val_loss: 7563.2993\n",
      "Epoch 9/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 2622.3650 - val_loss: 14999.1953\n",
      "Epoch 10/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 9430.6543 - val_loss: 7624.9297\n",
      "Epoch 11/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 2927.6309 - val_loss: 7571.0371\n",
      "Epoch 12/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 2871.6738 - val_loss: 7501.7979\n",
      "Epoch 13/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 2793.8823 - val_loss: 7351.2759\n",
      "Epoch 14/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 2637.8865 - val_loss: 7139.0024\n",
      "Epoch 15/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 13ms/step - loss: 2509.5410 - val_loss: 7069.8940\n",
      "Epoch 16/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 2576.3252 - val_loss: 7127.9756\n",
      "Epoch 17/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 2541.5293 - val_loss: 7172.4673\n",
      "Epoch 18/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 2517.3962 - val_loss: 7071.3882\n",
      "Epoch 19/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 2509.1919 - val_loss: 7071.8979\n",
      "Epoch 20/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 2548.0400 - val_loss: 7094.9336\n",
      "Epoch 21/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 2533.8735 - val_loss: 7073.4551\n",
      "Epoch 22/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 2516.8892 - val_loss: 7086.3091\n",
      "Epoch 23/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 2496.0159 - val_loss: 7117.3027\n",
      "Epoch 24/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 2497.1211 - val_loss: 7076.4810\n",
      "Epoch 25/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 2586.6284 - val_loss: 7070.1177\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1660.6091\n",
      "[CV] END learning_rate=0.009063759187891344, unit1=12, unit2=64, unit3=89; total time=   1.1s\n",
      "Epoch 1/1000\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 2857.9094 - val_loss: 7189.6191\n",
      "Epoch 2/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 1125338.1250 - val_loss: 10103.2578\n",
      "Epoch 3/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 240659609751797104640.0000 - val_loss: inf\n",
      "Epoch 4/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: nan - val_loss: nan\n",
      "Epoch 5/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: nan - val_loss: nan\n",
      "Epoch 6/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: nan - val_loss: nan\n",
      "Epoch 7/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: nan - val_loss: nan\n",
      "Epoch 8/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: nan - val_loss: nan\n",
      "Epoch 9/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: nan - val_loss: nan\n",
      "Epoch 11/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: nan - val_loss: nan\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan\n",
      "[CV] END learning_rate=0.009063759187891344, unit1=12, unit2=64, unit3=89; total time=   0.6s\n",
      "Epoch 1/1000\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 2543.6714 - val_loss: 7802.9971\n",
      "Epoch 2/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 1965.1556 - val_loss: 599658.0625\n",
      "Epoch 3/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 10888902656.0000 - val_loss: inf\n",
      "Epoch 4/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: nan - val_loss: nan\n",
      "Epoch 5/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: nan - val_loss: nan\n",
      "Epoch 6/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: nan - val_loss: nan\n",
      "Epoch 7/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: nan - val_loss: nan\n",
      "Epoch 8/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: nan - val_loss: nan\n",
      "Epoch 9/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: nan - val_loss: nan\n",
      "Epoch 11/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: nan - val_loss: nan\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan\n",
      "[CV] END learning_rate=0.007315728173609639, unit1=74, unit2=62, unit3=49; total time=   0.6s\n",
      "Epoch 1/1000\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 3352.8040 - val_loss: 6445.1470\n",
      "Epoch 2/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 498931.5625 - val_loss: 50866.3828\n",
      "Epoch 3/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: inf - val_loss: nan\n",
      "Epoch 4/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: nan - val_loss: nan\n",
      "Epoch 5/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: nan - val_loss: nan\n",
      "Epoch 6/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: nan - val_loss: nan\n",
      "Epoch 7/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: nan - val_loss: nan\n",
      "Epoch 8/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: nan - val_loss: nan\n",
      "Epoch 9/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: nan - val_loss: nan\n",
      "Epoch 11/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: nan - val_loss: nan\n",
      "2/2 [==============================] - 0s 3ms/step - loss: nan\n",
      "[CV] END learning_rate=0.007315728173609639, unit1=74, unit2=62, unit3=49; total time=   0.6s\n",
      "Epoch 1/1000\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 2852.3652 - val_loss: 6663.0571\n",
      "Epoch 2/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 22663.4512 - val_loss: 8264.9961\n",
      "Epoch 3/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 12080.4121 - val_loss: 633321717497856.0000\n",
      "Epoch 4/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: nan - val_loss: nan\n",
      "Epoch 5/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: nan - val_loss: nan\n",
      "Epoch 6/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: nan - val_loss: nan\n",
      "Epoch 7/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: nan - val_loss: nan\n",
      "Epoch 8/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: nan - val_loss: nan\n",
      "Epoch 9/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: nan - val_loss: nan\n",
      "Epoch 11/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: nan - val_loss: nan\n",
      "2/2 [==============================] - 0s 3ms/step - loss: nan\n",
      "[CV] END learning_rate=0.007315728173609639, unit1=74, unit2=62, unit3=49; total time=   0.6s\n",
      "Epoch 1/1000\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 2574.3823 - val_loss: 8155.9902\n",
      "Epoch 2/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 2553.7068 - val_loss: 8124.3101\n",
      "Epoch 3/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 2529.2566 - val_loss: 8082.4771\n",
      "Epoch 4/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 2496.1938 - val_loss: 8025.6455\n",
      "Epoch 5/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 2450.0161 - val_loss: 7934.1870\n",
      "Epoch 6/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 2378.8679 - val_loss: 7798.9771\n",
      "Epoch 7/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 2273.5618 - val_loss: 7580.6982\n",
      "Epoch 8/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 2127.8340 - val_loss: 7306.4170\n",
      "Epoch 9/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 2042.3726 - val_loss: 7313.8589\n",
      "Epoch 10/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 2041.4457 - val_loss: 7108.3662\n",
      "Epoch 11/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 1996.3885 - val_loss: 7106.2339\n",
      "Epoch 12/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 2010.9697 - val_loss: 7163.9941\n",
      "Epoch 13/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 1994.7184 - val_loss: 7096.1895\n",
      "Epoch 14/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 1975.9244 - val_loss: 7156.7812\n",
      "Epoch 15/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 2010.1584 - val_loss: 7200.5591\n",
      "Epoch 16/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 1927.8822 - val_loss: 7009.2456\n",
      "Epoch 17/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1764.3927 - val_loss: 6959.2021\n",
      "Epoch 18/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 1495.6605 - val_loss: 7426.1494\n",
      "Epoch 19/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 1631.1520 - val_loss: 5709.6616\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 1489.8267 - val_loss: 8122.1768\n",
      "Epoch 21/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 2529.5503 - val_loss: 8092.7803\n",
      "Epoch 22/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 2509.5911 - val_loss: 8067.8105\n",
      "Epoch 23/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 2490.8323 - val_loss: 8034.1177\n",
      "Epoch 24/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 2465.8696 - val_loss: 7998.1318\n",
      "Epoch 25/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 2438.5935 - val_loss: 7953.5791\n",
      "Epoch 26/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 2404.7373 - val_loss: 7890.8638\n",
      "Epoch 27/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 2356.6006 - val_loss: 7799.9297\n",
      "Epoch 28/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 2289.0686 - val_loss: 7639.2158\n",
      "Epoch 29/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 2176.4800 - val_loss: 7434.3950\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 2973.2454\n",
      "[CV] END learning_rate=0.0013464320273500377, unit1=3, unit2=126, unit3=73; total time=   1.4s\n",
      "Epoch 1/1000\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 3435.3503 - val_loss: 8142.3276\n",
      "Epoch 2/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 3395.2104 - val_loss: 8086.8188\n",
      "Epoch 3/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 3334.0261 - val_loss: 7980.8838\n",
      "Epoch 4/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 3201.9771 - val_loss: 7662.8994\n",
      "Epoch 5/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 2706.9622 - val_loss: 6518.5259\n",
      "Epoch 6/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 1734.9346 - val_loss: 5914.7661\n",
      "Epoch 7/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 1220.8479 - val_loss: 6383.0405\n",
      "Epoch 8/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 4967.5469 - val_loss: 8145.3877\n",
      "Epoch 9/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 3395.0029 - val_loss: 8104.7314\n",
      "Epoch 10/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 3368.3921 - val_loss: 8085.4077\n",
      "Epoch 11/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 3349.9397 - val_loss: 8063.7095\n",
      "Epoch 12/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 3329.5391 - val_loss: 8040.8408\n",
      "Epoch 13/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 3307.2222 - val_loss: 8012.7373\n",
      "Epoch 14/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 3279.7637 - val_loss: 7978.3481\n",
      "Epoch 15/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 3245.6287 - val_loss: 7927.5571\n",
      "Epoch 16/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 3192.5691 - val_loss: 7853.7588\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1853.0249\n",
      "[CV] END learning_rate=0.0013464320273500377, unit1=3, unit2=126, unit3=73; total time=   0.8s\n",
      "Epoch 1/1000\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 2923.5745 - val_loss: 8151.8691\n",
      "Epoch 2/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 2895.2754 - val_loss: 8109.5298\n",
      "Epoch 3/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 2852.7461 - val_loss: 8043.9341\n",
      "Epoch 4/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 2780.1892 - val_loss: 7892.9321\n",
      "Epoch 5/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 2579.6265 - val_loss: 7323.5947\n",
      "Epoch 6/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 2091.3062 - val_loss: 7739.6943\n",
      "Epoch 7/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 2249.8708 - val_loss: 6233.7124\n",
      "Epoch 8/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 2426.4448 - val_loss: 8110.1870\n",
      "Epoch 9/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 2861.4624 - val_loss: 8080.1929\n",
      "Epoch 10/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 2835.5547 - val_loss: 8047.2617\n",
      "Epoch 11/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 2805.8965 - val_loss: 8010.6318\n",
      "Epoch 12/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 2772.3440 - val_loss: 7965.8721\n",
      "Epoch 13/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 2729.8452 - val_loss: 7895.6621\n",
      "Epoch 14/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 2661.9568 - val_loss: 7796.0723\n",
      "Epoch 15/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 2567.0808 - val_loss: 7647.6865\n",
      "Epoch 16/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 2424.6353 - val_loss: 7404.4585\n",
      "Epoch 17/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 2252.8801 - val_loss: 7238.9326\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2442.4827\n",
      "[CV] END learning_rate=0.0013464320273500377, unit1=3, unit2=126, unit3=73; total time=   0.8s\n",
      "Epoch 1/1000\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 2575.1194 - val_loss: 8167.3320\n",
      "Epoch 2/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 2566.2600 - val_loss: 8155.1909\n",
      "Epoch 3/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 2557.5735 - val_loss: 8142.3994\n",
      "Epoch 4/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 2548.4353 - val_loss: 8129.2007\n",
      "Epoch 5/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 2538.5674 - val_loss: 8113.3091\n",
      "Epoch 6/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 2526.6816 - val_loss: 8092.0142\n",
      "Epoch 7/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 2510.9182 - val_loss: 8067.7168\n",
      "Epoch 8/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 2491.5488 - val_loss: 8030.5664\n",
      "Epoch 9/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 2463.5093 - val_loss: 7981.4912\n",
      "Epoch 10/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 2423.2124 - val_loss: 7901.7085\n",
      "Epoch 11/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 2361.3696 - val_loss: 7790.1396\n",
      "Epoch 12/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 2269.2781 - val_loss: 7605.9033\n",
      "Epoch 13/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 2125.6875 - val_loss: 7262.3179\n",
      "Epoch 14/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 1862.9606 - val_loss: 6755.8667\n",
      "Epoch 15/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 1541.0670 - val_loss: 6311.9243\n",
      "Epoch 16/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 1354.6450 - val_loss: 6169.7617\n",
      "Epoch 17/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 1316.6700 - val_loss: 6066.2217\n",
      "Epoch 18/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 1288.9060 - val_loss: 6057.6929\n",
      "Epoch 19/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 1112.7119 - val_loss: 5890.5493\n",
      "Epoch 20/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 998.0499 - val_loss: 5727.7695\n",
      "Epoch 21/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 997.4836 - val_loss: 5633.4629\n",
      "Epoch 22/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 865.7743 - val_loss: 5634.7959\n",
      "Epoch 23/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 792.9911 - val_loss: 5514.5176\n",
      "Epoch 24/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 949.3780 - val_loss: 5435.2319\n",
      "Epoch 25/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 613.7366 - val_loss: 5324.5601\n",
      "Epoch 26/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 550.8911 - val_loss: 5441.8125\n",
      "Epoch 27/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 533.8470 - val_loss: 5255.6118\n",
      "Epoch 28/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 446.0848 - val_loss: 5239.6641\n",
      "Epoch 29/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 419.1840 - val_loss: 5233.2153\n",
      "Epoch 30/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 389.3832 - val_loss: 5312.4058\n",
      "Epoch 31/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 14ms/step - loss: 461.7090 - val_loss: 5498.7109\n",
      "Epoch 32/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 355.3968 - val_loss: 5276.4019\n",
      "Epoch 33/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 321.3848 - val_loss: 5398.8159\n",
      "Epoch 34/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 320.0441 - val_loss: 5342.1743\n",
      "Epoch 35/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 444.7385 - val_loss: 5226.7788\n",
      "Epoch 36/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 302.3242 - val_loss: 5311.9058\n",
      "Epoch 37/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 283.2774 - val_loss: 5432.1006\n",
      "Epoch 38/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 275.5826 - val_loss: 5311.8560\n",
      "Epoch 39/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 425.5776 - val_loss: 5291.7417\n",
      "Epoch 40/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 282.4003 - val_loss: 5464.3154\n",
      "Epoch 41/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 388.2874 - val_loss: 5602.7700\n",
      "Epoch 42/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 368.4605 - val_loss: 5304.7798\n",
      "Epoch 43/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 269.9832 - val_loss: 5320.1606\n",
      "Epoch 44/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 239.2560 - val_loss: 5335.7153\n",
      "Epoch 45/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 354.2714 - val_loss: 5560.2100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2090.5276\n",
      "[CV] END learning_rate=0.00032165655238266904, unit1=88, unit2=106, unit3=85; total time=   1.8s\n",
      "Epoch 1/1000\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 3445.1521 - val_loss: 8174.2109\n",
      "Epoch 2/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 3435.2144 - val_loss: 8163.2217\n",
      "Epoch 3/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 3424.6604 - val_loss: 8151.9243\n",
      "Epoch 4/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 3413.5610 - val_loss: 8139.5996\n",
      "Epoch 5/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 3401.2136 - val_loss: 8125.2456\n",
      "Epoch 6/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 3387.1213 - val_loss: 8108.9609\n",
      "Epoch 7/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 3370.1411 - val_loss: 8087.3516\n",
      "Epoch 8/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 3347.8979 - val_loss: 8057.9902\n",
      "Epoch 9/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 3316.6023 - val_loss: 8013.9629\n",
      "Epoch 10/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 3268.0105 - val_loss: 7946.8418\n",
      "Epoch 11/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 3192.2629 - val_loss: 7835.3193\n",
      "Epoch 12/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 3061.2104 - val_loss: 7620.6450\n",
      "Epoch 13/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 2806.7295 - val_loss: 7179.2524\n",
      "Epoch 14/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 2306.8318 - val_loss: 6546.7280\n",
      "Epoch 15/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 1813.2606 - val_loss: 6275.2212\n",
      "Epoch 16/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 1627.7347 - val_loss: 6147.7725\n",
      "Epoch 17/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1527.2545 - val_loss: 6024.9751\n",
      "Epoch 18/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1497.1428 - val_loss: 5945.4302\n",
      "Epoch 19/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1423.2915 - val_loss: 5846.9307\n",
      "Epoch 20/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1289.2474 - val_loss: 5923.4487\n",
      "Epoch 21/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 1194.1479 - val_loss: 5663.5073\n",
      "Epoch 22/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 1342.5277 - val_loss: 5982.6226\n",
      "Epoch 23/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 1074.1208 - val_loss: 5560.9507\n",
      "Epoch 24/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 1047.3314 - val_loss: 5423.2412\n",
      "Epoch 25/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 1025.2362 - val_loss: 5499.1963\n",
      "Epoch 26/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 957.0852 - val_loss: 5302.4126\n",
      "Epoch 27/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 714.9860 - val_loss: 5245.3594\n",
      "Epoch 28/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 582.7863 - val_loss: 5461.3101\n",
      "Epoch 29/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 623.3770 - val_loss: 5825.5337\n",
      "Epoch 30/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 626.1703 - val_loss: 5276.2749\n",
      "Epoch 31/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 494.3526 - val_loss: 5153.9360\n",
      "Epoch 32/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 786.3616 - val_loss: 5580.2476\n",
      "Epoch 33/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 417.8303 - val_loss: 5214.1533\n",
      "Epoch 34/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1207.0225 - val_loss: 5409.6777\n",
      "Epoch 35/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 373.3984 - val_loss: 5166.6079\n",
      "Epoch 36/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 349.4490 - val_loss: 5236.0161\n",
      "Epoch 37/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 349.3465 - val_loss: 5240.6831\n",
      "Epoch 38/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 404.8076 - val_loss: 5223.4683\n",
      "Epoch 39/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 304.1807 - val_loss: 5138.8926\n",
      "Epoch 40/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 284.5930 - val_loss: 5266.4868\n",
      "Epoch 41/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 389.0981 - val_loss: 5273.3706\n",
      "Epoch 42/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 287.5768 - val_loss: 5184.3633\n",
      "Epoch 43/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 261.2291 - val_loss: 5020.6592\n",
      "Epoch 44/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 610.1248 - val_loss: 5456.2661\n",
      "Epoch 45/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 295.9216 - val_loss: 5222.9990\n",
      "Epoch 46/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 209.2123 - val_loss: 5079.6919\n",
      "Epoch 47/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 393.0382 - val_loss: 5009.2144\n",
      "Epoch 48/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 319.2090 - val_loss: 5131.1460\n",
      "Epoch 49/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 201.7109 - val_loss: 5163.5972\n",
      "Epoch 50/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 193.2630 - val_loss: 5088.4429\n",
      "Epoch 51/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 178.7518 - val_loss: 5218.7427\n",
      "Epoch 52/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 185.3472 - val_loss: 5122.9404\n",
      "Epoch 53/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 213.0795 - val_loss: 5118.9775\n",
      "Epoch 54/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 168.7219 - val_loss: 5126.5649\n",
      "Epoch 55/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 165.1318 - val_loss: 5138.2808\n",
      "Epoch 56/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 175.7825 - val_loss: 5240.2095\n",
      "Epoch 57/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 186.3243 - val_loss: 5313.0010\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 901.1464\n",
      "[CV] END learning_rate=0.00032165655238266904, unit1=88, unit2=106, unit3=85; total time=   2.2s\n",
      "Epoch 1/1000\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 2935.6960 - val_loss: 8177.7559\n",
      "Epoch 2/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 2925.8364 - val_loss: 8167.5132\n",
      "Epoch 3/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 2916.4771 - val_loss: 8156.7153\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 2906.6470 - val_loss: 8144.5254\n",
      "Epoch 5/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 2895.3860 - val_loss: 8129.8086\n",
      "Epoch 6/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 2881.9736 - val_loss: 8114.3882\n",
      "Epoch 7/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 2867.8901 - val_loss: 8096.2354\n",
      "Epoch 8/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 2849.9644 - val_loss: 8071.4795\n",
      "Epoch 9/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 2828.3538 - val_loss: 8041.6885\n",
      "Epoch 10/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 2797.1965 - val_loss: 7997.3984\n",
      "Epoch 11/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 2754.2668 - val_loss: 7929.7153\n",
      "Epoch 12/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 2683.6621 - val_loss: 7819.5488\n",
      "Epoch 13/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 2571.3721 - val_loss: 7639.6436\n",
      "Epoch 14/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 2387.0486 - val_loss: 7329.3809\n",
      "Epoch 15/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 2083.2715 - val_loss: 6860.6938\n",
      "Epoch 16/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 1763.9994 - val_loss: 6549.5620\n",
      "Epoch 17/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 1522.3672 - val_loss: 6293.9668\n",
      "Epoch 18/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 1561.2787 - val_loss: 6297.3633\n",
      "Epoch 19/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1369.1896 - val_loss: 6087.7358\n",
      "Epoch 20/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1242.6530 - val_loss: 6073.8511\n",
      "Epoch 21/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1304.1786 - val_loss: 5964.4731\n",
      "Epoch 22/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 1051.4188 - val_loss: 5837.9507\n",
      "Epoch 23/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 946.2916 - val_loss: 6039.4521\n",
      "Epoch 24/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1004.9548 - val_loss: 5850.4048\n",
      "Epoch 25/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 784.1042 - val_loss: 5858.9829\n",
      "Epoch 26/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 698.1058 - val_loss: 5693.2666\n",
      "Epoch 27/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 614.2593 - val_loss: 5575.8882\n",
      "Epoch 28/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 586.6035 - val_loss: 5650.3472\n",
      "Epoch 29/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 534.2458 - val_loss: 5792.7261\n",
      "Epoch 30/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 469.9225 - val_loss: 5646.7466\n",
      "Epoch 31/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 721.6630 - val_loss: 5737.3784\n",
      "Epoch 32/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 433.1978 - val_loss: 5602.0312\n",
      "Epoch 33/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 389.7840 - val_loss: 5878.0547\n",
      "Epoch 34/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 366.0741 - val_loss: 5607.8428\n",
      "Epoch 35/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 333.9540 - val_loss: 5693.7930\n",
      "Epoch 36/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 323.8515 - val_loss: 5656.7378\n",
      "Epoch 37/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 321.8593 - val_loss: 5746.1030\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1353.7810\n",
      "[CV] END learning_rate=0.00032165655238266904, unit1=88, unit2=106, unit3=85; total time=   1.5s\n",
      "Epoch 1/1000\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 2568.4539 - val_loss: 8142.0576\n",
      "Epoch 2/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 2538.9780 - val_loss: 8085.3545\n",
      "Epoch 3/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 2486.6362 - val_loss: 7970.7461\n",
      "Epoch 4/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 2362.1265 - val_loss: 7547.1636\n",
      "Epoch 5/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 1894.9436 - val_loss: 6320.8550\n",
      "Epoch 6/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 1731.0309 - val_loss: 7463.3164\n",
      "Epoch 7/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 1756.4174 - val_loss: 5863.7397\n",
      "Epoch 8/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 1197.9667 - val_loss: 6775.6567\n",
      "Epoch 9/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 1074.8073 - val_loss: 6219.5513\n",
      "Epoch 10/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 3012.9446 - val_loss: 8139.6484\n",
      "Epoch 11/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 2544.6001 - val_loss: 8124.2490\n",
      "Epoch 12/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 2534.0879 - val_loss: 8109.6895\n",
      "Epoch 13/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 2523.1077 - val_loss: 8093.2974\n",
      "Epoch 14/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 2510.6064 - val_loss: 8073.7427\n",
      "Epoch 15/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 2495.8254 - val_loss: 8049.1021\n",
      "Epoch 16/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 2476.9878 - val_loss: 8015.2920\n",
      "Epoch 17/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 2450.5549 - val_loss: 7967.5430\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 3566.9133\n",
      "[CV] END learning_rate=0.001013795819537981, unit1=80, unit2=145, unit3=28; total time=   0.8s\n",
      "Epoch 1/1000\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 3437.6946 - val_loss: 8148.7559\n",
      "Epoch 2/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 3404.8237 - val_loss: 8104.0449\n",
      "Epoch 3/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 3355.2664 - val_loss: 8014.8247\n",
      "Epoch 4/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 3234.9182 - val_loss: 7680.2168\n",
      "Epoch 5/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 2703.0098 - val_loss: 6330.2930\n",
      "Epoch 6/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 1651.3607 - val_loss: 6090.4077\n",
      "Epoch 7/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 1465.6727 - val_loss: 6126.0049\n",
      "Epoch 8/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 1637.1562 - val_loss: 6414.4365\n",
      "Epoch 9/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 1288.6176 - val_loss: 7385.1562\n",
      "Epoch 10/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1834.5452 - val_loss: 5896.2852\n",
      "Epoch 11/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 758.5538 - val_loss: 6932.6973\n",
      "Epoch 12/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1712.6641 - val_loss: 5841.5684\n",
      "Epoch 13/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 2453.3264 - val_loss: 8181.3965\n",
      "Epoch 14/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 3423.5354 - val_loss: 8118.9927\n",
      "Epoch 15/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 3382.2207 - val_loss: 8103.7559\n",
      "Epoch 16/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 3368.4397 - val_loss: 8089.2588\n",
      "Epoch 17/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 3354.8713 - val_loss: 8073.5542\n",
      "Epoch 18/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 3340.3394 - val_loss: 8058.2715\n",
      "Epoch 19/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 3325.4873 - val_loss: 8039.4336\n",
      "Epoch 20/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 3307.4084 - val_loss: 8017.9570\n",
      "Epoch 21/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 3285.8965 - val_loss: 7986.7007\n",
      "Epoch 22/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 3254.9363 - val_loss: 7945.5371\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1911.7738\n",
      "[CV] END learning_rate=0.001013795819537981, unit1=80, unit2=145, unit3=28; total time=   1.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 2926.9214 - val_loss: 8153.3921\n",
      "Epoch 2/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 2897.2434 - val_loss: 8108.3545\n",
      "Epoch 3/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 2851.6584 - val_loss: 8021.9487\n",
      "Epoch 4/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 2754.8645 - val_loss: 7801.0527\n",
      "Epoch 5/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 2453.4766 - val_loss: 6767.7891\n",
      "Epoch 6/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 1714.6482 - val_loss: 6104.6982\n",
      "Epoch 7/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 1872.2885 - val_loss: 5953.4551\n",
      "Epoch 8/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 1168.4767 - val_loss: 7074.7109\n",
      "Epoch 9/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 1706.9001 - val_loss: 7888.7588\n",
      "Epoch 10/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 2519.4504 - val_loss: 7256.9067\n",
      "Epoch 11/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 1397.9873 - val_loss: 7656.7070\n",
      "Epoch 12/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 4035.2493 - val_loss: 8127.6479\n",
      "Epoch 13/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 2879.3184 - val_loss: 8111.3936\n",
      "Epoch 14/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 2865.3154 - val_loss: 8095.4824\n",
      "Epoch 15/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 2851.6543 - val_loss: 8080.4351\n",
      "Epoch 16/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 2838.7244 - val_loss: 8065.6826\n",
      "Epoch 17/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 2825.8127 - val_loss: 8050.6655\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2989.6191\n",
      "[CV] END learning_rate=0.001013795819537981, unit1=80, unit2=145, unit3=28; total time=   0.8s\n",
      "Epoch 1/1000\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 2575.1128 - val_loss: 8152.4155\n",
      "Epoch 2/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 2551.0979 - val_loss: 8113.9883\n",
      "Epoch 3/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 2520.0667 - val_loss: 8054.3359\n",
      "Epoch 4/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 2465.4077 - val_loss: 7867.4990\n",
      "Epoch 5/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 2262.1245 - val_loss: 7105.4097\n",
      "Epoch 6/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 2217.3083 - val_loss: 8049.8560\n",
      "Epoch 7/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 2472.4822 - val_loss: 7994.4565\n",
      "Epoch 8/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 2426.7437 - val_loss: 7905.9717\n",
      "Epoch 9/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 2348.1738 - val_loss: 7696.9551\n",
      "Epoch 10/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 2144.2224 - val_loss: 6987.2388\n",
      "Epoch 11/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 1356.3314 - val_loss: 5722.1616\n",
      "Epoch 12/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1166.4478 - val_loss: 7240.7876\n",
      "Epoch 13/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1439.5991 - val_loss: 6346.0747\n",
      "Epoch 14/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 613.2487 - val_loss: 24766.1367\n",
      "Epoch 15/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 11911.3613 - val_loss: 8071.0493\n",
      "Epoch 16/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 2490.5144 - val_loss: 8038.1440\n",
      "Epoch 17/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 2468.8506 - val_loss: 8003.3013\n",
      "Epoch 18/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 2441.4595 - val_loss: 7942.8433\n",
      "Epoch 19/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 2386.6414 - val_loss: 7771.9629\n",
      "Epoch 20/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 2213.4893 - val_loss: 7178.5000\n",
      "Epoch 21/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1806.8104 - val_loss: 7205.6870\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 3030.9980\n",
      "[CV] END learning_rate=0.0017544161473511712, unit1=19, unit2=34, unit3=82; total time=   1.0s\n",
      "Epoch 1/1000\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 3433.1394 - val_loss: 8134.5991\n",
      "Epoch 2/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 3384.5737 - val_loss: 8063.0430\n",
      "Epoch 3/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 3289.8574 - val_loss: 7771.2217\n",
      "Epoch 4/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 2798.7131 - val_loss: 6895.7671\n",
      "Epoch 5/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 3397.1880 - val_loss: 8135.5542\n",
      "Epoch 6/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 3389.3452 - val_loss: 8092.9180\n",
      "Epoch 7/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 3353.0254 - val_loss: 8061.0547\n",
      "Epoch 8/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 3322.6846 - val_loss: 8027.1377\n",
      "Epoch 9/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 3289.8232 - val_loss: 7986.6768\n",
      "Epoch 10/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 3250.4231 - val_loss: 7935.8940\n",
      "Epoch 11/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 3197.3403 - val_loss: 7862.2202\n",
      "Epoch 12/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 3122.5872 - val_loss: 7757.9824\n",
      "Epoch 13/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 3019.8323 - val_loss: 7586.5303\n",
      "Epoch 14/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 2838.0708 - val_loss: 7342.6064\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1587.4926\n",
      "[CV] END learning_rate=0.0017544161473511712, unit1=19, unit2=34, unit3=82; total time=   0.7s\n",
      "Epoch 1/1000\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 2915.7639 - val_loss: 8118.5161\n",
      "Epoch 2/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 2855.8015 - val_loss: 7981.4507\n",
      "Epoch 3/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 2652.8606 - val_loss: 7185.9126\n",
      "Epoch 4/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 3459.8269 - val_loss: 8171.7202\n",
      "Epoch 5/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 2901.7129 - val_loss: 8107.5269\n",
      "Epoch 6/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 2860.1038 - val_loss: 8082.0317\n",
      "Epoch 7/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 2837.5950 - val_loss: 8053.6538\n",
      "Epoch 8/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 2811.2356 - val_loss: 8018.8467\n",
      "Epoch 9/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 2778.5276 - val_loss: 7970.8579\n",
      "Epoch 10/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 2733.4229 - val_loss: 7907.1870\n",
      "Epoch 11/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 2673.9004 - val_loss: 7814.0664\n",
      "Epoch 12/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 2577.4177 - val_loss: 7640.8057\n",
      "Epoch 13/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 2395.3601 - val_loss: 7147.6450\n",
      "Epoch 14/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1993.0420 - val_loss: 7053.0879\n",
      "Epoch 15/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 1503.5686 - val_loss: 18730.6680\n",
      "Epoch 16/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 8850.4307 - val_loss: 7990.6870\n",
      "Epoch 17/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 2758.7729 - val_loss: 7969.5747\n",
      "Epoch 18/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 2742.8184 - val_loss: 7952.4453\n",
      "Epoch 19/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 2728.5981 - val_loss: 7936.7993\n",
      "Epoch 20/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 2714.7324 - val_loss: 7920.3647\n",
      "Epoch 21/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 2700.6521 - val_loss: 7902.1826\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 2683.9612 - val_loss: 7877.7100\n",
      "Epoch 23/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 2660.3389 - val_loss: 7833.2095\n",
      "Epoch 24/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 2607.9536 - val_loss: 7652.9927\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2684.7227\n",
      "[CV] END learning_rate=0.0017544161473511712, unit1=19, unit2=34, unit3=82; total time=   1.0s\n",
      "Epoch 1/1000\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 2543.2114 - val_loss: 7859.6274\n",
      "Epoch 2/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 39390.7422 - val_loss: 8509.1973\n",
      "Epoch 3/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 2670.8982 - val_loss: 7708.1260\n",
      "Epoch 4/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 3341.7983 - val_loss: 572794112.0000\n",
      "Epoch 5/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: inf - val_loss: nan\n",
      "Epoch 6/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: nan - val_loss: nan\n",
      "Epoch 7/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: nan - val_loss: nan\n",
      "Epoch 8/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: nan - val_loss: nan\n",
      "Epoch 9/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: nan - val_loss: nan\n",
      "Epoch 11/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: nan - val_loss: nan\n",
      "Epoch 12/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: nan - val_loss: nan\n",
      "Epoch 13/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: nan - val_loss: nan\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan\n",
      "[CV] END learning_rate=0.006609624932254667, unit1=25, unit2=89, unit3=44; total time=   0.8s\n",
      "Epoch 1/1000\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 3390.7612 - val_loss: 7597.7876\n",
      "Epoch 2/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 14494.3770 - val_loss: 8209.1123\n",
      "Epoch 3/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 3447.7314 - val_loss: 8123.9062\n",
      "Epoch 4/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 3364.9800 - val_loss: 7982.4541\n",
      "Epoch 5/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 2717.3147 - val_loss: 1047572.4375\n",
      "Epoch 6/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 122857313009664.0000 - val_loss: 83564765184.0000\n",
      "Epoch 7/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 81695956992.0000 - val_loss: 77152059392.0000\n",
      "Epoch 8/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 75426627584.0000 - val_loss: 71231471616.0000\n",
      "Epoch 9/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 69638389760.0000 - val_loss: 65765208064.0000\n",
      "Epoch 10/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 64294334464.0000 - val_loss: 60718419968.0000\n",
      "Epoch 11/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 59360378880.0000 - val_loss: 56058949632.0000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 56053813248.0000\n",
      "[CV] END learning_rate=0.006609624932254667, unit1=25, unit2=89, unit3=44; total time=   0.6s\n",
      "Epoch 1/1000\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 2877.1970 - val_loss: 7437.7085\n",
      "Epoch 2/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 3032.0786 - val_loss: 8090.6641\n",
      "Epoch 3/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 2828.0557 - val_loss: 7973.3530\n",
      "Epoch 4/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 2688.3684 - val_loss: 7532.0688\n",
      "Epoch 5/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 2041.9020 - val_loss: 8000.4927\n",
      "Epoch 6/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 2729.8274 - val_loss: 7825.3467\n",
      "Epoch 7/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 2552.7732 - val_loss: 7430.3579\n",
      "Epoch 8/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 2136.3779 - val_loss: 7442.1382\n",
      "Epoch 9/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 2524.6711 - val_loss: 7805.5244\n",
      "Epoch 10/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 2562.3914 - val_loss: 7572.4785\n",
      "Epoch 11/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 2342.9766 - val_loss: 7233.1494\n",
      "Epoch 12/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 2194.6833 - val_loss: 7097.0317\n",
      "Epoch 13/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 2151.7026 - val_loss: 7243.6396\n",
      "Epoch 14/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 2151.2566 - val_loss: 7094.9888\n",
      "Epoch 15/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 2083.0959 - val_loss: 7067.9082\n",
      "Epoch 16/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 2076.5566 - val_loss: 7149.6265\n",
      "Epoch 17/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 2055.4346 - val_loss: 11215.2578\n",
      "Epoch 18/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 4991.4780 - val_loss: 7752.5200\n",
      "Epoch 19/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 2551.0894 - val_loss: 7704.5635\n",
      "Epoch 20/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 2512.8181 - val_loss: 7664.8936\n",
      "Epoch 21/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 2479.9233 - val_loss: 7625.6377\n",
      "Epoch 22/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 2448.2620 - val_loss: 7588.1636\n",
      "Epoch 23/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 2419.0820 - val_loss: 7554.0874\n",
      "Epoch 24/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 2390.4304 - val_loss: 7518.0386\n",
      "Epoch 25/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 2360.7566 - val_loss: 7470.0327\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2572.6497\n",
      "[CV] END learning_rate=0.006609624932254667, unit1=25, unit2=89, unit3=44; total time=   1.1s\n",
      "Epoch 1/1000\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 2584.0945 - val_loss: 8188.9126\n",
      "Epoch 2/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 2581.6230 - val_loss: 8185.2759\n",
      "Epoch 3/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 2579.1221 - val_loss: 8181.9570\n",
      "Epoch 4/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 2576.7371 - val_loss: 8178.3926\n",
      "Epoch 5/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 2574.2832 - val_loss: 8175.1533\n",
      "Epoch 6/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 2571.9800 - val_loss: 8171.5835\n",
      "Epoch 7/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 2569.4277 - val_loss: 8167.8188\n",
      "Epoch 8/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 2566.8386 - val_loss: 8164.4824\n",
      "Epoch 9/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 2564.4119 - val_loss: 8160.9824\n",
      "Epoch 10/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 2561.9785 - val_loss: 8157.5547\n",
      "Epoch 11/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 2559.4246 - val_loss: 8153.7280\n",
      "Epoch 12/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 2556.7402 - val_loss: 8150.1792\n",
      "Epoch 13/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 2554.1401 - val_loss: 8146.0605\n",
      "Epoch 14/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 2551.1538 - val_loss: 8142.0054\n",
      "Epoch 15/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 2548.2166 - val_loss: 8137.9180\n",
      "Epoch 16/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 2545.2185 - val_loss: 8133.1138\n",
      "Epoch 17/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 2541.7295 - val_loss: 8128.7295\n",
      "Epoch 18/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 2538.5137 - val_loss: 8123.3921\n",
      "Epoch 19/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 2534.6511 - val_loss: 8118.5708\n",
      "Epoch 20/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 15ms/step - loss: 2531.1614 - val_loss: 8113.6182\n",
      "Epoch 21/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 2527.4331 - val_loss: 8107.4985\n",
      "Epoch 22/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 2522.9888 - val_loss: 8101.6870\n",
      "Epoch 23/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 2518.7913 - val_loss: 8095.4165\n",
      "Epoch 24/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 2514.1028 - val_loss: 8088.5718\n",
      "Epoch 25/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 2509.0923 - val_loss: 8081.4111\n",
      "Epoch 26/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 2503.8689 - val_loss: 8073.3638\n",
      "Epoch 27/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 2498.1365 - val_loss: 8065.1880\n",
      "Epoch 28/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 2491.8645 - val_loss: 8054.5000\n",
      "Epoch 29/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 2484.4053 - val_loss: 8044.3608\n",
      "Epoch 30/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 2476.5676 - val_loss: 8033.1709\n",
      "Epoch 31/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 2468.5815 - val_loss: 8021.2759\n",
      "Epoch 32/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 2459.1548 - val_loss: 8005.5850\n",
      "Epoch 33/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 2447.5398 - val_loss: 7986.9341\n",
      "Epoch 34/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 2433.4651 - val_loss: 7967.2485\n",
      "Epoch 35/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 2418.6199 - val_loss: 7944.1685\n",
      "Epoch 36/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 2401.4475 - val_loss: 7918.5527\n",
      "Epoch 37/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 2382.2798 - val_loss: 7887.8130\n",
      "Epoch 38/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 2359.9192 - val_loss: 7852.6348\n",
      "Epoch 39/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 2332.8120 - val_loss: 7812.4106\n",
      "Epoch 40/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 2303.2339 - val_loss: 7766.8135\n",
      "Epoch 41/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 2268.7786 - val_loss: 7705.4873\n",
      "Epoch 42/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 2222.2043 - val_loss: 7630.1382\n",
      "Epoch 43/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 2165.8613 - val_loss: 7539.8271\n",
      "Epoch 44/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 2102.9712 - val_loss: 7416.5161\n",
      "Epoch 45/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 2009.4396 - val_loss: 7294.3877\n",
      "Epoch 46/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1922.5735 - val_loss: 7152.6089\n",
      "Epoch 47/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 1833.6317 - val_loss: 7010.2915\n",
      "Epoch 48/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 1738.2263 - val_loss: 6807.6855\n",
      "Epoch 49/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1605.9177 - val_loss: 6643.9453\n",
      "Epoch 50/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 1524.2249 - val_loss: 6536.0420\n",
      "Epoch 51/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 1464.7185 - val_loss: 6377.0171\n",
      "Epoch 52/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 1387.5968 - val_loss: 6317.3633\n",
      "Epoch 53/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 1363.3497 - val_loss: 6203.0723\n",
      "Epoch 54/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 1307.8071 - val_loss: 6151.9995\n",
      "Epoch 55/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1273.6962 - val_loss: 6101.7158\n",
      "Epoch 56/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1239.6185 - val_loss: 6073.6665\n",
      "Epoch 57/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 1208.5388 - val_loss: 6036.4033\n",
      "Epoch 58/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 1201.1323 - val_loss: 6029.8652\n",
      "Epoch 59/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1166.3145 - val_loss: 5943.5967\n",
      "Epoch 60/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1117.7777 - val_loss: 5906.5391\n",
      "Epoch 61/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 1080.2880 - val_loss: 5885.1118\n",
      "Epoch 62/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 1064.7129 - val_loss: 5820.7095\n",
      "Epoch 63/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 1039.0439 - val_loss: 5776.9712\n",
      "Epoch 64/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 1008.0841 - val_loss: 5737.3438\n",
      "Epoch 65/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 1032.9733 - val_loss: 5749.0356\n",
      "Epoch 66/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 917.8019 - val_loss: 5729.6738\n",
      "Epoch 67/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 924.1439 - val_loss: 5754.0679\n",
      "Epoch 68/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 907.9083 - val_loss: 5710.4507\n",
      "Epoch 69/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 855.1122 - val_loss: 5633.8062\n",
      "Epoch 70/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 847.5864 - val_loss: 5632.0039\n",
      "Epoch 71/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 798.4725 - val_loss: 5616.7993\n",
      "Epoch 72/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 770.8411 - val_loss: 5536.4570\n",
      "Epoch 73/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 751.0967 - val_loss: 5551.5737\n",
      "Epoch 74/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 744.2711 - val_loss: 5563.9863\n",
      "Epoch 75/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 708.7344 - val_loss: 5451.1538\n",
      "Epoch 76/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 669.0544 - val_loss: 5415.4189\n",
      "Epoch 77/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 655.7883 - val_loss: 5472.5645\n",
      "Epoch 78/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 632.1239 - val_loss: 5477.7070\n",
      "Epoch 79/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 616.1349 - val_loss: 5357.0015\n",
      "Epoch 80/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 600.8829 - val_loss: 5405.4116\n",
      "Epoch 81/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 548.9899 - val_loss: 5321.4248\n",
      "Epoch 82/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 534.4321 - val_loss: 5302.7461\n",
      "Epoch 83/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 518.1324 - val_loss: 5326.4326\n",
      "Epoch 84/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 482.2251 - val_loss: 5303.9795\n",
      "Epoch 85/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 489.1546 - val_loss: 5258.1880\n",
      "Epoch 86/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 488.0869 - val_loss: 5257.7095\n",
      "Epoch 87/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 445.8393 - val_loss: 5292.6816\n",
      "Epoch 88/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 434.2792 - val_loss: 5293.5483\n",
      "Epoch 89/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 421.4928 - val_loss: 5261.3564\n",
      "Epoch 90/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 425.6769 - val_loss: 5310.0181\n",
      "Epoch 91/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 407.1219 - val_loss: 5234.1987\n",
      "Epoch 92/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 391.1553 - val_loss: 5221.7632\n",
      "Epoch 93/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 416.5610 - val_loss: 5301.9688\n",
      "Epoch 94/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 396.1334 - val_loss: 5247.0278\n",
      "Epoch 95/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 369.3297 - val_loss: 5251.9624\n",
      "Epoch 96/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 364.5603 - val_loss: 5267.0771\n",
      "Epoch 97/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 14ms/step - loss: 376.4108 - val_loss: 5283.5771\n",
      "Epoch 98/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 353.5494 - val_loss: 5254.4497\n",
      "Epoch 99/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 358.5667 - val_loss: 5309.3755\n",
      "Epoch 100/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 378.6680 - val_loss: 5267.7490\n",
      "Epoch 101/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 336.2569 - val_loss: 5249.1729\n",
      "Epoch 102/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 331.2366 - val_loss: 5211.8740\n",
      "Epoch 103/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 327.1549 - val_loss: 5252.9487\n",
      "Epoch 104/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 333.3980 - val_loss: 5265.6719\n",
      "Epoch 105/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 332.8058 - val_loss: 5301.9224\n",
      "Epoch 106/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 321.1533 - val_loss: 5253.1250\n",
      "Epoch 107/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 309.3648 - val_loss: 5264.5518\n",
      "Epoch 108/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 315.5195 - val_loss: 5292.8193\n",
      "Epoch 109/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 317.5775 - val_loss: 5200.6455\n",
      "Epoch 110/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 318.6927 - val_loss: 5267.0654\n",
      "Epoch 111/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 306.3336 - val_loss: 5288.6675\n",
      "Epoch 112/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 297.5210 - val_loss: 5282.8301\n",
      "Epoch 113/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 305.8849 - val_loss: 5245.5200\n",
      "Epoch 114/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 301.8229 - val_loss: 5210.6533\n",
      "Epoch 115/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 285.4649 - val_loss: 5238.1987\n",
      "Epoch 116/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 281.6357 - val_loss: 5275.2471\n",
      "Epoch 117/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 288.4440 - val_loss: 5225.7261\n",
      "Epoch 118/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 274.2436 - val_loss: 5230.7915\n",
      "Epoch 119/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 268.2664 - val_loss: 5257.2319\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1811.2327\n",
      "[CV] END learning_rate=0.0001074063096070056, unit1=58, unit2=110, unit3=96; total time=   4.4s\n",
      "Epoch 1/1000\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 3448.7954 - val_loss: 8183.5962\n",
      "Epoch 2/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 3445.0098 - val_loss: 8179.6479\n",
      "Epoch 3/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 3441.4810 - val_loss: 8176.0635\n",
      "Epoch 4/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 3437.8411 - val_loss: 8171.9854\n",
      "Epoch 5/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 3433.9285 - val_loss: 8167.9990\n",
      "Epoch 6/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 3430.1370 - val_loss: 8163.7432\n",
      "Epoch 7/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 3426.0525 - val_loss: 8159.4795\n",
      "Epoch 8/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 3421.8687 - val_loss: 8155.1123\n",
      "Epoch 9/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 3417.6882 - val_loss: 8150.6484\n",
      "Epoch 10/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 3413.3293 - val_loss: 8145.6997\n",
      "Epoch 11/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 3408.6355 - val_loss: 8140.7202\n",
      "Epoch 12/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 3403.7410 - val_loss: 8135.3921\n",
      "Epoch 13/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 3398.4688 - val_loss: 8129.3677\n",
      "Epoch 14/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 3392.5752 - val_loss: 8122.3750\n",
      "Epoch 15/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 3385.8855 - val_loss: 8115.8608\n",
      "Epoch 16/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 3379.3215 - val_loss: 8108.1885\n",
      "Epoch 17/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 3371.9182 - val_loss: 8100.6323\n",
      "Epoch 18/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 3364.2332 - val_loss: 8091.4673\n",
      "Epoch 19/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 3355.1287 - val_loss: 8081.1885\n",
      "Epoch 20/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 3344.8281 - val_loss: 8070.2803\n",
      "Epoch 21/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 3334.0938 - val_loss: 8058.4785\n",
      "Epoch 22/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 3321.9590 - val_loss: 8044.0405\n",
      "Epoch 23/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 3307.3914 - val_loss: 8028.0718\n",
      "Epoch 24/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 3291.1401 - val_loss: 8009.1167\n",
      "Epoch 25/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 3272.6804 - val_loss: 7989.1016\n",
      "Epoch 26/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 3251.3809 - val_loss: 7962.9976\n",
      "Epoch 27/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 3224.8877 - val_loss: 7931.7783\n",
      "Epoch 28/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 3194.1570 - val_loss: 7895.7065\n",
      "Epoch 29/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 3155.8567 - val_loss: 7851.1880\n",
      "Epoch 30/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 3112.0112 - val_loss: 7799.1045\n",
      "Epoch 31/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 3056.1633 - val_loss: 7729.1582\n",
      "Epoch 32/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 2984.2676 - val_loss: 7637.4888\n",
      "Epoch 33/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 2888.5874 - val_loss: 7524.6782\n",
      "Epoch 34/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 2773.9285 - val_loss: 7388.9336\n",
      "Epoch 35/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 2637.4670 - val_loss: 7209.5044\n",
      "Epoch 36/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 2453.1582 - val_loss: 7002.4600\n",
      "Epoch 37/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 2265.3193 - val_loss: 6736.0952\n",
      "Epoch 38/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 2020.9861 - val_loss: 6569.6914\n",
      "Epoch 39/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 1885.2802 - val_loss: 6446.0586\n",
      "Epoch 40/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1817.8984 - val_loss: 6379.3564\n",
      "Epoch 41/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 1734.2695 - val_loss: 6312.9385\n",
      "Epoch 42/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1682.6451 - val_loss: 6248.0088\n",
      "Epoch 43/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 1673.5865 - val_loss: 6221.2617\n",
      "Epoch 44/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 1599.4435 - val_loss: 6182.8604\n",
      "Epoch 45/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 1577.4816 - val_loss: 6167.1616\n",
      "Epoch 46/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1536.6287 - val_loss: 6129.9526\n",
      "Epoch 47/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 1503.9214 - val_loss: 6067.6299\n",
      "Epoch 48/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1474.0662 - val_loss: 6028.1724\n",
      "Epoch 49/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 1432.0930 - val_loss: 6011.7222\n",
      "Epoch 50/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1426.1381 - val_loss: 5964.3740\n",
      "Epoch 51/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 1342.2119 - val_loss: 5936.3164\n",
      "Epoch 52/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 1340.0186 - val_loss: 5885.2080\n",
      "Epoch 53/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 1291.5288 - val_loss: 5850.3496\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1258.1411 - val_loss: 5816.3467\n",
      "Epoch 55/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 1210.7994 - val_loss: 5793.8257\n",
      "Epoch 56/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 1196.4158 - val_loss: 5773.6948\n",
      "Epoch 57/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1155.0830 - val_loss: 5731.1973\n",
      "Epoch 58/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1131.6066 - val_loss: 5741.6128\n",
      "Epoch 59/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 1099.5282 - val_loss: 5708.9292\n",
      "Epoch 60/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 1056.9626 - val_loss: 5708.9092\n",
      "Epoch 61/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1029.0555 - val_loss: 5679.9126\n",
      "Epoch 62/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 1003.8606 - val_loss: 5637.2510\n",
      "Epoch 63/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 953.3766 - val_loss: 5596.3184\n",
      "Epoch 64/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 960.2739 - val_loss: 5617.8550\n",
      "Epoch 65/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 933.1657 - val_loss: 5588.6138\n",
      "Epoch 66/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 877.0089 - val_loss: 5548.8252\n",
      "Epoch 67/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 854.1805 - val_loss: 5508.4805\n",
      "Epoch 68/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 806.7605 - val_loss: 5491.6782\n",
      "Epoch 69/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 797.5943 - val_loss: 5430.2910\n",
      "Epoch 70/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 790.2390 - val_loss: 5445.8237\n",
      "Epoch 71/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 729.7156 - val_loss: 5416.5752\n",
      "Epoch 72/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 725.1026 - val_loss: 5455.0054\n",
      "Epoch 73/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 695.2841 - val_loss: 5357.4971\n",
      "Epoch 74/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 652.8344 - val_loss: 5367.8994\n",
      "Epoch 75/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 629.4372 - val_loss: 5343.8970\n",
      "Epoch 76/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 614.8841 - val_loss: 5385.7925\n",
      "Epoch 77/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 591.2786 - val_loss: 5289.4946\n",
      "Epoch 78/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 579.7278 - val_loss: 5271.4277\n",
      "Epoch 79/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 556.9806 - val_loss: 5266.5957\n",
      "Epoch 80/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 534.9334 - val_loss: 5236.7510\n",
      "Epoch 81/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 507.4145 - val_loss: 5287.7759\n",
      "Epoch 82/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 509.0279 - val_loss: 5324.6177\n",
      "Epoch 83/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 519.4891 - val_loss: 5272.7339\n",
      "Epoch 84/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 484.1104 - val_loss: 5242.9199\n",
      "Epoch 85/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 492.6035 - val_loss: 5255.1743\n",
      "Epoch 86/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 458.9694 - val_loss: 5170.8970\n",
      "Epoch 87/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 442.2809 - val_loss: 5180.4976\n",
      "Epoch 88/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 414.6652 - val_loss: 5210.4990\n",
      "Epoch 89/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 399.2545 - val_loss: 5188.7700\n",
      "Epoch 90/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 409.8956 - val_loss: 5149.6025\n",
      "Epoch 91/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 389.8741 - val_loss: 5162.5039\n",
      "Epoch 92/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 393.6039 - val_loss: 5199.6060\n",
      "Epoch 93/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 431.0198 - val_loss: 5227.6323\n",
      "Epoch 94/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 367.9296 - val_loss: 5117.2554\n",
      "Epoch 95/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 365.1457 - val_loss: 5102.0415\n",
      "Epoch 96/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 343.2210 - val_loss: 5166.5771\n",
      "Epoch 97/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 345.5437 - val_loss: 5082.4868\n",
      "Epoch 98/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 329.0558 - val_loss: 5218.4248\n",
      "Epoch 99/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 333.4254 - val_loss: 5072.3882\n",
      "Epoch 100/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 322.3547 - val_loss: 5152.7441\n",
      "Epoch 101/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 301.9078 - val_loss: 5138.5996\n",
      "Epoch 102/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 307.7301 - val_loss: 5138.1592\n",
      "Epoch 103/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 303.3337 - val_loss: 5220.7910\n",
      "Epoch 104/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 314.9952 - val_loss: 5205.5435\n",
      "Epoch 105/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 289.4325 - val_loss: 5144.6299\n",
      "Epoch 106/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 272.9525 - val_loss: 5116.5161\n",
      "Epoch 107/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 273.8242 - val_loss: 5207.3198\n",
      "Epoch 108/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 271.8630 - val_loss: 5117.8066\n",
      "Epoch 109/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 253.3293 - val_loss: 5118.8081\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 692.2780\n",
      "[CV] END learning_rate=0.0001074063096070056, unit1=58, unit2=110, unit3=96; total time=   3.9s\n",
      "Epoch 1/1000\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 2925.7368 - val_loss: 8173.7842\n",
      "Epoch 2/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 2923.4392 - val_loss: 8171.1792\n",
      "Epoch 3/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 2921.0176 - val_loss: 8168.5254\n",
      "Epoch 4/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 2918.6377 - val_loss: 8165.8223\n",
      "Epoch 5/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 2916.1294 - val_loss: 8162.8862\n",
      "Epoch 6/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 2913.4895 - val_loss: 8160.0371\n",
      "Epoch 7/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 2910.9136 - val_loss: 8156.9912\n",
      "Epoch 8/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 2908.1411 - val_loss: 8153.7847\n",
      "Epoch 9/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 2905.3430 - val_loss: 8150.6479\n",
      "Epoch 10/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 2902.4993 - val_loss: 8147.4526\n",
      "Epoch 11/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 2899.5710 - val_loss: 8144.0474\n",
      "Epoch 12/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 2896.5571 - val_loss: 8140.5723\n",
      "Epoch 13/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 2893.3457 - val_loss: 8136.7329\n",
      "Epoch 14/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 2889.8503 - val_loss: 8132.4810\n",
      "Epoch 15/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 2886.0020 - val_loss: 8128.1792\n",
      "Epoch 16/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 2882.0911 - val_loss: 8123.7759\n",
      "Epoch 17/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 2878.1270 - val_loss: 8119.2856\n",
      "Epoch 18/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 2873.9292 - val_loss: 8114.2539\n",
      "Epoch 19/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 2869.3164 - val_loss: 8108.8794\n",
      "Epoch 20/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 2864.5164 - val_loss: 8103.2544\n",
      "Epoch 21/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 17ms/step - loss: 2859.2200 - val_loss: 8097.4136\n",
      "Epoch 22/1000\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 2853.8684 - val_loss: 8089.7905\n",
      "Epoch 23/1000\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 2846.7793 - val_loss: 8081.7490\n",
      "Epoch 24/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 2839.3657 - val_loss: 8073.8193\n",
      "Epoch 25/1000\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 2832.0659 - val_loss: 8065.5503\n",
      "Epoch 26/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 2824.4177 - val_loss: 8055.8423\n",
      "Epoch 27/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 2815.5098 - val_loss: 8045.2788\n",
      "Epoch 28/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 2805.5334 - val_loss: 8033.5356\n",
      "Epoch 29/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 2794.5317 - val_loss: 8020.1479\n",
      "Epoch 30/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 2782.0254 - val_loss: 8004.7559\n",
      "Epoch 31/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 2768.1074 - val_loss: 7989.1240\n",
      "Epoch 32/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 2752.9502 - val_loss: 7969.8521\n",
      "Epoch 33/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 2735.3081 - val_loss: 7949.0503\n",
      "Epoch 34/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 2715.3457 - val_loss: 7922.9565\n",
      "Epoch 35/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 2690.3323 - val_loss: 7893.5693\n",
      "Epoch 36/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 2662.5061 - val_loss: 7854.1924\n",
      "Epoch 37/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 2624.5605 - val_loss: 7809.8477\n",
      "Epoch 38/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 2582.5732 - val_loss: 7758.0776\n",
      "Epoch 39/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 2533.9536 - val_loss: 7696.7905\n",
      "Epoch 40/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 2475.6472 - val_loss: 7620.5229\n",
      "Epoch 41/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 2402.3279 - val_loss: 7519.7056\n",
      "Epoch 42/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 2311.4685 - val_loss: 7414.5215\n",
      "Epoch 43/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 2216.6421 - val_loss: 7290.2446\n",
      "Epoch 44/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 2098.7295 - val_loss: 7136.6304\n",
      "Epoch 45/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 1968.5319 - val_loss: 6987.0459\n",
      "Epoch 46/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 1847.0117 - val_loss: 6844.5117\n",
      "Epoch 47/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 1733.7433 - val_loss: 6697.0659\n",
      "Epoch 48/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 1624.3970 - val_loss: 6582.6162\n",
      "Epoch 49/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 1549.5266 - val_loss: 6492.6699\n",
      "Epoch 50/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 1503.2826 - val_loss: 6441.5317\n",
      "Epoch 51/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 1473.5508 - val_loss: 6423.7656\n",
      "Epoch 52/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 1453.8002 - val_loss: 6383.9150\n",
      "Epoch 53/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 1410.0139 - val_loss: 6314.1450\n",
      "Epoch 54/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 1367.9161 - val_loss: 6279.8711\n",
      "Epoch 55/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 1345.0771 - val_loss: 6275.5029\n",
      "Epoch 56/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 1332.9357 - val_loss: 6270.3389\n",
      "Epoch 57/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 1302.5768 - val_loss: 6234.6396\n",
      "Epoch 58/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 1294.1080 - val_loss: 6228.8545\n",
      "Epoch 59/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 1233.1892 - val_loss: 6183.6455\n",
      "Epoch 60/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 1220.7953 - val_loss: 6149.2285\n",
      "Epoch 61/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 1167.3896 - val_loss: 6090.8120\n",
      "Epoch 62/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 1130.0869 - val_loss: 6064.3530\n",
      "Epoch 63/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 1129.2170 - val_loss: 6003.0439\n",
      "Epoch 64/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 1085.4175 - val_loss: 5966.6113\n",
      "Epoch 65/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 1052.5575 - val_loss: 5989.2241\n",
      "Epoch 66/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 1015.4468 - val_loss: 6025.5112\n",
      "Epoch 67/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 982.2592 - val_loss: 5980.6108\n",
      "Epoch 68/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 933.7876 - val_loss: 5912.7754\n",
      "Epoch 69/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 906.3254 - val_loss: 5932.2974\n",
      "Epoch 70/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 865.0538 - val_loss: 5874.2559\n",
      "Epoch 71/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 837.7150 - val_loss: 5886.4619\n",
      "Epoch 72/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 812.8344 - val_loss: 5823.6309\n",
      "Epoch 73/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 789.4510 - val_loss: 5784.7329\n",
      "Epoch 74/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 770.9796 - val_loss: 5780.9150\n",
      "Epoch 75/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 698.0140 - val_loss: 5778.6382\n",
      "Epoch 76/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 691.7670 - val_loss: 5783.3530\n",
      "Epoch 77/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 667.7956 - val_loss: 5729.1587\n",
      "Epoch 78/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 643.2983 - val_loss: 5673.4976\n",
      "Epoch 79/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 603.8833 - val_loss: 5779.2607\n",
      "Epoch 80/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 583.9520 - val_loss: 5806.2734\n",
      "Epoch 81/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 560.6050 - val_loss: 5720.9839\n",
      "Epoch 82/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 519.6876 - val_loss: 5708.0449\n",
      "Epoch 83/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 535.9913 - val_loss: 5725.8936\n",
      "Epoch 84/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 487.0374 - val_loss: 5693.5303\n",
      "Epoch 85/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 467.3751 - val_loss: 5639.6182\n",
      "Epoch 86/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 459.6305 - val_loss: 5761.8481\n",
      "Epoch 87/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 446.4232 - val_loss: 5727.8120\n",
      "Epoch 88/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 426.3800 - val_loss: 5681.5957\n",
      "Epoch 89/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 412.4660 - val_loss: 5636.1543\n",
      "Epoch 90/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 402.4809 - val_loss: 5647.6934\n",
      "Epoch 91/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 391.2851 - val_loss: 5688.8164\n",
      "Epoch 92/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 395.0880 - val_loss: 5650.0078\n",
      "Epoch 93/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 369.9179 - val_loss: 5642.0127\n",
      "Epoch 94/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 368.2887 - val_loss: 5600.0693\n",
      "Epoch 95/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 365.9574 - val_loss: 5699.9170\n",
      "Epoch 96/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 352.4049 - val_loss: 5680.1108\n",
      "Epoch 97/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 342.8171 - val_loss: 5659.8647\n",
      "Epoch 98/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 14ms/step - loss: 337.5673 - val_loss: 5663.0371\n",
      "Epoch 99/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 331.4713 - val_loss: 5671.1699\n",
      "Epoch 100/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 328.5071 - val_loss: 5623.7539\n",
      "Epoch 101/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 334.4139 - val_loss: 5687.2378\n",
      "Epoch 102/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 317.1582 - val_loss: 5655.4854\n",
      "Epoch 103/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 319.1084 - val_loss: 5668.9976\n",
      "Epoch 104/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 306.3084 - val_loss: 5621.2368\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1275.3761\n",
      "[CV] END learning_rate=0.0001074063096070056, unit1=58, unit2=110, unit3=96; total time=   3.6s\n",
      "Epoch 1/1000\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 2563.9915 - val_loss: 8093.1855\n",
      "Epoch 2/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 2473.5457 - val_loss: 7651.2109\n",
      "Epoch 3/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 2160.5239 - val_loss: 8164.5527\n",
      "Epoch 4/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 2538.8330 - val_loss: 8075.9038\n",
      "Epoch 5/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 2490.8301 - val_loss: 8018.1104\n",
      "Epoch 6/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 2445.1506 - val_loss: 7930.6436\n",
      "Epoch 7/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 2370.1597 - val_loss: 7733.4932\n",
      "Epoch 8/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 2170.2151 - val_loss: 6595.9229\n",
      "Epoch 9/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 1660.9119 - val_loss: 237549.5312\n",
      "Epoch 10/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 89507.5156 - val_loss: 7927.2256\n",
      "Epoch 11/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 3769.2935 - val_loss: 8124.0605\n",
      "Epoch 12/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 2529.2317 - val_loss: 8084.8633\n",
      "Epoch 13/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 2502.1028 - val_loss: 8051.0620\n",
      "Epoch 14/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 2477.6135 - val_loss: 8016.6177\n",
      "Epoch 15/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 2453.9934 - val_loss: 7986.4756\n",
      "Epoch 16/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 2432.6414 - val_loss: 7954.0371\n",
      "Epoch 17/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 2410.6160 - val_loss: 7925.2354\n",
      "Epoch 18/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 2391.1870 - val_loss: 7898.8188\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 3491.8745\n",
      "[CV] END learning_rate=0.003944783267943095, unit1=73, unit2=18, unit3=73; total time=   0.8s\n",
      "Epoch 1/1000\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 3429.5559 - val_loss: 8112.2686\n",
      "Epoch 2/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 3348.1550 - val_loss: 7929.3218\n",
      "Epoch 3/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 2903.9229 - val_loss: 6140.2866\n",
      "Epoch 4/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 21313.1465 - val_loss: 8268.8281\n",
      "Epoch 5/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 3576.3140 - val_loss: 8088.8696\n",
      "Epoch 6/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 3279.4204 - val_loss: 7272.4941\n",
      "Epoch 7/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 484168.3438 - val_loss: 400149824.0000\n",
      "Epoch 8/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: inf - val_loss: nan\n",
      "Epoch 9/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: nan - val_loss: nan\n",
      "Epoch 11/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: nan - val_loss: nan\n",
      "Epoch 12/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: nan - val_loss: nan\n",
      "Epoch 13/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: nan - val_loss: nan\n",
      "2/2 [==============================] - 0s 3ms/step - loss: nan\n",
      "[CV] END learning_rate=0.003944783267943095, unit1=73, unit2=18, unit3=73; total time=   0.6s\n",
      "Epoch 1/1000\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 2909.0781 - val_loss: 8064.5586\n",
      "Epoch 2/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 2724.5378 - val_loss: 6325.3735\n",
      "Epoch 3/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 1935.0018 - val_loss: 252593.9375\n",
      "Epoch 4/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 74690.3594 - val_loss: 8224.4648\n",
      "Epoch 5/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 2917.3042 - val_loss: 7825.5479\n",
      "Epoch 6/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 6918.0103 - val_loss: 3006257.0000\n",
      "Epoch 7/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: inf - val_loss: nan\n",
      "Epoch 8/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: nan - val_loss: nan\n",
      "Epoch 9/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: nan - val_loss: nan\n",
      "Epoch 11/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: nan - val_loss: nan\n",
      "Epoch 12/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: nan - val_loss: nan\n",
      "2/2 [==============================] - 0s 3ms/step - loss: nan\n",
      "[CV] END learning_rate=0.003944783267943095, unit1=73, unit2=18, unit3=73; total time=   0.6s\n",
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "H:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [-1485.79256185            nan            nan -2422.91764323\n",
      " -1448.48498535 -2822.76875814 -2434.40441895            nan\n",
      " -1259.6289266             nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 30ms/step - loss: 2984.2981 - val_loss: 8177.5479\n",
      "Epoch 2/1000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 2979.7119 - val_loss: 8172.0571\n",
      "Epoch 3/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 2975.3682 - val_loss: 8166.5649\n",
      "Epoch 4/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 2970.7778 - val_loss: 8161.0908\n",
      "Epoch 5/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 2966.3057 - val_loss: 8155.4824\n",
      "Epoch 6/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 2961.7871 - val_loss: 8149.7041\n",
      "Epoch 7/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 2956.9075 - val_loss: 8143.5576\n",
      "Epoch 8/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 2951.8645 - val_loss: 8137.0659\n",
      "Epoch 9/1000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 2946.4878 - val_loss: 8130.3203\n",
      "Epoch 10/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 2940.8894 - val_loss: 8123.0562\n",
      "Epoch 11/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 2934.8489 - val_loss: 8115.2280\n",
      "Epoch 12/1000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 2928.1917 - val_loss: 8106.6191\n",
      "Epoch 13/1000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 2920.9583 - val_loss: 8096.9688\n",
      "Epoch 14/1000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 2912.7590 - val_loss: 8086.2842\n",
      "Epoch 15/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 2903.8081 - val_loss: 8074.1714\n",
      "Epoch 16/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 2893.4551 - val_loss: 8060.4985\n",
      "Epoch 17/1000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 2882.1406 - val_loss: 8044.8564\n",
      "Epoch 18/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 2868.2688 - val_loss: 8026.4702\n",
      "Epoch 19/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 2852.6619 - val_loss: 8004.8335\n",
      "Epoch 20/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 2833.9158 - val_loss: 7978.7246\n",
      "Epoch 21/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 2810.7146 - val_loss: 7947.0708\n",
      "Epoch 22/1000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 2783.1655 - val_loss: 7907.4341\n",
      "Epoch 23/1000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 2748.9736 - val_loss: 7858.6367\n",
      "Epoch 24/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 2706.0071 - val_loss: 7796.7861\n",
      "Epoch 25/1000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 2648.8965 - val_loss: 7716.2144\n",
      "Epoch 26/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 2577.0232 - val_loss: 7609.5830\n",
      "Epoch 27/1000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 2480.8911 - val_loss: 7471.0220\n",
      "Epoch 28/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 2364.3247 - val_loss: 7297.0103\n",
      "Epoch 29/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 2208.7566 - val_loss: 7077.0464\n",
      "Epoch 30/1000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 2036.1183 - val_loss: 6837.8691\n",
      "Epoch 31/1000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 1866.2738 - val_loss: 6614.1577\n",
      "Epoch 32/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 1720.2333 - val_loss: 6413.6147\n",
      "Epoch 33/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 1607.8846 - val_loss: 6288.8906\n",
      "Epoch 34/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 1568.6643 - val_loss: 6213.8374\n",
      "Epoch 35/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 1527.1466 - val_loss: 6185.3760\n",
      "Epoch 36/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 1500.0894 - val_loss: 6151.4302\n",
      "Epoch 37/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 1444.4464 - val_loss: 6094.3315\n",
      "Epoch 38/1000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 1405.8497 - val_loss: 6044.3193\n",
      "Epoch 39/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 1391.1012 - val_loss: 6027.6675\n",
      "Epoch 40/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 1345.3181 - val_loss: 5963.1455\n",
      "Epoch 41/1000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 1306.2739 - val_loss: 5938.3027\n",
      "Epoch 42/1000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 1282.1776 - val_loss: 5900.7188\n",
      "Epoch 43/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 1254.4092 - val_loss: 5827.4727\n",
      "Epoch 44/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 1211.2938 - val_loss: 5775.3950\n",
      "Epoch 45/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 1173.6299 - val_loss: 5735.0088\n",
      "Epoch 46/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 1151.4426 - val_loss: 5695.0356\n",
      "Epoch 47/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 1105.7686 - val_loss: 5680.8394\n",
      "Epoch 48/1000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 1117.1183 - val_loss: 5620.9048\n",
      "Epoch 49/1000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 1039.5872 - val_loss: 5614.8052\n",
      "Epoch 50/1000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 1016.6445 - val_loss: 5612.6782\n",
      "Epoch 51/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 965.9054 - val_loss: 5568.4795\n",
      "Epoch 52/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 937.2679 - val_loss: 5521.0952\n",
      "Epoch 53/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 909.4072 - val_loss: 5488.2837\n",
      "Epoch 54/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 889.9010 - val_loss: 5463.4624\n",
      "Epoch 55/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 861.0898 - val_loss: 5398.5474\n",
      "Epoch 56/1000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 833.0790 - val_loss: 5407.5615\n",
      "Epoch 57/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 783.3212 - val_loss: 5400.2324\n",
      "Epoch 58/1000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 807.9651 - val_loss: 5463.3613\n",
      "Epoch 59/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 740.9355 - val_loss: 5339.5312\n",
      "Epoch 60/1000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 709.7903 - val_loss: 5310.2515\n",
      "Epoch 61/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 694.3879 - val_loss: 5264.7446\n",
      "Epoch 62/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 689.2849 - val_loss: 5268.1260\n",
      "Epoch 63/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 675.0152 - val_loss: 5217.6958\n",
      "Epoch 64/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 664.5883 - val_loss: 5236.7891\n",
      "Epoch 65/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 630.2940 - val_loss: 5274.6206\n",
      "Epoch 66/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 613.4866 - val_loss: 5255.2388\n",
      "Epoch 67/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 588.7855 - val_loss: 5173.1831\n",
      "Epoch 68/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 598.9386 - val_loss: 5232.4609\n",
      "Epoch 69/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 552.1909 - val_loss: 5173.1104\n",
      "Epoch 70/1000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 534.2944 - val_loss: 5170.6582\n",
      "Epoch 71/1000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 520.6933 - val_loss: 5160.1802\n",
      "Epoch 72/1000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 513.7271 - val_loss: 5203.7158\n",
      "Epoch 73/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 525.9949 - val_loss: 5122.4580\n",
      "Epoch 74/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 491.7039 - val_loss: 5201.6968\n",
      "Epoch 75/1000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 485.8639 - val_loss: 5144.0391\n",
      "Epoch 76/1000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 470.7430 - val_loss: 5114.6655\n",
      "Epoch 77/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 478.1724 - val_loss: 5091.6777\n",
      "Epoch 78/1000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 476.2841 - val_loss: 5135.4810\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 454.0162 - val_loss: 5113.7886\n",
      "Epoch 80/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 469.2382 - val_loss: 5071.1191\n",
      "Epoch 81/1000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 474.4254 - val_loss: 5068.4429\n",
      "Epoch 82/1000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 445.3460 - val_loss: 5113.4019\n",
      "Epoch 83/1000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 428.1314 - val_loss: 5119.1030\n",
      "Epoch 84/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 429.0365 - val_loss: 5029.0918\n",
      "Epoch 85/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 437.1215 - val_loss: 5086.4722\n",
      "Epoch 86/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 405.7032 - val_loss: 5033.1909\n",
      "Epoch 87/1000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 398.0746 - val_loss: 5075.7827\n",
      "Epoch 88/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 387.7173 - val_loss: 5102.6587\n",
      "Epoch 89/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 413.1609 - val_loss: 5063.3594\n",
      "Epoch 90/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 377.3166 - val_loss: 5017.4253\n",
      "Epoch 91/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 405.6455 - val_loss: 4991.6821\n",
      "Epoch 92/1000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 383.4699 - val_loss: 5082.5806\n",
      "Epoch 93/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 363.5800 - val_loss: 5003.3843\n",
      "Epoch 94/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 365.1834 - val_loss: 4983.3457\n",
      "Epoch 95/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 356.2272 - val_loss: 5015.1201\n",
      "Epoch 96/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 359.2492 - val_loss: 5051.9126\n",
      "Epoch 97/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 354.3049 - val_loss: 5009.0161\n",
      "Epoch 98/1000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 346.6307 - val_loss: 5023.1245\n",
      "Epoch 99/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 370.3157 - val_loss: 4990.3267\n",
      "Epoch 100/1000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 336.6915 - val_loss: 4938.2939\n",
      "Epoch 101/1000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 353.7858 - val_loss: 4965.2900\n",
      "Epoch 102/1000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 324.0026 - val_loss: 4963.4419\n",
      "Epoch 103/1000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 317.3067 - val_loss: 4964.5088\n",
      "Epoch 104/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 327.6717 - val_loss: 4898.1514\n",
      "Epoch 105/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 333.2217 - val_loss: 4942.9131\n",
      "Epoch 106/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 313.7155 - val_loss: 4924.0381\n",
      "Epoch 107/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 302.9581 - val_loss: 4948.5967\n",
      "Epoch 108/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 309.3687 - val_loss: 4924.7798\n",
      "Epoch 109/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 306.0258 - val_loss: 4973.9258\n",
      "Epoch 110/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 324.5952 - val_loss: 4956.6777\n",
      "Epoch 111/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 290.0630 - val_loss: 4911.7690\n",
      "Epoch 112/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 289.8061 - val_loss: 4909.4390\n",
      "Epoch 113/1000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 293.0347 - val_loss: 4897.1411\n",
      "Epoch 114/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 278.2768 - val_loss: 4965.6929\n",
      "Epoch 115/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 282.2934 - val_loss: 4963.4839\n",
      "Epoch 116/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 294.3647 - val_loss: 4921.2539\n",
      "Epoch 117/1000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 276.0639 - val_loss: 4886.0420\n",
      "Epoch 118/1000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 281.6144 - val_loss: 4896.4492\n",
      "Epoch 119/1000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 265.5460 - val_loss: 4935.5400\n",
      "Epoch 120/1000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 267.1302 - val_loss: 4880.8076\n",
      "Epoch 121/1000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 258.8889 - val_loss: 4844.9263\n",
      "Epoch 122/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 257.4118 - val_loss: 4951.8262\n",
      "Epoch 123/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 274.9471 - val_loss: 4958.1504\n",
      "Epoch 124/1000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 291.8233 - val_loss: 4833.2388\n",
      "Epoch 125/1000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 266.6920 - val_loss: 4867.0444\n",
      "Epoch 126/1000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 247.8555 - val_loss: 4865.2051\n",
      "Epoch 127/1000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 249.0022 - val_loss: 4974.7979\n",
      "Epoch 128/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 257.6909 - val_loss: 4956.2207\n",
      "Epoch 129/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 257.3794 - val_loss: 4831.3389\n",
      "Epoch 130/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 247.5451 - val_loss: 4885.0151\n",
      "Epoch 131/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 262.4377 - val_loss: 4976.1016\n",
      "Epoch 132/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 245.2157 - val_loss: 4896.1987\n",
      "Epoch 133/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 237.0760 - val_loss: 4847.0493\n",
      "Epoch 134/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 227.2979 - val_loss: 4975.6167\n",
      "Epoch 135/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 236.6673 - val_loss: 4888.1743\n",
      "Epoch 136/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 223.4250 - val_loss: 4838.0571\n",
      "Epoch 137/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 228.2695 - val_loss: 4865.9658\n",
      "Epoch 138/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 219.5034 - val_loss: 4916.4468\n",
      "Epoch 139/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 219.9702 - val_loss: 4864.5352\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3,\n",
       "                   estimator=<keras.wrappers.scikit_learn.KerasRegressor object at 0x00000201E46E9D00>,\n",
       "                   param_distributions={'learning_rate': [0.00037896177388938045,\n",
       "                                                          0.00023654624838037315,\n",
       "                                                          0.0003371662054603376,\n",
       "                                                          0.008393083024295716,\n",
       "                                                          0.005745644407776698,\n",
       "                                                          0.0035904250477495985,\n",
       "                                                          0.009970850890059911,\n",
       "                                                          0.009743539091207155,\n",
       "                                                          0.00862676151178373,\n",
       "                                                          0.00312444976...\n",
       "                                                          0.0002296607974108677,\n",
       "                                                          0.00020813145027850355,\n",
       "                                                          0.001332580206163112, ...],\n",
       "                                        'unit1': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10,\n",
       "                                                  11, 12, 13, 14, 15, 16, 17,\n",
       "                                                  18, 19, 20, 21, 22, 23, 24,\n",
       "                                                  25, 26, 27, 28, 29, 30, ...],\n",
       "                                        'unit2': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10,\n",
       "                                                  11, 12, 13, 14, 15, 16, 17,\n",
       "                                                  18, 19, 20, 21, 22, 23, 24,\n",
       "                                                  25, 26, 27, 28, 29, 30, ...],\n",
       "                                        'unit3': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10,\n",
       "                                                  11, 12, 13, 14, 15, 16, 17,\n",
       "                                                  18, 19, 20, 21, 22, 23, 24,\n",
       "                                                  25, 26, 27, 28, 29, 30, ...]},\n",
       "                   verbose=2)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import reciprocal\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "param_distribs = {\n",
    "    \"unit1\": np.arange(1,100) .tolist(),\n",
    "    \"unit2\": np.arange(1,200) .tolist(),\n",
    "    \"unit3\": np.arange(1,100) .tolist(),\n",
    "    \"learning_rate\": reciprocal(1e-4, 1e-2)      .rvs(1000).tolist(),\n",
    "}\n",
    "\n",
    "rnd_search_cv = RandomizedSearchCV(keras_reg, param_distribs, n_iter=10,cv=3, verbose=2)\n",
    "rnd_search_cv.fit(X_train, y_train, epochs=1000,\n",
    "                  validation_data=(X_train_full, y_train_full),\n",
    "                  callbacks=[keras.callbacks.EarlyStopping(patience=10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "60013e8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'unit3': 96,\n",
       " 'unit2': 110,\n",
       " 'unit1': 58,\n",
       " 'learning_rate': 0.0001074063096070056}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "cfab9ece",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1259.628926595052"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2269fbf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = rnd_search_cv.best_estimator_.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86201809",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "84c130a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "deep_predict = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "709e1ea2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.14292762668515713"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "r2_score(y_valid,deep_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "f27847cb",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_valid_backup' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-106-bb35330fc7d7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX_valid_backup\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'X_valid_backup' is not defined"
     ]
    }
   ],
   "source": [
    "X_valid_backup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "18499e7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200     36\n",
       "142     15\n",
       "151      0\n",
       "114     72\n",
       "81       1\n",
       "43       0\n",
       "58     102\n",
       "175      1\n",
       "71      19\n",
       "166     20\n",
       "130      1\n",
       "13       1\n",
       "87       0\n",
       "208     38\n",
       "117      3\n",
       "122     71\n",
       "99       4\n",
       "50      20\n",
       "26      22\n",
       "11      47\n",
       "74     229\n",
       "141     90\n",
       "204      2\n",
       "77       2\n",
       "149     21\n",
       "192      1\n",
       "63       1\n",
       "12       4\n",
       "65       4\n",
       "51       4\n",
       "133      1\n",
       "2      100\n",
       "91       1\n",
       "191     38\n",
       "1       74\n",
       "112      9\n",
       "24       1\n",
       "46     948\n",
       "3        8\n",
       "179      0\n",
       "59      34\n",
       "164     32\n",
       "203     11\n",
       "Name: LUT, dtype: int64"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "410da835",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "127      1\n",
       "108     68\n",
       "69      14\n",
       "84       0\n",
       "97     123\n",
       "      ... \n",
       "106      0\n",
       "14     170\n",
       "92       1\n",
       "179      0\n",
       "102     44\n",
       "Name: LUT, Length: 169, dtype: int64"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6d695f1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 4ms/step - loss: 58.6963\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 29.1148\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 271.5947\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 397.6594\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 36.1284\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 19.6233\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 14.7397\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 12.1934\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 10.4712\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 9.0539\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 7.9604\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 7.0873\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 20.4979\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 18.3104\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 18.3919\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 20.9277\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 19.1724\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 19.1145\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 18.8052\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 17.8670\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 16.7895\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 17.6328\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 16.6086\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 22.4309\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 22.2753\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 21.2144\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 20.3069\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 19.7270\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 18.9854\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 22.5943\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 21.5300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.9708\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 22.6867\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 22.0928\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 21.4186\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 38.0179\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 37.1373\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 34.9858\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 33.2669\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 32.8241\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 31.3185\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 30.6014\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 30.5888\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 29.7860\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 29.0780\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 28.2926\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 29.5157\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 106.5273\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 110.8818\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 107.3441\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 105.1381\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 103.1913\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 101.1600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 98.4603\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 96.8294\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 104.2235\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 102.0139\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 100.5642\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 109.9649\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 102.0766\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 98.7947\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 95.8264\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 94.8017\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 93.2702\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 90.8342\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 92.2116\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 90.9573\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 89.2453\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 88.1510\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 87.5336\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 85.0416\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 92.3764\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 91.3128\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 90.6328\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 89.2769\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 88.7812\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 87.1048\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 85.9496\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 86.0573\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 120.6456\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 117.8666\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 115.2217\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 113.4651\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 111.0241\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 109.3355\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 107.8142\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 106.4108\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 105.1943\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 103.3590\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 101.3632\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 100.7895\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 98.8514\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 99.6797\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 96.4760\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 95.2219\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 94.7791\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 93.3703\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 92.4026\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 93.3560\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 91.4674\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 90.0777\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 89.1898\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 87.4441\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 86.6578\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 85.7461\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 84.5649\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 101.3778\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 98.0089\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 96.8706\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 97.3413\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 94.9401\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 95.6776\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 94.2005\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 92.6235\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 92.6490\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 103.2650\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 100.8611\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 103.5039\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 102.8245\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 102.2060\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 101.1206\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 100.4673\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 101.2691\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 101.6557\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 99.4374\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 99.6614\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 123.6458\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 121.3547\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 121.8686\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 119.8205\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 120.7087\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 120.6280\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 120.4231\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 120.0824\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 119.4804\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_learning_curves(model, X_train_full, y_train_full)\n",
    "#plt.axis([0, 200, 0, 200])                         # not shown in the book\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "80d0ad85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 31.302113 ],\n",
       "       [ 13.202502 ],\n",
       "       [  1.4642506],\n",
       "       [ 17.41863  ],\n",
       "       [  1.4345452],\n",
       "       [ 15.217053 ],\n",
       "       [105.78109  ],\n",
       "       [  6.984596 ],\n",
       "       [ 22.208517 ],\n",
       "       [ 24.478987 ],\n",
       "       [ 10.146852 ],\n",
       "       [  2.697756 ],\n",
       "       [ 26.683569 ],\n",
       "       [ 40.61043  ],\n",
       "       [  2.24936  ],\n",
       "       [ 10.2791815],\n",
       "       [  3.617224 ],\n",
       "       [  7.230478 ],\n",
       "       [ 26.78847  ],\n",
       "       [ 40.987774 ],\n",
       "       [233.39195  ],\n",
       "       [ 73.843506 ],\n",
       "       [ 25.366823 ],\n",
       "       [  1.3949833],\n",
       "       [ 13.382822 ],\n",
       "       [  2.8901322],\n",
       "       [  1.9197996],\n",
       "       [  2.89565  ],\n",
       "       [ 24.560827 ],\n",
       "       [  5.523542 ],\n",
       "       [  5.0518036],\n",
       "       [ 95.76241  ],\n",
       "       [  2.3377774],\n",
       "       [ 38.192425 ],\n",
       "       [ 60.7633   ],\n",
       "       [  5.6340957],\n",
       "       [  2.9980829],\n",
       "       [950.7049   ],\n",
       "       [  9.212509 ],\n",
       "       [  2.8258276],\n",
       "       [ 33.661537 ],\n",
       "       [ 32.743523 ],\n",
       "       [ 18.795252 ]], dtype=float32)"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict = model.predict(X_valid)\n",
    "predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "f1500aa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200     36\n",
       "142     15\n",
       "151      0\n",
       "114     72\n",
       "81       1\n",
       "43       0\n",
       "58     102\n",
       "175      1\n",
       "71      19\n",
       "166     20\n",
       "130      1\n",
       "13       1\n",
       "87       0\n",
       "208     38\n",
       "117      3\n",
       "122     71\n",
       "99       4\n",
       "50      20\n",
       "26      22\n",
       "11      47\n",
       "74     229\n",
       "141     90\n",
       "204      2\n",
       "77       2\n",
       "149     21\n",
       "192      1\n",
       "63       1\n",
       "12       4\n",
       "65       4\n",
       "51       4\n",
       "133      1\n",
       "2      100\n",
       "91       1\n",
       "191     38\n",
       "1       74\n",
       "112      9\n",
       "24       1\n",
       "46     948\n",
       "3        8\n",
       "179      0\n",
       "59      34\n",
       "164     32\n",
       "203     11\n",
       "Name: LUT, dtype: int64"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "4d9a0ba2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(1)\n",
    "plt.clf()\n",
    "ax=plt.axes(aspect='equal')\n",
    "plt.scatter(y_valid,predict)\n",
    "plt.xlabel('True Values')\n",
    "plt.ylabel('Predictions')\n",
    "Lims=[0,300]\n",
    "plt.xlim(Lims)\n",
    "plt.ylim(Lims)\n",
    "plt.plot(Lims,Lims)\n",
    "plt.grid(False)\n",
    "    \n",
    "plt.figure(2)\n",
    "plt.clf()\n",
    "plt.hist(predict,bins=30)\n",
    "plt.xlabel('LUT_ANN_Prediction')\n",
    "plt.ylabel('Count')\n",
    "plt.grid(False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33806898",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
