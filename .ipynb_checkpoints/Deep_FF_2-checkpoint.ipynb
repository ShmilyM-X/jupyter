{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "be7433a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tarfile\n",
    "import urllib.request\n",
    "\n",
    "RES_PATH = os.path.join(\"res_datasets\",\"resourceing\")\n",
    "\n",
    "def fetch_resource_data(res_path=RES_PATH):\n",
    "    if not os.path.isdir(res_path):\n",
    "        os.makedirs(res_path)\n",
    "##创建文件夹路径函数\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def plot_learning_curves(model, X, y):\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    train_errors, val_errors = [], []\n",
    "    for m in range(1, len(X_train) + 1):\n",
    "        model.fit(X_train[:m], y_train[:m])\n",
    "        y_train_predict = model.predict(X_train[:m])\n",
    "        y_val_predict = model.predict(X_val)\n",
    "        train_errors.append(mean_squared_error(y_train[:m], y_train_predict))\n",
    "        val_errors.append(mean_squared_error(y_val, y_val_predict))\n",
    "\n",
    "    plt.plot(np.sqrt(train_errors), \"r-\", linewidth=2, label=\"train\")\n",
    "    plt.plot(np.sqrt(val_errors), \"b-\", linewidth=2, label=\"val\")\n",
    "    plt.legend(loc=\"upper right\", fontsize=14)   # not shown in the book\n",
    "    plt.xlabel(\"Training set size\", fontsize=14) # not shown\n",
    "    plt.ylabel(\"RMSE\", fontsize=14)              # not shown\n",
    "    \n",
    "fetch_resource_data() ##调用创建\n",
    "\n",
    "##读取CSV文件\n",
    "import pandas as pd\n",
    "\n",
    "def load_res_data(res_path = RES_PATH,file_name=\"resource.csv\"):\n",
    "    csv_path = os.path.join(RES_PATH,file_name)\n",
    "    return pd.read_csv(csv_path) \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "0bfef604",
   "metadata": {},
   "outputs": [],
   "source": [
    "##数据处理\n",
    "resource_origin_data = load_res_data()  #get origin csv data\n",
    "\n",
    "#%matplotlib inline\n",
    "#import matplotlib.pyplot as plt\n",
    "#resource_origin_data.hist(bins=50, figsize=(20,15))\n",
    "#plt.show() #data plot show\n",
    "\n",
    "resource_origin_data_lut = resource_origin_data.dropna(subset = [\"FF\"])\n",
    "resource_origin_data_lut=resource_origin_data_lut.drop(\"LUT\",axis=1)\n",
    "resource_origin_data_lut=resource_origin_data_lut.drop(\"BUFG\",axis=1)\n",
    "resource_origin_data_lut=resource_origin_data_lut.drop(\"IO\",axis=1)\n",
    "resource_origin_data_lut=resource_origin_data_lut.drop(\"ModuleName\",axis=1)\n",
    "resource_origin_data_lut=resource_origin_data_lut.drop(\"PARAMETERVALUE\",axis=1)\n",
    "resource_origin_data_lut=resource_origin_data_lut.drop(\"ModuleInsts\",axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "25d04eab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 126 entries, 0 to 139\n",
      "Data columns (total 41 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   AlwaysConstructs         126 non-null    int64  \n",
      " 1   AssignLHSPortNum         126 non-null    int64  \n",
      " 2   AssignLHSWidth           126 non-null    int64  \n",
      " 3   AssignRHSPortNum         126 non-null    int64  \n",
      " 4   AssignRHSWidth           126 non-null    int64  \n",
      " 5   AssignStmts              126 non-null    int64  \n",
      " 6   BLOCKINGASSIGN           126 non-null    int64  \n",
      " 7   CASECONDITIONNUM         126 non-null    int64  \n",
      " 8   CASECONDITIONWIDTH       126 non-null    int64  \n",
      " 9   CASEITEMCONDITIONNUM     126 non-null    int64  \n",
      " 10  CASEITEMCONDITIOWIDTH    126 non-null    int64  \n",
      " 11  CASEITEMNUM              126 non-null    int64  \n",
      " 12  CONDITIONALELSE          126 non-null    int64  \n",
      " 13  CONDITIONALIF            126 non-null    int64  \n",
      " 14  CONDITIONALTHEN          126 non-null    int64  \n",
      " 15  FORBLOCK                 126 non-null    int64  \n",
      " 16  FORTIMES                 126 non-null    int64  \n",
      " 17  INDEXMEMRORY             126 non-null    int64  \n",
      " 18  INOUT                    126 non-null    int64  \n",
      " 19  INOUTWIDTH               126 non-null    int64  \n",
      " 20  INPUT                    126 non-null    int64  \n",
      " 21  INPUTWIDTH               126 non-null    int64  \n",
      " 22  MIN                      126 non-null    int64  \n",
      " 23  NonBlockingAssign        126 non-null    int64  \n",
      " 24  NonBlockingLeftPortNum   126 non-null    int64  \n",
      " 25  NonBlockingRightPortNum  126 non-null    int64  \n",
      " 26  OUTPUT                   126 non-null    int64  \n",
      " 27  OUTPUTWIDTH              126 non-null    int64  \n",
      " 28  PARAMETERNUM             126 non-null    int64  \n",
      " 29  QUESTIONCOLON            126 non-null    int64  \n",
      " 30  QUESTIONCOLONELSE        126 non-null    int64  \n",
      " 31  QUESTIONCOLONIF          126 non-null    int64  \n",
      " 32  QUESTIONCOLONTHEN        126 non-null    int64  \n",
      " 33  REDAND                   126 non-null    int64  \n",
      " 34  REDAOR                   126 non-null    int64  \n",
      " 35  REDXOR                   126 non-null    int64  \n",
      " 36  REG                      126 non-null    int64  \n",
      " 37  REGWIDTH                 126 non-null    int64  \n",
      " 38  WIRENUM                  126 non-null    int64  \n",
      " 39  WIREWIDTH                126 non-null    int64  \n",
      " 40  FF                       126 non-null    float64\n",
      "dtypes: float64(1), int64(40)\n",
      "memory usage: 41.3 KB\n"
     ]
    }
   ],
   "source": [
    "#数据信息\n",
    "resource_origin_data_lut.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "81c08573",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AlwaysConstructs</th>\n",
       "      <th>AssignLHSPortNum</th>\n",
       "      <th>AssignLHSWidth</th>\n",
       "      <th>AssignRHSPortNum</th>\n",
       "      <th>AssignRHSWidth</th>\n",
       "      <th>AssignStmts</th>\n",
       "      <th>BLOCKINGASSIGN</th>\n",
       "      <th>CASECONDITIONNUM</th>\n",
       "      <th>CASECONDITIONWIDTH</th>\n",
       "      <th>CASEITEMCONDITIONNUM</th>\n",
       "      <th>...</th>\n",
       "      <th>QUESTIONCOLONIF</th>\n",
       "      <th>QUESTIONCOLONTHEN</th>\n",
       "      <th>REDAND</th>\n",
       "      <th>REDAOR</th>\n",
       "      <th>REDXOR</th>\n",
       "      <th>REG</th>\n",
       "      <th>REGWIDTH</th>\n",
       "      <th>WIRENUM</th>\n",
       "      <th>WIREWIDTH</th>\n",
       "      <th>FF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>126.000000</td>\n",
       "      <td>126.000000</td>\n",
       "      <td>126.00000</td>\n",
       "      <td>126.000000</td>\n",
       "      <td>126.000000</td>\n",
       "      <td>126.000000</td>\n",
       "      <td>126.000000</td>\n",
       "      <td>126.000000</td>\n",
       "      <td>126.000000</td>\n",
       "      <td>126.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>126.000000</td>\n",
       "      <td>126.000000</td>\n",
       "      <td>126.000000</td>\n",
       "      <td>126.000000</td>\n",
       "      <td>126.000000</td>\n",
       "      <td>126.000000</td>\n",
       "      <td>126.000000</td>\n",
       "      <td>126.000000</td>\n",
       "      <td>126.000000</td>\n",
       "      <td>126.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.452381</td>\n",
       "      <td>0.936508</td>\n",
       "      <td>2.15873</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>3.095238</td>\n",
       "      <td>0.984127</td>\n",
       "      <td>5.190476</td>\n",
       "      <td>0.420635</td>\n",
       "      <td>1.150794</td>\n",
       "      <td>1.238095</td>\n",
       "      <td>...</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.515873</td>\n",
       "      <td>0.230159</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>3.015873</td>\n",
       "      <td>15.492063</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>1.777778</td>\n",
       "      <td>17.063492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.092299</td>\n",
       "      <td>3.388796</td>\n",
       "      <td>7.49764</td>\n",
       "      <td>2.346669</td>\n",
       "      <td>10.716289</td>\n",
       "      <td>3.382269</td>\n",
       "      <td>11.930274</td>\n",
       "      <td>0.941090</td>\n",
       "      <td>2.724900</td>\n",
       "      <td>6.669847</td>\n",
       "      <td>...</td>\n",
       "      <td>0.485210</td>\n",
       "      <td>0.485210</td>\n",
       "      <td>2.382382</td>\n",
       "      <td>1.529249</td>\n",
       "      <td>5.184593</td>\n",
       "      <td>4.814950</td>\n",
       "      <td>26.967757</td>\n",
       "      <td>1.536518</td>\n",
       "      <td>7.155293</td>\n",
       "      <td>70.962835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>64.00000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>168.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>768.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       AlwaysConstructs  AssignLHSPortNum  AssignLHSWidth  AssignRHSPortNum  \\\n",
       "count        126.000000        126.000000       126.00000        126.000000   \n",
       "mean           1.452381          0.936508         2.15873          0.928571   \n",
       "std            2.092299          3.388796         7.49764          2.346669   \n",
       "min            0.000000          0.000000         0.00000          0.000000   \n",
       "25%            1.000000          0.000000         0.00000          0.000000   \n",
       "50%            1.000000          0.000000         0.00000          0.000000   \n",
       "75%            1.000000          1.000000         1.00000          1.000000   \n",
       "max           17.000000         33.000000        64.00000         19.000000   \n",
       "\n",
       "       AssignRHSWidth  AssignStmts  BLOCKINGASSIGN  CASECONDITIONNUM  \\\n",
       "count      126.000000   126.000000      126.000000        126.000000   \n",
       "mean         3.095238     0.984127        5.190476          0.420635   \n",
       "std         10.716289     3.382269       11.930274          0.941090   \n",
       "min          0.000000     0.000000        0.000000          0.000000   \n",
       "25%          0.000000     0.000000        0.000000          0.000000   \n",
       "50%          0.000000     0.000000        0.500000          0.000000   \n",
       "75%          1.000000     1.000000        4.000000          0.000000   \n",
       "max         96.000000    33.000000       80.000000          5.000000   \n",
       "\n",
       "       CASECONDITIONWIDTH  CASEITEMCONDITIONNUM  ...  QUESTIONCOLONIF  \\\n",
       "count          126.000000            126.000000  ...       126.000000   \n",
       "mean             1.150794              1.238095  ...         0.142857   \n",
       "std              2.724900              6.669847  ...         0.485210   \n",
       "min              0.000000              0.000000  ...         0.000000   \n",
       "25%              0.000000              0.000000  ...         0.000000   \n",
       "50%              0.000000              0.000000  ...         0.000000   \n",
       "75%              0.000000              0.000000  ...         0.000000   \n",
       "max             14.000000             64.000000  ...         3.000000   \n",
       "\n",
       "       QUESTIONCOLONTHEN      REDAND      REDAOR      REDXOR         REG  \\\n",
       "count         126.000000  126.000000  126.000000  126.000000  126.000000   \n",
       "mean            0.142857    0.515873    0.230159    0.666667    3.015873   \n",
       "std             0.485210    2.382382    1.529249    5.184593    4.814950   \n",
       "min             0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%             0.000000    0.000000    0.000000    0.000000    1.000000   \n",
       "50%             0.000000    0.000000    0.000000    0.000000    1.000000   \n",
       "75%             0.000000    0.000000    0.000000    0.000000    3.000000   \n",
       "max             3.000000   16.000000   16.000000   56.000000   32.000000   \n",
       "\n",
       "         REGWIDTH     WIRENUM   WIREWIDTH          FF  \n",
       "count  126.000000  126.000000  126.000000  126.000000  \n",
       "mean    15.492063    0.444444    1.777778   17.063492  \n",
       "std     26.967757    1.536518    7.155293   70.962835  \n",
       "min      0.000000    0.000000    0.000000    0.000000  \n",
       "25%      0.000000    0.000000    0.000000    0.000000  \n",
       "50%      4.000000    0.000000    0.000000    2.000000  \n",
       "75%     17.000000    0.000000    0.000000    9.000000  \n",
       "max    168.000000   12.000000   66.000000  768.000000  \n",
       "\n",
       "[8 rows x 41 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resource_origin_data_lut.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "2f73c8ca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FF                         1.000000\n",
       "REGWIDTH                   0.404814\n",
       "OUTPUTWIDTH                0.340722\n",
       "FORBLOCK                   0.251895\n",
       "INPUTWIDTH                 0.232194\n",
       "REG                        0.178221\n",
       "NonBlockingLeftPortNum     0.159190\n",
       "NonBlockingAssign          0.154441\n",
       "AssignRHSWidth             0.127115\n",
       "AlwaysConstructs           0.105950\n",
       "AssignLHSWidth             0.102512\n",
       "CONDITIONALIF              0.096179\n",
       "CONDITIONALTHEN            0.096179\n",
       "MIN                        0.094977\n",
       "CONDITIONALELSE            0.091307\n",
       "AssignRHSPortNum           0.051719\n",
       "WIREWIDTH                  0.038960\n",
       "WIRENUM                    0.027693\n",
       "INDEXMEMRORY               0.026838\n",
       "CASEITEMCONDITIONNUM       0.024899\n",
       "NonBlockingRightPortNum    0.023370\n",
       "QUESTIONCOLON              0.021110\n",
       "QUESTIONCOLONELSE          0.021110\n",
       "QUESTIONCOLONIF            0.021110\n",
       "QUESTIONCOLONTHEN          0.021110\n",
       "PARAMETERNUM               0.016360\n",
       "AssignLHSPortNum           0.016251\n",
       "REDAND                     0.014143\n",
       "AssignStmts                0.013170\n",
       "OUTPUT                     0.007807\n",
       "REDXOR                     0.000841\n",
       "CASEITEMNUM               -0.000174\n",
       "REDAOR                    -0.002126\n",
       "INPUT                     -0.003208\n",
       "CASECONDITIONWIDTH        -0.009359\n",
       "CASECONDITIONNUM          -0.014059\n",
       "BLOCKINGASSIGN            -0.014434\n",
       "INOUTWIDTH                -0.017708\n",
       "CASEITEMCONDITIOWIDTH     -0.018392\n",
       "INOUT                     -0.018855\n",
       "FORTIMES                  -0.021592\n",
       "Name: FF, dtype: float64"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#相关性分析\n",
    "corr_matrix=resource_origin_data_lut.corr()\n",
    "corr_matrix[\"FF\"].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "2fd8d5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#特征优化\n",
    "resource_lut = resource_origin_data_lut[\"FF\"].copy() #label data\n",
    "resource_lut_data = resource_origin_data_lut.drop(\"FF\",axis=1) #feature data\n",
    "resource_label = list(resource_lut_data) #labal list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f8e7acfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#数据分割\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "#训练集、测试集、验证集\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(resource_lut_data, resource_lut, test_size=0.2,random_state=42)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "7eecddc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#数据标准化\n",
    "scaler = StandardScaler() \n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_valid = scaler.transform(X_valid)\n",
    "X_test = scaler.transform(X_test)\n",
    "X_train_full = scaler.transform(X_train_full)\n",
    "X_data_full = scaler.transform(resource_lut_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "cf04fcac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#深度学习\n",
    "\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ebc9345f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(117, 59)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "aba9a350",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "input_ = keras.layers.Input(shape=X_train.shape[1:])\n",
    "hidden1 = keras.layers.Dense(59, activation=\"relu\")(input_)\n",
    "#hidden2 = keras.layers.Dense(150, activation=\"relu\")(hidden1)\n",
    "concat = keras.layers.concatenate([input_, hidden1])\n",
    "output = keras.layers.Dense(1)(concat)\n",
    "model = keras.models.Model(inputs=[input_], outputs=[output])\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(monitor='val_loss',patience=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "252b1313",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Input(shape=X_train.shape[1:]),\n",
    "    keras.layers.Dense(59, activation=\"relu\"),\n",
    "    keras.layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "3fe69cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Input(shape=X_train.shape[1:]),\n",
    "    keras.layers.Dense(59, activation=\"relu\"),\n",
    "    keras.layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "eae277e4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 5387.9834 - val_loss: 1385.2418\n",
      "Epoch 2/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 4483.6548 - val_loss: 1070.2001\n",
      "Epoch 3/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 7063.9263 - val_loss: 1415.6160\n",
      "Epoch 4/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 4570.5010 - val_loss: 1241.0851\n",
      "Epoch 5/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 4404.9766 - val_loss: 1207.7156\n",
      "Epoch 6/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 4386.5366 - val_loss: 1197.5310\n",
      "Epoch 7/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 4379.1294 - val_loss: 1195.9274\n",
      "Epoch 8/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4378.1514 - val_loss: 1198.1783\n",
      "Epoch 9/1000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 4384.8374 - val_loss: 1198.9763\n",
      "Epoch 10/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 4383.2544 - val_loss: 1196.4496\n",
      "Epoch 11/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 4391.1890 - val_loss: 1200.5061\n",
      "Epoch 12/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 4374.7402 - val_loss: 1195.9319\n",
      "Epoch 13/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 4390.8032 - val_loss: 1197.0281\n",
      "Epoch 14/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 4393.8535 - val_loss: 1195.9354\n",
      "Epoch 15/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4382.2266 - val_loss: 1202.1465\n",
      "Epoch 16/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 4382.9438 - val_loss: 1202.2991\n",
      "Epoch 17/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4381.6025 - val_loss: 1205.8643\n",
      "Epoch 18/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 4392.7173 - val_loss: 1196.7701\n",
      "Epoch 19/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 4388.1675 - val_loss: 1196.0609\n",
      "Epoch 20/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4382.3774 - val_loss: 1196.0588\n",
      "Epoch 21/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4372.0801 - val_loss: 1197.3459\n",
      "Epoch 22/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4384.0469 - val_loss: 1201.8645\n",
      "Epoch 23/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4376.1030 - val_loss: 1196.9302\n",
      "Epoch 24/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4380.2720 - val_loss: 1196.4734\n",
      "Epoch 25/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4386.4136 - val_loss: 1195.9178\n",
      "Epoch 26/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4391.5869 - val_loss: 1196.5491\n",
      "Epoch 27/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4407.5918 - val_loss: 1197.2950\n",
      "Epoch 28/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4401.1021 - val_loss: 1196.9233\n",
      "Epoch 29/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4385.4995 - val_loss: 1197.7722\n",
      "Epoch 30/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4371.3735 - val_loss: 1195.9143\n",
      "Epoch 31/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4385.5366 - val_loss: 1196.3247\n",
      "Epoch 32/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4385.7207 - val_loss: 1195.9443\n",
      "Epoch 33/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4381.3652 - val_loss: 1195.9564\n",
      "Epoch 34/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4398.2437 - val_loss: 1197.3264\n",
      "Epoch 35/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4375.3472 - val_loss: 1196.9388\n",
      "Epoch 36/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4392.8252 - val_loss: 1196.6267\n",
      "Epoch 37/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4398.4253 - val_loss: 1197.4785\n",
      "Epoch 38/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4376.4463 - val_loss: 1196.5067\n",
      "Epoch 39/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4373.4268 - val_loss: 1199.6204\n",
      "Epoch 40/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4369.1641 - val_loss: 1196.1882\n",
      "Epoch 41/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4378.6641 - val_loss: 1195.8658\n",
      "Epoch 42/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4378.2485 - val_loss: 1199.9823\n",
      "Epoch 43/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4387.3047 - val_loss: 1196.2623\n",
      "Epoch 44/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4381.9961 - val_loss: 1199.7183\n",
      "Epoch 45/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4376.3271 - val_loss: 1196.1282\n",
      "Epoch 46/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4386.4385 - val_loss: 1196.5485\n",
      "Epoch 47/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4399.4790 - val_loss: 1207.2972\n",
      "Epoch 48/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4386.5815 - val_loss: 1196.4426\n",
      "Epoch 49/1000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 4387.9585 - val_loss: 1196.0271\n",
      "Epoch 50/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4388.9038 - val_loss: 1196.4216\n",
      "Epoch 51/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4390.3057 - val_loss: 1197.4573\n",
      "Epoch 52/1000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 4394.4673 - val_loss: 1197.8605\n",
      "Epoch 53/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4385.5601 - val_loss: 1198.8878\n",
      "Epoch 54/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4373.3804 - val_loss: 1197.4218\n",
      "Epoch 55/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4383.9639 - val_loss: 1196.4878\n",
      "Epoch 56/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4375.5894 - val_loss: 1198.6981\n",
      "Epoch 57/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4373.4888 - val_loss: 1197.7965\n",
      "Epoch 58/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4380.4590 - val_loss: 1201.6526\n",
      "Epoch 59/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4389.9873 - val_loss: 1196.5433\n",
      "Epoch 60/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4377.6821 - val_loss: 1196.1127\n",
      "Epoch 61/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4387.4409 - val_loss: 1196.3444\n",
      "Epoch 62/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4400.5693 - val_loss: 1197.9592\n",
      "Epoch 63/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4382.4014 - val_loss: 1195.9675\n",
      "Epoch 64/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4389.5669 - val_loss: 1195.8907\n",
      "Epoch 65/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4397.0444 - val_loss: 1202.2507\n",
      "Epoch 66/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4375.8008 - val_loss: 1196.5349\n",
      "Epoch 67/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4388.0273 - val_loss: 1196.5085\n",
      "Epoch 68/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4384.9116 - val_loss: 1199.9144\n",
      "Epoch 69/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4383.3506 - val_loss: 1204.9263\n",
      "Epoch 70/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4403.6528 - val_loss: 1196.7844\n",
      "Epoch 71/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4390.8608 - val_loss: 1195.8619\n",
      "Epoch 72/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4382.6694 - val_loss: 1196.1495\n",
      "Epoch 73/1000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 4387.5396 - val_loss: 1196.7737\n",
      "Epoch 74/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4384.1797 - val_loss: 1196.8704\n",
      "Epoch 75/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4387.9873 - val_loss: 1196.7412\n",
      "Epoch 76/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4381.3853 - val_loss: 1195.8619\n",
      "Epoch 77/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4386.2026 - val_loss: 1195.8722\n",
      "Epoch 78/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4388.7197 - val_loss: 1197.8914\n",
      "Epoch 79/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 6ms/step - loss: 4385.4136 - val_loss: 1200.0642\n",
      "Epoch 80/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4382.2261 - val_loss: 1199.7632\n",
      "Epoch 81/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4403.8936 - val_loss: 1197.0134\n",
      "Epoch 82/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4380.6167 - val_loss: 1196.0880\n",
      "Epoch 83/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4382.2334 - val_loss: 1196.2849\n",
      "Epoch 84/1000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 4370.6401 - val_loss: 1196.1910\n",
      "Epoch 85/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4376.4653 - val_loss: 1200.8752\n",
      "Epoch 86/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4394.2607 - val_loss: 1197.7108\n",
      "Epoch 87/1000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 4395.5898 - val_loss: 1197.4095\n",
      "Epoch 88/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4402.3994 - val_loss: 1195.9214\n",
      "Epoch 89/1000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 4390.3984 - val_loss: 1198.9896\n",
      "Epoch 90/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4397.1797 - val_loss: 1197.0392\n",
      "Epoch 91/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4370.6597 - val_loss: 1196.0669\n",
      "Epoch 92/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4395.3232 - val_loss: 1200.1705\n",
      "Epoch 93/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4375.6260 - val_loss: 1196.4919\n",
      "Epoch 94/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4379.5176 - val_loss: 1196.0603\n",
      "Epoch 95/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4392.2661 - val_loss: 1195.9136\n",
      "Epoch 96/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4387.2988 - val_loss: 1195.9203\n",
      "Epoch 97/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4391.5088 - val_loss: 1197.2615\n",
      "Epoch 98/1000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 4393.9082 - val_loss: 1196.2727\n",
      "Epoch 99/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4384.1001 - val_loss: 1196.0557\n",
      "Epoch 100/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4407.0190 - val_loss: 1198.2668\n",
      "Epoch 101/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4374.6699 - val_loss: 1196.2526\n",
      "Epoch 102/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4379.6021 - val_loss: 1196.1829\n",
      "Epoch 103/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4402.7642 - val_loss: 1196.0787\n",
      "Epoch 104/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4397.7354 - val_loss: 1199.4657\n",
      "Epoch 105/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4386.2466 - val_loss: 1196.4968\n",
      "Epoch 106/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4380.0210 - val_loss: 1195.8625\n",
      "Epoch 107/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4410.5874 - val_loss: 1196.7629\n",
      "Epoch 108/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4390.2822 - val_loss: 1199.1010\n",
      "Epoch 109/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4377.7695 - val_loss: 1196.0200\n",
      "Epoch 110/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4382.9883 - val_loss: 1196.4398\n",
      "Epoch 111/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4376.6650 - val_loss: 1199.2847\n",
      "Epoch 112/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4387.4355 - val_loss: 1196.4226\n",
      "Epoch 113/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4380.2627 - val_loss: 1204.9871\n",
      "Epoch 114/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4377.4131 - val_loss: 1197.3981\n",
      "Epoch 115/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4373.4619 - val_loss: 1197.4750\n",
      "Epoch 116/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4378.9009 - val_loss: 1195.8981\n",
      "Epoch 117/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4383.1904 - val_loss: 1201.2161\n",
      "Epoch 118/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4386.1064 - val_loss: 1197.8666\n",
      "Epoch 119/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4393.5254 - val_loss: 1195.9779\n",
      "Epoch 120/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4376.0508 - val_loss: 1196.0322\n",
      "Epoch 121/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4374.4028 - val_loss: 1196.5946\n",
      "Epoch 122/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4372.5581 - val_loss: 1197.3794\n",
      "Epoch 123/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4373.8623 - val_loss: 1197.7498\n",
      "Epoch 124/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4397.6455 - val_loss: 1198.4512\n",
      "Epoch 125/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4384.4946 - val_loss: 1196.8762\n",
      "Epoch 126/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4381.5703 - val_loss: 1196.9019\n",
      "Epoch 127/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4389.0508 - val_loss: 1198.1459\n",
      "Epoch 128/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4372.8472 - val_loss: 1197.1746\n",
      "Epoch 129/1000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 4383.9644 - val_loss: 1204.0942\n",
      "Epoch 130/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4430.3135 - val_loss: 1196.1295\n",
      "Epoch 131/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4420.7656 - val_loss: 1212.5499\n",
      "Epoch 132/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4386.3364 - val_loss: 1196.8857\n",
      "Epoch 133/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4378.7563 - val_loss: 1197.3718\n",
      "Epoch 134/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4387.3813 - val_loss: 1196.9958\n",
      "Epoch 135/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4382.8032 - val_loss: 1198.2439\n",
      "Epoch 136/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4378.1924 - val_loss: 1196.9757\n",
      "Epoch 137/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4400.1133 - val_loss: 1196.2112\n",
      "Epoch 138/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4398.5190 - val_loss: 1198.0491\n",
      "Epoch 139/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4390.0054 - val_loss: 1195.9437\n",
      "Epoch 140/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4389.9531 - val_loss: 1195.8704\n",
      "Epoch 141/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4392.3560 - val_loss: 1196.6729\n",
      "Epoch 142/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4379.5630 - val_loss: 1198.6803\n",
      "Epoch 143/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4377.9229 - val_loss: 1197.9583\n",
      "Epoch 144/1000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 4375.6172 - val_loss: 1198.3962\n",
      "Epoch 145/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4390.5034 - val_loss: 1198.7102\n",
      "Epoch 146/1000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 4385.2915 - val_loss: 1196.4634\n",
      "Epoch 147/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 4382.9058 - val_loss: 1196.0909\n",
      "Epoch 148/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4380.3740 - val_loss: 1196.7200\n",
      "Epoch 149/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4385.6353 - val_loss: 1196.8518\n",
      "Epoch 150/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4387.2534 - val_loss: 1195.9844\n",
      "Epoch 151/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4389.2505 - val_loss: 1196.0665\n",
      "Epoch 152/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4382.8188 - val_loss: 1201.1035\n",
      "Epoch 153/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4410.8281 - val_loss: 1196.1564\n",
      "Epoch 154/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4389.9878 - val_loss: 1196.5671\n",
      "Epoch 155/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4386.1484 - val_loss: 1198.3134\n",
      "Epoch 156/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 6ms/step - loss: 4380.4937 - val_loss: 1199.2318\n",
      "Epoch 157/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4375.2339 - val_loss: 1197.4844\n",
      "Epoch 158/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4380.6260 - val_loss: 1195.9832\n",
      "Epoch 159/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4379.2686 - val_loss: 1196.0488\n",
      "Epoch 160/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4371.8179 - val_loss: 1195.9802\n",
      "Epoch 161/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4380.3735 - val_loss: 1197.1102\n",
      "Epoch 162/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4380.3823 - val_loss: 1200.2646\n",
      "Epoch 163/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4384.6831 - val_loss: 1199.4302\n",
      "Epoch 164/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4383.8516 - val_loss: 1196.7531\n",
      "Epoch 165/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4379.6729 - val_loss: 1199.2898\n",
      "Epoch 166/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4380.2764 - val_loss: 1196.6265\n",
      "Epoch 167/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4387.4946 - val_loss: 1196.4951\n",
      "Epoch 168/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4388.0415 - val_loss: 1195.9153\n",
      "Epoch 169/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4381.6499 - val_loss: 1196.3250\n",
      "Epoch 170/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4388.1318 - val_loss: 1195.8811\n",
      "Epoch 171/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4386.0332 - val_loss: 1197.2179\n",
      "Epoch 172/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4385.8804 - val_loss: 1195.8781\n",
      "Epoch 173/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4373.8208 - val_loss: 1196.9875\n",
      "Epoch 174/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4386.9346 - val_loss: 1195.9612\n",
      "Epoch 175/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4375.7256 - val_loss: 1197.5262\n",
      "Epoch 176/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4400.5000 - val_loss: 1195.8621\n",
      "Epoch 177/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4382.1211 - val_loss: 1196.2305\n",
      "Epoch 178/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4383.9897 - val_loss: 1196.3269\n",
      "Epoch 179/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4382.5161 - val_loss: 1196.0726\n",
      "Epoch 180/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4383.0391 - val_loss: 1195.9709\n",
      "Epoch 181/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4379.9009 - val_loss: 1199.2009\n",
      "Epoch 182/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4379.8315 - val_loss: 1196.1255\n",
      "Epoch 183/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4376.0981 - val_loss: 1196.0122\n",
      "Epoch 184/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4386.9761 - val_loss: 1196.4750\n",
      "Epoch 185/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4376.4248 - val_loss: 1195.9628\n",
      "Epoch 186/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4388.8452 - val_loss: 1203.9060\n",
      "Epoch 187/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4387.8413 - val_loss: 1199.9573\n",
      "Epoch 188/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4387.4702 - val_loss: 1198.4093\n",
      "Epoch 189/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4393.8965 - val_loss: 1195.8744\n",
      "Epoch 190/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4385.8628 - val_loss: 1197.4873\n",
      "Epoch 191/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 4382.5181 - val_loss: 1198.7781\n",
      "Epoch 192/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4382.7212 - val_loss: 1195.9617\n",
      "Epoch 193/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4379.9785 - val_loss: 1197.4453\n",
      "Epoch 194/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4380.9541 - val_loss: 1199.7460\n",
      "Epoch 195/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4390.5293 - val_loss: 1195.9271\n",
      "Epoch 196/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4396.0464 - val_loss: 1195.9222\n",
      "Epoch 197/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4400.0142 - val_loss: 1195.9482\n",
      "Epoch 198/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4394.3169 - val_loss: 1196.6345\n",
      "Epoch 199/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4381.4722 - val_loss: 1196.0002\n",
      "Epoch 200/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4387.6855 - val_loss: 1197.9478\n",
      "Epoch 201/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4374.1235 - val_loss: 1196.0173\n",
      "Epoch 202/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4372.6621 - val_loss: 1196.9209\n",
      "Epoch 203/1000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 4384.6216 - val_loss: 1196.9600\n",
      "Epoch 204/1000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 4393.7637 - val_loss: 1196.0391\n",
      "Epoch 205/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4397.2896 - val_loss: 1196.1442\n",
      "Epoch 206/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4391.8252 - val_loss: 1195.8694\n",
      "Epoch 207/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4383.1729 - val_loss: 1196.5293\n",
      "Epoch 208/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4382.4722 - val_loss: 1195.9275\n",
      "Epoch 209/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4397.8247 - val_loss: 1200.3053\n",
      "Epoch 210/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4384.5415 - val_loss: 1198.7535\n",
      "Epoch 211/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4432.7783 - val_loss: 1196.2471\n",
      "Epoch 212/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4379.4990 - val_loss: 1196.1796\n",
      "Epoch 213/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4395.0190 - val_loss: 1196.3088\n",
      "Epoch 214/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4382.1050 - val_loss: 1195.9310\n",
      "Epoch 215/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4385.5630 - val_loss: 1197.2133\n",
      "Epoch 216/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4383.2036 - val_loss: 1195.9075\n",
      "Epoch 217/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4386.9722 - val_loss: 1197.1991\n",
      "Epoch 218/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4390.0078 - val_loss: 1196.6462\n",
      "Epoch 219/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4382.2739 - val_loss: 1201.2640\n",
      "Epoch 220/1000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 4399.7891 - val_loss: 1196.0281\n",
      "Epoch 221/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 4391.2603 - val_loss: 1195.9585\n",
      "Epoch 222/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4374.6392 - val_loss: 1197.1204\n",
      "Epoch 223/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 4400.4624 - val_loss: 1197.2683\n",
      "Epoch 224/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4395.9868 - val_loss: 1195.9398\n",
      "Epoch 225/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4397.1021 - val_loss: 1197.9493\n",
      "Epoch 226/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4377.9058 - val_loss: 1196.1560\n",
      "Epoch 227/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4386.8345 - val_loss: 1198.7638\n",
      "Epoch 228/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4388.6025 - val_loss: 1197.8562\n",
      "Epoch 229/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4382.8984 - val_loss: 1196.0083\n",
      "Epoch 230/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4380.1489 - val_loss: 1195.8824\n",
      "Epoch 231/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4382.2915 - val_loss: 1195.8621\n",
      "Epoch 232/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4388.3252 - val_loss: 1200.2550\n",
      "Epoch 233/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 6ms/step - loss: 4383.6660 - val_loss: 1196.0955\n",
      "Epoch 234/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4387.6709 - val_loss: 1195.8762\n",
      "Epoch 235/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4372.6958 - val_loss: 1197.7429\n",
      "Epoch 236/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4386.9863 - val_loss: 1199.2854\n",
      "Epoch 237/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4381.4341 - val_loss: 1195.8900\n",
      "Epoch 238/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4411.4624 - val_loss: 1196.1010\n",
      "Epoch 239/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4372.2466 - val_loss: 1196.5780\n",
      "Epoch 240/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4394.0928 - val_loss: 1196.8622\n",
      "Epoch 241/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4377.3447 - val_loss: 1196.2882\n",
      "Epoch 242/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4386.8096 - val_loss: 1196.6135\n",
      "Epoch 243/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4387.4512 - val_loss: 1200.7850\n",
      "Epoch 244/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4387.9326 - val_loss: 1196.1169\n",
      "Epoch 245/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4372.5708 - val_loss: 1195.9364\n",
      "Epoch 246/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4375.7529 - val_loss: 1196.5959\n",
      "Epoch 247/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4390.5640 - val_loss: 1196.1232\n",
      "Epoch 248/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4372.7041 - val_loss: 1196.8412\n",
      "Epoch 249/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4385.2578 - val_loss: 1197.9913\n",
      "Epoch 250/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4389.7144 - val_loss: 1197.7368\n",
      "Epoch 251/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4370.6562 - val_loss: 1197.1371\n",
      "Epoch 252/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4405.3320 - val_loss: 1196.3992\n",
      "Epoch 253/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4384.3604 - val_loss: 1199.8795\n",
      "Epoch 254/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4382.3174 - val_loss: 1199.2400\n",
      "Epoch 255/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4383.6484 - val_loss: 1197.0890\n",
      "Epoch 256/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4379.3003 - val_loss: 1197.2223\n",
      "Epoch 257/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4390.7725 - val_loss: 1195.9772\n",
      "Epoch 258/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4386.9575 - val_loss: 1195.8619\n",
      "Epoch 259/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4395.9248 - val_loss: 1196.2322\n",
      "Epoch 260/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4378.6948 - val_loss: 1198.0334\n",
      "Epoch 261/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4392.7222 - val_loss: 1196.9963\n",
      "Epoch 262/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4370.8965 - val_loss: 1196.8210\n",
      "Epoch 263/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4401.9351 - val_loss: 1195.9443\n",
      "Epoch 264/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4387.6055 - val_loss: 1196.7223\n",
      "Epoch 265/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4383.8516 - val_loss: 1196.7467\n",
      "Epoch 266/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4381.4097 - val_loss: 1196.7924\n",
      "Epoch 267/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4390.1167 - val_loss: 1195.8752\n",
      "Epoch 268/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4388.8916 - val_loss: 1197.5319\n",
      "Epoch 269/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4398.1616 - val_loss: 1196.3762\n",
      "Epoch 270/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4375.8853 - val_loss: 1195.9602\n",
      "Epoch 271/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4377.2764 - val_loss: 1195.9805\n",
      "Epoch 272/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4402.1416 - val_loss: 1208.7244\n",
      "Epoch 273/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4399.2275 - val_loss: 1198.1681\n",
      "Epoch 274/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4394.6924 - val_loss: 1196.2937\n",
      "Epoch 275/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4383.7134 - val_loss: 1197.5690\n",
      "Epoch 276/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4413.0703 - val_loss: 1196.2480\n",
      "Epoch 277/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4387.6353 - val_loss: 1197.1514\n",
      "Epoch 278/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4390.2354 - val_loss: 1202.2145\n",
      "Epoch 279/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4397.8008 - val_loss: 1195.9489\n",
      "Epoch 280/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4377.6172 - val_loss: 1195.8743\n",
      "Epoch 281/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4385.0249 - val_loss: 1196.3475\n",
      "Epoch 282/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4379.4556 - val_loss: 1200.5490\n",
      "Epoch 283/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4378.9380 - val_loss: 1197.9148\n",
      "Epoch 284/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4374.0107 - val_loss: 1196.8093\n",
      "Epoch 285/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4387.4448 - val_loss: 1197.3481\n",
      "Epoch 286/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 4401.5493 - val_loss: 1199.5416\n",
      "Epoch 287/1000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 4399.7129 - val_loss: 1199.9692\n",
      "Epoch 288/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4384.8853 - val_loss: 1195.9045\n",
      "Epoch 289/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4397.3569 - val_loss: 1200.0975\n",
      "Epoch 290/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4395.1099 - val_loss: 1196.5043\n",
      "Epoch 291/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4379.1689 - val_loss: 1198.4045\n",
      "Epoch 292/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4386.9790 - val_loss: 1196.7532\n",
      "Epoch 293/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4384.8086 - val_loss: 1196.2172\n",
      "Epoch 294/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4387.8770 - val_loss: 1203.8915\n",
      "Epoch 295/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4389.1812 - val_loss: 1208.1705\n",
      "Epoch 296/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4385.4897 - val_loss: 1206.6135\n",
      "Epoch 297/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4373.7158 - val_loss: 1196.0730\n",
      "Epoch 298/1000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 4381.3516 - val_loss: 1197.4543\n",
      "Epoch 299/1000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 4385.6177 - val_loss: 1196.9758\n",
      "Epoch 300/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 4396.1846 - val_loss: 1195.8621\n",
      "Epoch 301/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4379.7026 - val_loss: 1196.0703\n",
      "Epoch 302/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4405.9043 - val_loss: 1199.2542\n",
      "Epoch 303/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4398.4707 - val_loss: 1195.8695\n",
      "Epoch 304/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4377.2065 - val_loss: 1196.0740\n",
      "Epoch 305/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4384.6846 - val_loss: 1197.3486\n",
      "Epoch 306/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4391.4038 - val_loss: 1199.7861\n",
      "Epoch 307/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4386.4189 - val_loss: 1198.9966\n",
      "Epoch 308/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4386.6504 - val_loss: 1195.9664\n",
      "Epoch 309/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4402.0317 - val_loss: 1196.1738\n",
      "Epoch 310/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 6ms/step - loss: 4387.8740 - val_loss: 1198.1470\n",
      "Epoch 311/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4382.0210 - val_loss: 1200.4713\n",
      "Epoch 312/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4379.3696 - val_loss: 1196.2061\n",
      "Epoch 313/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4376.5708 - val_loss: 1195.8645\n",
      "Epoch 314/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4373.3779 - val_loss: 1196.1481\n",
      "Epoch 315/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4403.8159 - val_loss: 1195.8658\n",
      "Epoch 316/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4376.1343 - val_loss: 1195.9255\n",
      "Epoch 317/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4382.4365 - val_loss: 1198.0880\n",
      "Epoch 318/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4385.1953 - val_loss: 1196.6957\n",
      "Epoch 319/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4382.5571 - val_loss: 1195.9203\n",
      "Epoch 320/1000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 4388.3970 - val_loss: 1195.9177\n",
      "Epoch 321/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4379.9634 - val_loss: 1196.2128\n",
      "Epoch 322/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4388.8975 - val_loss: 1204.2012\n",
      "Epoch 323/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4394.8071 - val_loss: 1195.9076\n",
      "Epoch 324/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4380.1997 - val_loss: 1196.8932\n",
      "Epoch 325/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4379.3140 - val_loss: 1200.0092\n",
      "Epoch 326/1000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 4392.9316 - val_loss: 1196.3221\n",
      "Epoch 327/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4388.1353 - val_loss: 1202.9625\n",
      "Epoch 328/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4405.0762 - val_loss: 1196.0415\n",
      "Epoch 329/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4378.5767 - val_loss: 1195.8843\n",
      "Epoch 330/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4374.3672 - val_loss: 1199.3199\n",
      "Epoch 331/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4396.7192 - val_loss: 1207.2075\n",
      "Epoch 332/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4403.8613 - val_loss: 1211.3494\n",
      "Epoch 333/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4393.3013 - val_loss: 1205.1021\n",
      "Epoch 334/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4391.7109 - val_loss: 1198.0100\n",
      "Epoch 335/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4397.0688 - val_loss: 1206.2427\n",
      "Epoch 336/1000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 4393.8970 - val_loss: 1195.9490\n",
      "Epoch 337/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4377.9048 - val_loss: 1195.8621\n",
      "Epoch 338/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4390.0200 - val_loss: 1196.9373\n",
      "Epoch 339/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4403.9048 - val_loss: 1195.8948\n",
      "Epoch 340/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4390.7983 - val_loss: 1195.9775\n",
      "Epoch 341/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4397.7700 - val_loss: 1200.6002\n",
      "Epoch 342/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4383.0073 - val_loss: 1197.8867\n",
      "Epoch 343/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4380.0835 - val_loss: 1197.0114\n",
      "Epoch 344/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4380.5181 - val_loss: 1203.7107\n",
      "Epoch 345/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4383.5303 - val_loss: 1195.8776\n",
      "Epoch 346/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4385.4097 - val_loss: 1195.9324\n",
      "Epoch 347/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4375.3628 - val_loss: 1198.9257\n",
      "Epoch 348/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4388.4878 - val_loss: 1201.4152\n",
      "Epoch 349/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4384.3193 - val_loss: 1197.7399\n",
      "Epoch 350/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4382.0171 - val_loss: 1200.5857\n",
      "Epoch 351/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4379.5078 - val_loss: 1195.8715\n",
      "Epoch 352/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4392.8350 - val_loss: 1196.6100\n",
      "Epoch 353/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4377.4766 - val_loss: 1196.0500\n",
      "Epoch 354/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4406.5249 - val_loss: 1196.2924\n",
      "Epoch 355/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4385.1763 - val_loss: 1199.0847\n",
      "Epoch 356/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4380.2598 - val_loss: 1195.9489\n",
      "Epoch 357/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4407.1724 - val_loss: 1195.9001\n",
      "Epoch 358/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4411.9536 - val_loss: 1195.9590\n",
      "Epoch 359/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4372.9316 - val_loss: 1196.6499\n",
      "Epoch 360/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4380.1792 - val_loss: 1200.8809\n",
      "Epoch 361/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4395.9453 - val_loss: 1196.9083\n",
      "Epoch 362/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4384.0254 - val_loss: 1202.6774\n",
      "Epoch 363/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4387.4302 - val_loss: 1205.0286\n",
      "Epoch 364/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4397.2378 - val_loss: 1196.1526\n",
      "Epoch 365/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4379.2729 - val_loss: 1197.5728\n",
      "Epoch 366/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4378.8628 - val_loss: 1198.6711\n",
      "Epoch 367/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4380.7197 - val_loss: 1198.9946\n",
      "Epoch 368/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4374.7910 - val_loss: 1196.2449\n",
      "Epoch 369/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4380.9678 - val_loss: 1199.2532\n",
      "Epoch 370/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4393.8755 - val_loss: 1207.4911\n",
      "Epoch 371/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4393.3267 - val_loss: 1199.0377\n",
      "Epoch 372/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4392.8345 - val_loss: 1196.3793\n",
      "Epoch 373/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4386.7183 - val_loss: 1196.2498\n",
      "Epoch 374/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4377.6206 - val_loss: 1197.8386\n",
      "Epoch 375/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4387.8804 - val_loss: 1196.1482\n",
      "Epoch 376/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4379.2812 - val_loss: 1197.6111\n",
      "Epoch 377/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4382.0259 - val_loss: 1196.3602\n",
      "Epoch 378/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4381.7437 - val_loss: 1200.3328\n",
      "Epoch 379/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4396.4810 - val_loss: 1195.8740\n",
      "Epoch 380/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4391.2148 - val_loss: 1201.4235\n",
      "Epoch 381/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4390.0874 - val_loss: 1195.9309\n",
      "Epoch 382/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4381.7734 - val_loss: 1195.9342\n",
      "Epoch 383/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4384.0913 - val_loss: 1196.6931\n",
      "Epoch 384/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4381.0366 - val_loss: 1198.2334\n",
      "Epoch 385/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4380.1123 - val_loss: 1196.3640\n",
      "Epoch 386/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4381.1982 - val_loss: 1197.1580\n",
      "Epoch 387/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 6ms/step - loss: 4390.9385 - val_loss: 1198.5061\n",
      "Epoch 388/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4378.6172 - val_loss: 1196.1765\n",
      "Epoch 389/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4380.4692 - val_loss: 1196.1072\n",
      "Epoch 390/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4399.6494 - val_loss: 1196.1498\n",
      "Epoch 391/1000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 4383.3784 - val_loss: 1196.6714\n",
      "Epoch 392/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4378.9062 - val_loss: 1199.9476\n",
      "Epoch 393/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4395.4180 - val_loss: 1197.6798\n",
      "Epoch 394/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4377.1875 - val_loss: 1199.0271\n",
      "Epoch 395/1000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 4373.7476 - val_loss: 1197.9418\n",
      "Epoch 396/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4375.6021 - val_loss: 1195.9297\n",
      "Epoch 397/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4387.4253 - val_loss: 1201.7125\n",
      "Epoch 398/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4381.2466 - val_loss: 1205.5754\n",
      "Epoch 399/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4377.0376 - val_loss: 1196.0826\n",
      "Epoch 400/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4384.8691 - val_loss: 1195.9486\n",
      "Epoch 401/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4407.8022 - val_loss: 1207.0802\n",
      "Epoch 402/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4403.6782 - val_loss: 1209.2198\n",
      "Epoch 403/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4386.5820 - val_loss: 1197.4071\n",
      "Epoch 404/1000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 4398.7339 - val_loss: 1198.7473\n",
      "Epoch 405/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4382.0073 - val_loss: 1204.7554\n",
      "Epoch 406/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4387.4165 - val_loss: 1206.8698\n",
      "Epoch 407/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4389.0850 - val_loss: 1197.7271\n",
      "Epoch 408/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4377.7378 - val_loss: 1201.7715\n",
      "Epoch 409/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4409.0386 - val_loss: 1195.9221\n",
      "Epoch 410/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4387.9780 - val_loss: 1199.4998\n",
      "Epoch 411/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4379.7305 - val_loss: 1195.8898\n",
      "Epoch 412/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4382.0166 - val_loss: 1199.8468\n",
      "Epoch 413/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4373.3784 - val_loss: 1196.1145\n",
      "Epoch 414/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4392.4609 - val_loss: 1199.2122\n",
      "Epoch 415/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4403.2593 - val_loss: 1197.6669\n",
      "Epoch 416/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4380.3428 - val_loss: 1195.8635\n",
      "Epoch 417/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4371.4810 - val_loss: 1195.9646\n",
      "Epoch 418/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4386.7217 - val_loss: 1196.0339\n",
      "Epoch 419/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4397.1831 - val_loss: 1196.0621\n",
      "Epoch 420/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4385.8584 - val_loss: 1196.4083\n",
      "Epoch 421/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4383.4629 - val_loss: 1196.4568\n",
      "Epoch 422/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4374.8789 - val_loss: 1195.8748\n",
      "Epoch 423/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4377.8853 - val_loss: 1199.8220\n",
      "Epoch 424/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4390.9819 - val_loss: 1196.3933\n",
      "Epoch 425/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4396.5728 - val_loss: 1196.5807\n",
      "Epoch 426/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4374.7109 - val_loss: 1196.3300\n",
      "Epoch 427/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4378.5205 - val_loss: 1196.1089\n",
      "Epoch 428/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4385.9136 - val_loss: 1198.4329\n",
      "Epoch 429/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4398.5908 - val_loss: 1196.2627\n",
      "Epoch 430/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4381.0786 - val_loss: 1200.4072\n",
      "Epoch 431/1000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 4416.0430 - val_loss: 1200.4727\n",
      "Epoch 432/1000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 4386.6064 - val_loss: 1199.6008\n",
      "Epoch 433/1000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 4406.9585 - val_loss: 1195.8638\n",
      "Epoch 434/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 4386.3652 - val_loss: 1195.8999\n",
      "Epoch 435/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4377.5073 - val_loss: 1196.2434\n",
      "Epoch 436/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4389.1890 - val_loss: 1201.8696\n",
      "Epoch 437/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4380.4287 - val_loss: 1195.8943\n",
      "Epoch 438/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4385.2290 - val_loss: 1195.8728\n",
      "Epoch 439/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4380.3052 - val_loss: 1195.8875\n",
      "Epoch 440/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4381.9771 - val_loss: 1204.1257\n",
      "Epoch 441/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4400.1084 - val_loss: 1200.6560\n",
      "Epoch 442/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4382.4116 - val_loss: 1196.5422\n",
      "Epoch 443/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4375.3457 - val_loss: 1197.1477\n",
      "Epoch 444/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4394.1685 - val_loss: 1196.0182\n",
      "Epoch 445/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4387.5601 - val_loss: 1198.1055\n",
      "Epoch 446/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 4384.4678 - val_loss: 1196.5100\n",
      "Epoch 447/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4393.1157 - val_loss: 1195.9127\n",
      "Epoch 448/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4385.2490 - val_loss: 1200.7205\n",
      "Epoch 449/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4385.6680 - val_loss: 1200.5162\n",
      "Epoch 450/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4389.1328 - val_loss: 1202.6871\n",
      "Epoch 451/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4378.6074 - val_loss: 1196.1272\n",
      "Epoch 452/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4411.9575 - val_loss: 1195.8816\n",
      "Epoch 453/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4398.8760 - val_loss: 1201.4285\n",
      "Epoch 454/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4389.4834 - val_loss: 1200.6001\n",
      "Epoch 455/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4407.5322 - val_loss: 1195.8630\n",
      "Epoch 456/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4381.8335 - val_loss: 1197.4203\n",
      "Epoch 457/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4397.2827 - val_loss: 1196.1713\n",
      "Epoch 458/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4379.9663 - val_loss: 1198.7156\n",
      "Epoch 459/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4381.1763 - val_loss: 1196.0481\n",
      "Epoch 460/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4382.9453 - val_loss: 1195.8760\n",
      "Epoch 461/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4380.9595 - val_loss: 1196.8127\n",
      "Epoch 462/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4379.1084 - val_loss: 1197.0953\n",
      "Epoch 463/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4383.8931 - val_loss: 1196.5718\n",
      "Epoch 464/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 7ms/step - loss: 4388.3413 - val_loss: 1196.2957\n",
      "Epoch 465/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4399.0884 - val_loss: 1196.4858\n",
      "Epoch 466/1000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 4376.9321 - val_loss: 1197.0784\n",
      "Epoch 467/1000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 4387.9336 - val_loss: 1196.4646\n",
      "Epoch 468/1000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 4405.5840 - val_loss: 1196.2449\n",
      "Epoch 469/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4377.1875 - val_loss: 1197.0472\n",
      "Epoch 470/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4374.4844 - val_loss: 1196.7888\n",
      "Epoch 471/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4398.0410 - val_loss: 1195.9509\n",
      "Epoch 472/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4376.8252 - val_loss: 1196.2153\n",
      "Epoch 473/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4378.1406 - val_loss: 1197.1881\n",
      "Epoch 474/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4389.3794 - val_loss: 1203.8411\n",
      "Epoch 475/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4388.9170 - val_loss: 1197.6794\n",
      "Epoch 476/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4377.7759 - val_loss: 1198.0596\n",
      "Epoch 477/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4434.5918 - val_loss: 1201.5862\n",
      "Epoch 478/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4384.5161 - val_loss: 1195.8882\n",
      "Epoch 479/1000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 4382.3081 - val_loss: 1195.9003\n",
      "Epoch 480/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4379.0293 - val_loss: 1197.4456\n",
      "Epoch 481/1000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 4378.6621 - val_loss: 1195.9098\n",
      "Epoch 482/1000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 4376.2822 - val_loss: 1196.0518\n",
      "Epoch 483/1000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 4384.6973 - val_loss: 1197.3523\n",
      "Epoch 484/1000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 4392.5869 - val_loss: 1197.2075\n",
      "Epoch 485/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4375.6685 - val_loss: 1196.3942\n",
      "Epoch 486/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4385.6909 - val_loss: 1196.0490\n",
      "Epoch 487/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4387.7632 - val_loss: 1201.5452\n",
      "Epoch 488/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4372.2993 - val_loss: 1196.0194\n",
      "Epoch 489/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4399.1338 - val_loss: 1197.2468\n",
      "Epoch 490/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4385.5688 - val_loss: 1201.3224\n",
      "Epoch 491/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4372.8740 - val_loss: 1195.8658\n",
      "Epoch 492/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4388.8032 - val_loss: 1195.9806\n",
      "Epoch 493/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4375.7354 - val_loss: 1198.0135\n",
      "Epoch 494/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4373.0103 - val_loss: 1197.4467\n",
      "Epoch 495/1000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 4378.0171 - val_loss: 1195.8678\n",
      "Epoch 496/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4377.6914 - val_loss: 1198.8975\n",
      "Epoch 497/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4393.2168 - val_loss: 1195.8640\n",
      "Epoch 498/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 4376.3315 - val_loss: 1196.0420\n",
      "Epoch 499/1000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 4387.8984 - val_loss: 1196.1638\n",
      "Epoch 500/1000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 4394.2231 - val_loss: 1197.2777\n",
      "Epoch 501/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4405.0728 - val_loss: 1200.0613\n",
      "Epoch 502/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4397.5034 - val_loss: 1201.2913\n",
      "Epoch 503/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4387.4087 - val_loss: 1197.5693\n",
      "Epoch 504/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4375.9399 - val_loss: 1195.8684\n",
      "Epoch 505/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4381.8345 - val_loss: 1196.1527\n",
      "Epoch 506/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4390.5962 - val_loss: 1195.8684\n",
      "Epoch 507/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4384.3228 - val_loss: 1199.6931\n",
      "Epoch 508/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4391.5239 - val_loss: 1196.8085\n",
      "Epoch 509/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 4407.2383 - val_loss: 1195.9913\n",
      "Epoch 510/1000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 4384.3315 - val_loss: 1196.8553\n",
      "Epoch 511/1000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 4393.3398 - val_loss: 1197.2622\n",
      "Epoch 512/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4380.1470 - val_loss: 1196.2968\n",
      "Epoch 513/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4379.0874 - val_loss: 1196.1250\n",
      "Epoch 514/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4379.0649 - val_loss: 1197.4080\n",
      "Epoch 515/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4378.3008 - val_loss: 1195.8718\n",
      "Epoch 516/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4396.0161 - val_loss: 1198.5164\n",
      "Epoch 517/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4389.5952 - val_loss: 1196.6200\n",
      "Epoch 518/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4378.1416 - val_loss: 1196.3545\n",
      "Epoch 519/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4377.8975 - val_loss: 1196.3904\n",
      "Epoch 520/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4386.6768 - val_loss: 1195.8647\n",
      "Epoch 521/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4394.3359 - val_loss: 1195.9961\n",
      "Epoch 522/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4385.7139 - val_loss: 1197.7922\n",
      "Epoch 523/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4393.4946 - val_loss: 1199.0448\n",
      "Epoch 524/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4391.0928 - val_loss: 1198.4202\n",
      "Epoch 525/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4379.5869 - val_loss: 1198.3330\n",
      "Epoch 526/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4387.9185 - val_loss: 1196.0479\n",
      "Epoch 527/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4379.4629 - val_loss: 1196.6531\n",
      "Epoch 528/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4380.6978 - val_loss: 1197.2335\n",
      "Epoch 529/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4377.5850 - val_loss: 1195.8643\n",
      "Epoch 530/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4388.1948 - val_loss: 1196.1221\n",
      "Epoch 531/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4392.3911 - val_loss: 1196.0110\n",
      "Epoch 532/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4386.7070 - val_loss: 1196.1117\n",
      "Epoch 533/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4383.5337 - val_loss: 1199.2251\n",
      "Epoch 534/1000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 4383.6250 - val_loss: 1199.1702\n",
      "Epoch 535/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4396.9785 - val_loss: 1198.9702\n",
      "Epoch 536/1000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 4391.3813 - val_loss: 1201.5822\n",
      "Epoch 537/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4385.5112 - val_loss: 1196.3563\n",
      "Epoch 538/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4389.4521 - val_loss: 1202.4454\n",
      "Epoch 539/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4387.6128 - val_loss: 1196.7660\n",
      "Epoch 540/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4418.3423 - val_loss: 1197.0354\n",
      "Epoch 541/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 6ms/step - loss: 4397.8599 - val_loss: 1199.4387\n",
      "Epoch 542/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4389.9595 - val_loss: 1196.7107\n",
      "Epoch 543/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4373.4902 - val_loss: 1195.9677\n",
      "Epoch 544/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4378.9697 - val_loss: 1197.1692\n",
      "Epoch 545/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4389.1836 - val_loss: 1198.3923\n",
      "Epoch 546/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4396.3047 - val_loss: 1196.3184\n",
      "Epoch 547/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4387.8110 - val_loss: 1199.6721\n",
      "Epoch 548/1000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 4384.7373 - val_loss: 1198.6355\n",
      "Epoch 549/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4392.1826 - val_loss: 1196.4935\n",
      "Epoch 550/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4400.8271 - val_loss: 1213.3953\n",
      "Epoch 551/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4401.0425 - val_loss: 1195.9246\n",
      "Epoch 552/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4384.1943 - val_loss: 1195.8660\n",
      "Epoch 553/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4385.4360 - val_loss: 1197.2942\n",
      "Epoch 554/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4388.6904 - val_loss: 1196.9388\n",
      "Epoch 555/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4385.6382 - val_loss: 1199.8629\n",
      "Epoch 556/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4376.8091 - val_loss: 1196.6132\n",
      "Epoch 557/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4386.9146 - val_loss: 1196.0049\n",
      "Epoch 558/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4374.2661 - val_loss: 1197.4919\n",
      "Epoch 559/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4386.2373 - val_loss: 1195.8708\n",
      "Epoch 560/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4376.1289 - val_loss: 1197.8435\n",
      "Epoch 561/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4408.3394 - val_loss: 1198.4866\n",
      "Epoch 562/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4387.4707 - val_loss: 1196.5956\n",
      "Epoch 563/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4390.3315 - val_loss: 1195.8782\n",
      "Epoch 564/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4396.2632 - val_loss: 1195.8784\n",
      "Epoch 565/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4386.0039 - val_loss: 1197.3539\n",
      "Epoch 566/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4381.9551 - val_loss: 1197.6086\n",
      "Epoch 567/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4383.0479 - val_loss: 1195.8645\n",
      "Epoch 568/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4383.8140 - val_loss: 1196.0542\n",
      "Epoch 569/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4382.4097 - val_loss: 1196.0052\n",
      "Epoch 570/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4374.9409 - val_loss: 1197.9739\n",
      "Epoch 571/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4396.9165 - val_loss: 1195.8704\n",
      "Epoch 572/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4382.8501 - val_loss: 1197.3855\n",
      "Epoch 573/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4385.8428 - val_loss: 1197.5697\n",
      "Epoch 574/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4381.1655 - val_loss: 1196.4265\n",
      "Epoch 575/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4384.5508 - val_loss: 1196.1340\n",
      "Epoch 576/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4380.2427 - val_loss: 1196.6760\n",
      "Epoch 577/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4411.4492 - val_loss: 1196.0934\n",
      "Epoch 578/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4415.5044 - val_loss: 1196.4744\n",
      "Epoch 579/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4384.3647 - val_loss: 1196.0950\n",
      "Epoch 580/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 4374.1367 - val_loss: 1198.0477\n",
      "Epoch 581/1000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 4385.2974 - val_loss: 1196.0574\n",
      "Epoch 582/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4379.4380 - val_loss: 1196.6492\n",
      "Epoch 583/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4378.8394 - val_loss: 1196.8801\n",
      "Epoch 584/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4384.1865 - val_loss: 1197.0845\n",
      "Epoch 585/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4370.1963 - val_loss: 1197.9917\n",
      "Epoch 586/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4389.1841 - val_loss: 1196.2087\n",
      "Epoch 587/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4383.0591 - val_loss: 1196.2434\n",
      "Epoch 588/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4388.9585 - val_loss: 1195.8705\n",
      "Epoch 589/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4385.7358 - val_loss: 1197.9821\n",
      "Epoch 590/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4381.3540 - val_loss: 1195.9052\n",
      "Epoch 591/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4381.8530 - val_loss: 1199.9419\n",
      "Epoch 592/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4384.2471 - val_loss: 1196.2549\n",
      "Epoch 593/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4381.9438 - val_loss: 1195.9180\n",
      "Epoch 594/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4385.1460 - val_loss: 1198.4902\n",
      "Epoch 595/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4377.2310 - val_loss: 1197.2771\n",
      "Epoch 596/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4383.5518 - val_loss: 1198.2804\n",
      "Epoch 597/1000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 4395.4102 - val_loss: 1196.8699\n",
      "Epoch 598/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4410.3848 - val_loss: 1196.4795\n",
      "Epoch 599/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4384.7153 - val_loss: 1196.7131\n",
      "Epoch 600/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4381.1157 - val_loss: 1197.7203\n",
      "Epoch 601/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4383.5513 - val_loss: 1202.6785\n",
      "Epoch 602/1000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 4397.6616 - val_loss: 1195.8909\n",
      "Epoch 603/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4388.8711 - val_loss: 1197.9396\n",
      "Epoch 604/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4381.4648 - val_loss: 1197.5344\n",
      "Epoch 605/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4393.6631 - val_loss: 1200.0120\n",
      "Epoch 606/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4374.7896 - val_loss: 1196.0364\n",
      "Epoch 607/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4387.1870 - val_loss: 1196.0612\n",
      "Epoch 608/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4394.4297 - val_loss: 1196.3750\n",
      "Epoch 609/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4376.9297 - val_loss: 1196.6239\n",
      "Epoch 610/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4384.2241 - val_loss: 1197.0415\n",
      "Epoch 611/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4381.8403 - val_loss: 1196.5367\n",
      "Epoch 612/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4400.0527 - val_loss: 1202.3164\n",
      "Epoch 613/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4394.6997 - val_loss: 1196.8121\n",
      "Epoch 614/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4405.4595 - val_loss: 1195.8656\n",
      "Epoch 615/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4386.9087 - val_loss: 1196.8038\n",
      "Epoch 616/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4389.3647 - val_loss: 1196.6951\n",
      "Epoch 617/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4370.8252 - val_loss: 1196.8262\n",
      "Epoch 618/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 7ms/step - loss: 4379.3115 - val_loss: 1198.8905\n",
      "Epoch 619/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4382.8413 - val_loss: 1196.5348\n",
      "Epoch 620/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4379.9365 - val_loss: 1196.6089\n",
      "Epoch 621/1000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 4380.1064 - val_loss: 1196.8610\n",
      "Epoch 622/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4376.7622 - val_loss: 1195.9781\n",
      "Epoch 623/1000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 4379.5732 - val_loss: 1197.4192\n",
      "Epoch 624/1000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 4393.8359 - val_loss: 1196.0563\n",
      "Epoch 625/1000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 4376.9736 - val_loss: 1197.9602\n",
      "Epoch 626/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4375.5610 - val_loss: 1197.9910\n",
      "Epoch 627/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4375.7583 - val_loss: 1196.1605\n",
      "Epoch 628/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4379.5122 - val_loss: 1196.2555\n",
      "Epoch 629/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4394.1006 - val_loss: 1196.0356\n",
      "Epoch 630/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4391.5352 - val_loss: 1196.4993\n",
      "Epoch 631/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4380.1187 - val_loss: 1198.5431\n",
      "Epoch 632/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4374.3911 - val_loss: 1198.1250\n",
      "Epoch 633/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4372.2202 - val_loss: 1195.8706\n",
      "Epoch 634/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4406.0654 - val_loss: 1196.4635\n",
      "Epoch 635/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4375.2559 - val_loss: 1195.9246\n",
      "Epoch 636/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4385.5254 - val_loss: 1195.8627\n",
      "Epoch 637/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4382.8091 - val_loss: 1196.9459\n",
      "Epoch 638/1000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 4383.7407 - val_loss: 1196.0016\n",
      "Epoch 639/1000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 4378.9541 - val_loss: 1195.8746\n",
      "Epoch 640/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4389.1724 - val_loss: 1196.8220\n",
      "Epoch 641/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4390.9087 - val_loss: 1205.4359\n",
      "Epoch 642/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4382.1558 - val_loss: 1196.1941\n",
      "Epoch 643/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4374.0137 - val_loss: 1196.6311\n",
      "Epoch 644/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4378.9961 - val_loss: 1200.9675\n",
      "Epoch 645/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4394.4775 - val_loss: 1196.5208\n",
      "Epoch 646/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4370.4424 - val_loss: 1196.2672\n",
      "Epoch 647/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4382.8994 - val_loss: 1195.8688\n",
      "Epoch 648/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4377.9561 - val_loss: 1197.2390\n",
      "Epoch 649/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4378.6206 - val_loss: 1196.1757\n",
      "Epoch 650/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4385.4204 - val_loss: 1196.2622\n",
      "Epoch 651/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4381.1616 - val_loss: 1195.9973\n",
      "Epoch 652/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4386.5688 - val_loss: 1198.9607\n",
      "Epoch 653/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4385.7734 - val_loss: 1195.8909\n",
      "Epoch 654/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4384.3447 - val_loss: 1195.8801\n",
      "Epoch 655/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4371.7534 - val_loss: 1199.3254\n",
      "Epoch 656/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4392.0347 - val_loss: 1198.7061\n",
      "Epoch 657/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4381.2734 - val_loss: 1200.6124\n",
      "Epoch 658/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4383.5708 - val_loss: 1196.5460\n",
      "Epoch 659/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4388.6396 - val_loss: 1197.2134\n",
      "Epoch 660/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4394.7925 - val_loss: 1196.1335\n",
      "Epoch 661/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4378.4067 - val_loss: 1196.6877\n",
      "Epoch 662/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4387.4438 - val_loss: 1199.0466\n",
      "Epoch 663/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4386.8843 - val_loss: 1202.8148\n",
      "Epoch 664/1000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 4392.2441 - val_loss: 1196.7507\n",
      "Epoch 665/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4388.6938 - val_loss: 1198.9534\n",
      "Epoch 666/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4392.5283 - val_loss: 1196.2354\n",
      "Epoch 667/1000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 4380.1221 - val_loss: 1196.2742\n",
      "Epoch 668/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4389.0176 - val_loss: 1195.8737\n",
      "Epoch 669/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4381.8975 - val_loss: 1195.8894\n",
      "Epoch 670/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4392.4834 - val_loss: 1196.0439\n",
      "Epoch 671/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4379.5527 - val_loss: 1196.4863\n",
      "Epoch 672/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4422.2935 - val_loss: 1197.0468\n",
      "Epoch 673/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4379.3276 - val_loss: 1201.3502\n",
      "Epoch 674/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4387.8271 - val_loss: 1196.1554\n",
      "Epoch 675/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4386.9810 - val_loss: 1195.8633\n",
      "Epoch 676/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4381.7085 - val_loss: 1196.2780\n",
      "Epoch 677/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4397.6001 - val_loss: 1195.8865\n",
      "Epoch 678/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4388.4028 - val_loss: 1203.7360\n",
      "Epoch 679/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4386.5166 - val_loss: 1203.8655\n",
      "Epoch 680/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4394.3423 - val_loss: 1196.0311\n",
      "Epoch 681/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4377.0024 - val_loss: 1196.1821\n",
      "Epoch 682/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4380.7427 - val_loss: 1195.9656\n",
      "Epoch 683/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4378.3164 - val_loss: 1196.4377\n",
      "Epoch 684/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4382.3647 - val_loss: 1195.8912\n",
      "Epoch 685/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4391.4668 - val_loss: 1196.4041\n",
      "Epoch 686/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4377.2300 - val_loss: 1198.8643\n",
      "Epoch 687/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4379.8804 - val_loss: 1203.1974\n",
      "Epoch 688/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4384.4194 - val_loss: 1196.3966\n",
      "Epoch 689/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4389.6890 - val_loss: 1201.9364\n",
      "Epoch 690/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4385.0205 - val_loss: 1195.9377\n",
      "Epoch 691/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4420.4297 - val_loss: 1196.0845\n",
      "Epoch 692/1000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 4387.0264 - val_loss: 1196.7356\n",
      "Epoch 693/1000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 4415.2778 - val_loss: 1197.0874\n",
      "Epoch 694/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4380.2979 - val_loss: 1195.8948\n",
      "Epoch 695/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 7ms/step - loss: 4394.3369 - val_loss: 1195.8789\n",
      "Epoch 696/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4395.5391 - val_loss: 1196.9518\n",
      "Epoch 697/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4393.0571 - val_loss: 1201.1666\n",
      "Epoch 698/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4390.2256 - val_loss: 1197.5154\n",
      "Epoch 699/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4381.8794 - val_loss: 1195.8630\n",
      "Epoch 700/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4384.4443 - val_loss: 1200.4736\n",
      "Epoch 701/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4394.5449 - val_loss: 1196.6946\n",
      "Epoch 702/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4389.5591 - val_loss: 1196.7673\n",
      "Epoch 703/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4390.5098 - val_loss: 1208.8977\n",
      "Epoch 704/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4390.2173 - val_loss: 1195.8665\n",
      "Epoch 705/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4386.9175 - val_loss: 1199.8141\n",
      "Epoch 706/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4386.5747 - val_loss: 1201.2463\n",
      "Epoch 707/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4391.2188 - val_loss: 1196.9812\n",
      "Epoch 708/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4394.2231 - val_loss: 1196.2664\n",
      "Epoch 709/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4385.6948 - val_loss: 1197.7883\n",
      "Epoch 710/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4392.8428 - val_loss: 1196.6597\n",
      "Epoch 711/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4385.4150 - val_loss: 1195.9320\n",
      "Epoch 712/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4372.9272 - val_loss: 1199.0443\n",
      "Epoch 713/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4388.9160 - val_loss: 1205.9470\n",
      "Epoch 714/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4399.0039 - val_loss: 1195.9985\n",
      "Epoch 715/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4379.9629 - val_loss: 1196.4717\n",
      "Epoch 716/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4379.7085 - val_loss: 1198.4602\n",
      "Epoch 717/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4395.0312 - val_loss: 1196.0129\n",
      "Epoch 718/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4376.9404 - val_loss: 1198.1387\n",
      "Epoch 719/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4382.3882 - val_loss: 1195.8793\n",
      "Epoch 720/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4386.1460 - val_loss: 1196.0043\n",
      "Epoch 721/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4393.9878 - val_loss: 1197.8649\n",
      "Epoch 722/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4381.0254 - val_loss: 1201.5350\n",
      "Epoch 723/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4381.8643 - val_loss: 1195.8771\n",
      "Epoch 724/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4372.4512 - val_loss: 1195.8730\n",
      "Epoch 725/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4376.6172 - val_loss: 1196.6935\n",
      "Epoch 726/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4379.0522 - val_loss: 1200.5603\n",
      "Epoch 727/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4397.8511 - val_loss: 1206.1179\n",
      "Epoch 728/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4392.8765 - val_loss: 1201.1360\n",
      "Epoch 729/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4398.9897 - val_loss: 1195.9899\n",
      "Epoch 730/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4387.5308 - val_loss: 1196.5972\n",
      "Epoch 731/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4375.4131 - val_loss: 1197.7278\n",
      "Epoch 732/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4404.7217 - val_loss: 1196.4755\n",
      "Epoch 733/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4382.6382 - val_loss: 1198.9698\n",
      "Epoch 734/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4378.5610 - val_loss: 1201.4180\n",
      "Epoch 735/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4394.5747 - val_loss: 1198.8389\n",
      "Epoch 736/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4383.6685 - val_loss: 1196.1565\n",
      "Epoch 737/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4380.4365 - val_loss: 1197.5186\n",
      "Epoch 738/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4381.2666 - val_loss: 1195.8629\n",
      "Epoch 739/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4402.0903 - val_loss: 1196.2538\n",
      "Epoch 740/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4375.9106 - val_loss: 1195.9404\n",
      "Epoch 741/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4384.4897 - val_loss: 1202.9104\n",
      "Epoch 742/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4386.7578 - val_loss: 1198.4498\n",
      "Epoch 743/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4383.0645 - val_loss: 1196.0183\n",
      "Epoch 744/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4379.5566 - val_loss: 1198.4071\n",
      "Epoch 745/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4382.4087 - val_loss: 1197.1635\n",
      "Epoch 746/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4375.1177 - val_loss: 1197.0789\n",
      "Epoch 747/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4384.6104 - val_loss: 1196.3926\n",
      "Epoch 748/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4387.2339 - val_loss: 1195.8693\n",
      "Epoch 749/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4372.0928 - val_loss: 1198.6719\n",
      "Epoch 750/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4380.7183 - val_loss: 1199.5151\n",
      "Epoch 751/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4394.9185 - val_loss: 1197.5240\n",
      "Epoch 752/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4378.5347 - val_loss: 1196.0046\n",
      "Epoch 753/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4380.1597 - val_loss: 1196.1237\n",
      "Epoch 754/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4403.6650 - val_loss: 1196.0513\n",
      "Epoch 755/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4385.6504 - val_loss: 1199.4231\n",
      "Epoch 756/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4392.8716 - val_loss: 1199.4465\n",
      "Epoch 757/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4402.8535 - val_loss: 1196.8596\n",
      "Epoch 758/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4384.2339 - val_loss: 1198.7389\n",
      "Epoch 759/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4384.8765 - val_loss: 1195.8699\n",
      "Epoch 760/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4398.7642 - val_loss: 1196.1146\n",
      "Epoch 761/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4372.9976 - val_loss: 1197.2631\n",
      "Epoch 762/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4394.8418 - val_loss: 1196.7805\n",
      "Epoch 763/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4385.2432 - val_loss: 1196.3376\n",
      "Epoch 764/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4376.1191 - val_loss: 1196.3684\n",
      "Epoch 765/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4391.2529 - val_loss: 1195.9166\n",
      "Epoch 766/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4378.0942 - val_loss: 1195.9199\n",
      "Epoch 767/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4372.6807 - val_loss: 1199.5828\n",
      "Epoch 768/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4384.1235 - val_loss: 1196.4482\n",
      "Epoch 769/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4380.9023 - val_loss: 1195.9943\n",
      "Epoch 770/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4381.1377 - val_loss: 1201.1885\n",
      "Epoch 771/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4388.0034 - val_loss: 1195.8838\n",
      "Epoch 772/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 6ms/step - loss: 4391.9761 - val_loss: 1195.9221\n",
      "Epoch 773/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4381.5835 - val_loss: 1196.0094\n",
      "Epoch 774/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4368.6143 - val_loss: 1196.0422\n",
      "Epoch 775/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4381.9028 - val_loss: 1198.5294\n",
      "Epoch 776/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4379.0918 - val_loss: 1197.4124\n",
      "Epoch 777/1000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 4380.7759 - val_loss: 1195.9086\n",
      "Epoch 778/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4378.5444 - val_loss: 1199.3848\n",
      "Epoch 779/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4384.6460 - val_loss: 1196.6404\n",
      "Epoch 780/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4385.5444 - val_loss: 1198.9634\n",
      "Epoch 781/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4374.9702 - val_loss: 1196.4042\n",
      "Epoch 782/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4383.6636 - val_loss: 1197.6754\n",
      "Epoch 783/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4421.6328 - val_loss: 1196.9891\n",
      "Epoch 784/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4383.8628 - val_loss: 1196.3461\n",
      "Epoch 785/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4382.9438 - val_loss: 1195.8867\n",
      "Epoch 786/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4391.0479 - val_loss: 1203.1708\n",
      "Epoch 787/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4379.1230 - val_loss: 1195.8884\n",
      "Epoch 788/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4397.5566 - val_loss: 1196.3990\n",
      "Epoch 789/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4387.1826 - val_loss: 1196.1370\n",
      "Epoch 790/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4384.9609 - val_loss: 1204.1096\n",
      "Epoch 791/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4410.3267 - val_loss: 1196.1783\n",
      "Epoch 792/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4381.7266 - val_loss: 1196.3049\n",
      "Epoch 793/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4388.4009 - val_loss: 1196.1721\n",
      "Epoch 794/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4385.8901 - val_loss: 1199.8801\n",
      "Epoch 795/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4405.2017 - val_loss: 1196.9473\n",
      "Epoch 796/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4368.9546 - val_loss: 1196.1189\n",
      "Epoch 797/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4385.3774 - val_loss: 1195.8801\n",
      "Epoch 798/1000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 4388.6899 - val_loss: 1196.4086\n",
      "Epoch 799/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4382.0234 - val_loss: 1196.5255\n",
      "Epoch 800/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4379.6353 - val_loss: 1197.3888\n",
      "Epoch 801/1000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 4381.5249 - val_loss: 1198.3214\n",
      "Epoch 802/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4393.4736 - val_loss: 1195.9517\n",
      "Epoch 803/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4384.0005 - val_loss: 1196.0483\n",
      "Epoch 804/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4379.8008 - val_loss: 1196.2688\n",
      "Epoch 805/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4381.5176 - val_loss: 1195.9587\n",
      "Epoch 806/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4375.6626 - val_loss: 1200.2675\n",
      "Epoch 807/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4390.9683 - val_loss: 1207.4561\n",
      "Epoch 808/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4390.2935 - val_loss: 1195.9756\n",
      "Epoch 809/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4388.5547 - val_loss: 1196.8015\n",
      "Epoch 810/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4398.5703 - val_loss: 1196.4170\n",
      "Epoch 811/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4384.8813 - val_loss: 1196.1725\n",
      "Epoch 812/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4380.8667 - val_loss: 1196.2209\n",
      "Epoch 813/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4385.8784 - val_loss: 1207.4645\n",
      "Epoch 814/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4398.9932 - val_loss: 1196.5563\n",
      "Epoch 815/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4396.1997 - val_loss: 1197.6619\n",
      "Epoch 816/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4412.7080 - val_loss: 1195.8849\n",
      "Epoch 817/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4389.3584 - val_loss: 1195.8625\n",
      "Epoch 818/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4375.6484 - val_loss: 1196.0426\n",
      "Epoch 819/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4388.4805 - val_loss: 1200.3934\n",
      "Epoch 820/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4383.5063 - val_loss: 1195.9092\n",
      "Epoch 821/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4385.1982 - val_loss: 1196.0054\n",
      "Epoch 822/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4400.7578 - val_loss: 1198.7410\n",
      "Epoch 823/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4376.1641 - val_loss: 1198.9192\n",
      "Epoch 824/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4372.1387 - val_loss: 1197.5735\n",
      "Epoch 825/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4385.9434 - val_loss: 1197.3997\n",
      "Epoch 826/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4384.7183 - val_loss: 1196.7820\n",
      "Epoch 827/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4396.8843 - val_loss: 1195.8717\n",
      "Epoch 828/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4379.5044 - val_loss: 1197.1097\n",
      "Epoch 829/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4376.8428 - val_loss: 1196.4456\n",
      "Epoch 830/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4381.7700 - val_loss: 1198.4037\n",
      "Epoch 831/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4387.8784 - val_loss: 1197.9175\n",
      "Epoch 832/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4384.3560 - val_loss: 1199.7908\n",
      "Epoch 833/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4387.4385 - val_loss: 1197.7913\n",
      "Epoch 834/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4377.8477 - val_loss: 1198.8491\n",
      "Epoch 835/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4383.9961 - val_loss: 1197.6852\n",
      "Epoch 836/1000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 4416.0771 - val_loss: 1195.8806\n",
      "Epoch 837/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4402.9229 - val_loss: 1198.7039\n",
      "Epoch 838/1000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 4411.8037 - val_loss: 1195.9111\n",
      "Epoch 839/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4384.0728 - val_loss: 1196.7922\n",
      "Epoch 840/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4377.3726 - val_loss: 1197.2123\n",
      "Epoch 841/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4378.3960 - val_loss: 1198.0464\n",
      "Epoch 842/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4377.4106 - val_loss: 1195.9358\n",
      "Epoch 843/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4384.2310 - val_loss: 1195.8627\n",
      "Epoch 844/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4372.3433 - val_loss: 1195.9656\n",
      "Epoch 845/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4377.9399 - val_loss: 1200.3638\n",
      "Epoch 846/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4394.9482 - val_loss: 1199.2900\n",
      "Epoch 847/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4389.3877 - val_loss: 1201.3650\n",
      "Epoch 848/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4386.4761 - val_loss: 1195.9503\n",
      "Epoch 849/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 6ms/step - loss: 4373.9434 - val_loss: 1196.0503\n",
      "Epoch 850/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4405.5000 - val_loss: 1195.8975\n",
      "Epoch 851/1000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 4380.3447 - val_loss: 1195.8655\n",
      "Epoch 852/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4391.2041 - val_loss: 1195.8762\n",
      "Epoch 853/1000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 4369.5728 - val_loss: 1197.9187\n",
      "Epoch 854/1000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 4398.2617 - val_loss: 1196.6348\n",
      "Epoch 855/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4374.7095 - val_loss: 1196.4802\n",
      "Epoch 856/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4388.9263 - val_loss: 1196.5052\n",
      "Epoch 857/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4381.6138 - val_loss: 1195.9718\n",
      "Epoch 858/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4382.2275 - val_loss: 1196.0798\n",
      "Epoch 859/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4385.6567 - val_loss: 1195.8887\n",
      "Epoch 860/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4389.7271 - val_loss: 1195.8785\n",
      "Epoch 861/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4374.1514 - val_loss: 1200.7253\n",
      "Epoch 862/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4375.6821 - val_loss: 1195.9226\n",
      "Epoch 863/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4377.9756 - val_loss: 1196.2971\n",
      "Epoch 864/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4384.5317 - val_loss: 1200.1804\n",
      "Epoch 865/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4378.4541 - val_loss: 1196.1721\n",
      "Epoch 866/1000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 4373.2700 - val_loss: 1201.5153\n",
      "Epoch 867/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4378.5054 - val_loss: 1203.8311\n",
      "Epoch 868/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4396.4541 - val_loss: 1195.8802\n",
      "Epoch 869/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4390.0288 - val_loss: 1196.4319\n",
      "Epoch 870/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4391.4395 - val_loss: 1196.0994\n",
      "Epoch 871/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4386.9790 - val_loss: 1196.6611\n",
      "Epoch 872/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4388.0010 - val_loss: 1197.0530\n",
      "Epoch 873/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4393.0605 - val_loss: 1196.0574\n",
      "Epoch 874/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4384.6338 - val_loss: 1195.8894\n",
      "Epoch 875/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4386.9824 - val_loss: 1196.0886\n",
      "Epoch 876/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4386.2510 - val_loss: 1195.8845\n",
      "Epoch 877/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4378.4033 - val_loss: 1196.7205\n",
      "Epoch 878/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4381.0293 - val_loss: 1196.5627\n",
      "Epoch 879/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4404.7871 - val_loss: 1199.6143\n",
      "Epoch 880/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4378.5923 - val_loss: 1197.2137\n",
      "Epoch 881/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4384.1943 - val_loss: 1195.9138\n",
      "Epoch 882/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4389.3169 - val_loss: 1196.1287\n",
      "Epoch 883/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4383.2378 - val_loss: 1197.7145\n",
      "Epoch 884/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4381.0679 - val_loss: 1198.3876\n",
      "Epoch 885/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4377.6245 - val_loss: 1197.8094\n",
      "Epoch 886/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4385.2827 - val_loss: 1196.5969\n",
      "Epoch 887/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4395.3926 - val_loss: 1196.9845\n",
      "Epoch 888/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4388.6890 - val_loss: 1196.6705\n",
      "Epoch 889/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4385.3823 - val_loss: 1196.1836\n",
      "Epoch 890/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4393.2876 - val_loss: 1198.2063\n",
      "Epoch 891/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4383.8398 - val_loss: 1203.2544\n",
      "Epoch 892/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4376.3130 - val_loss: 1196.3331\n",
      "Epoch 893/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4380.5259 - val_loss: 1196.5876\n",
      "Epoch 894/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4380.5864 - val_loss: 1196.0087\n",
      "Epoch 895/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4380.3296 - val_loss: 1198.5527\n",
      "Epoch 896/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4395.1143 - val_loss: 1204.8785\n",
      "Epoch 897/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4401.8511 - val_loss: 1196.4120\n",
      "Epoch 898/1000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 4395.5029 - val_loss: 1196.2433\n",
      "Epoch 899/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4378.5947 - val_loss: 1199.8230\n",
      "Epoch 900/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4381.4067 - val_loss: 1196.0867\n",
      "Epoch 901/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4384.5679 - val_loss: 1196.5789\n",
      "Epoch 902/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4392.1099 - val_loss: 1195.8640\n",
      "Epoch 903/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4402.5186 - val_loss: 1195.8684\n",
      "Epoch 904/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4371.9565 - val_loss: 1195.9392\n",
      "Epoch 905/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4415.3306 - val_loss: 1196.1158\n",
      "Epoch 906/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4388.0488 - val_loss: 1195.8618\n",
      "Epoch 907/1000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 4387.3975 - val_loss: 1196.2795\n",
      "Epoch 908/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4380.6807 - val_loss: 1196.0795\n",
      "Epoch 909/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4383.7363 - val_loss: 1195.9064\n",
      "Epoch 910/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4369.4526 - val_loss: 1195.8635\n",
      "Epoch 911/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4379.5273 - val_loss: 1197.6775\n",
      "Epoch 912/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4400.7935 - val_loss: 1195.9115\n",
      "Epoch 913/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4377.1953 - val_loss: 1199.6965\n",
      "Epoch 914/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4378.3677 - val_loss: 1195.9954\n",
      "Epoch 915/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4379.4312 - val_loss: 1196.5457\n",
      "Epoch 916/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4392.1934 - val_loss: 1196.6028\n",
      "Epoch 917/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4413.3545 - val_loss: 1196.8102\n",
      "Epoch 918/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4379.2378 - val_loss: 1198.6575\n",
      "Epoch 919/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4389.8379 - val_loss: 1196.1133\n",
      "Epoch 920/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4392.1641 - val_loss: 1201.3441\n",
      "Epoch 921/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4406.2065 - val_loss: 1197.3820\n",
      "Epoch 922/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4386.3271 - val_loss: 1196.0588\n",
      "Epoch 923/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4373.1235 - val_loss: 1199.5846\n",
      "Epoch 924/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4392.6572 - val_loss: 1195.8978\n",
      "Epoch 925/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4374.7583 - val_loss: 1199.7922\n",
      "Epoch 926/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 7ms/step - loss: 4390.1587 - val_loss: 1195.9751\n",
      "Epoch 927/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4399.0547 - val_loss: 1195.9729\n",
      "Epoch 928/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4381.6533 - val_loss: 1196.2756\n",
      "Epoch 929/1000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 4381.3560 - val_loss: 1195.8635\n",
      "Epoch 930/1000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 4390.5723 - val_loss: 1197.0112\n",
      "Epoch 931/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4381.7866 - val_loss: 1199.1042\n",
      "Epoch 932/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4385.8843 - val_loss: 1198.1232\n",
      "Epoch 933/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4375.1060 - val_loss: 1195.9465\n",
      "Epoch 934/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4381.5903 - val_loss: 1195.9172\n",
      "Epoch 935/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4378.5728 - val_loss: 1195.9957\n",
      "Epoch 936/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4374.6797 - val_loss: 1196.9524\n",
      "Epoch 937/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4409.5815 - val_loss: 1201.3586\n",
      "Epoch 938/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4393.0117 - val_loss: 1198.9094\n",
      "Epoch 939/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4385.2295 - val_loss: 1195.9683\n",
      "Epoch 940/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4379.2695 - val_loss: 1199.5408\n",
      "Epoch 941/1000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 4383.4058 - val_loss: 1199.6511\n",
      "Epoch 942/1000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 4382.7817 - val_loss: 1195.9762\n",
      "Epoch 943/1000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 4398.1396 - val_loss: 1195.8669\n",
      "Epoch 944/1000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 4385.3999 - val_loss: 1196.2400\n",
      "Epoch 945/1000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 4375.7368 - val_loss: 1195.8676\n",
      "Epoch 946/1000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 4381.0049 - val_loss: 1196.4496\n",
      "Epoch 947/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4385.2119 - val_loss: 1196.1818\n",
      "Epoch 948/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4386.6978 - val_loss: 1196.0132\n",
      "Epoch 949/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4390.0366 - val_loss: 1205.8756\n",
      "Epoch 950/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4376.9854 - val_loss: 1195.8621\n",
      "Epoch 951/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4387.2041 - val_loss: 1196.6244\n",
      "Epoch 952/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4391.7280 - val_loss: 1197.7119\n",
      "Epoch 953/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4378.6309 - val_loss: 1196.0667\n",
      "Epoch 954/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4374.8389 - val_loss: 1198.8015\n",
      "Epoch 955/1000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 4382.0972 - val_loss: 1202.1898\n",
      "Epoch 956/1000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 4390.4102 - val_loss: 1197.5359\n",
      "Epoch 957/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 4379.4595 - val_loss: 1198.4451\n",
      "Epoch 958/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4394.0933 - val_loss: 1196.0664\n",
      "Epoch 959/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4391.5400 - val_loss: 1195.8652\n",
      "Epoch 960/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4376.5127 - val_loss: 1199.9045\n",
      "Epoch 961/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4394.4907 - val_loss: 1195.9614\n",
      "Epoch 962/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4389.8105 - val_loss: 1200.5768\n",
      "Epoch 963/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4416.1123 - val_loss: 1195.9215\n",
      "Epoch 964/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4384.3794 - val_loss: 1196.8173\n",
      "Epoch 965/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4378.3682 - val_loss: 1196.6775\n",
      "Epoch 966/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4367.7065 - val_loss: 1195.8638\n",
      "Epoch 967/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4385.0889 - val_loss: 1198.8271\n",
      "Epoch 968/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4381.0503 - val_loss: 1202.5497\n",
      "Epoch 969/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4385.8398 - val_loss: 1206.1749\n",
      "Epoch 970/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4383.6763 - val_loss: 1196.1766\n",
      "Epoch 971/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4374.8452 - val_loss: 1196.1958\n",
      "Epoch 972/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4389.9868 - val_loss: 1196.0436\n",
      "Epoch 973/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4378.5259 - val_loss: 1196.2256\n",
      "Epoch 974/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4381.6777 - val_loss: 1199.2638\n",
      "Epoch 975/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4391.3511 - val_loss: 1197.0765\n",
      "Epoch 976/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4397.1665 - val_loss: 1196.7216\n",
      "Epoch 977/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4388.7451 - val_loss: 1200.0751\n",
      "Epoch 978/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4379.4741 - val_loss: 1195.9506\n",
      "Epoch 979/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4374.9648 - val_loss: 1196.4102\n",
      "Epoch 980/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4375.9146 - val_loss: 1199.0394\n",
      "Epoch 981/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4385.3472 - val_loss: 1195.8696\n",
      "Epoch 982/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4395.7656 - val_loss: 1195.8782\n",
      "Epoch 983/1000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 4387.3833 - val_loss: 1196.2141\n",
      "Epoch 984/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4410.9922 - val_loss: 1196.8253\n",
      "Epoch 985/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4380.2017 - val_loss: 1196.0823\n",
      "Epoch 986/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4396.5859 - val_loss: 1196.8064\n",
      "Epoch 987/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4414.1001 - val_loss: 1201.0725\n",
      "Epoch 988/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4379.3818 - val_loss: 1198.8184\n",
      "Epoch 989/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4393.2959 - val_loss: 1197.8691\n",
      "Epoch 990/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4379.8989 - val_loss: 1196.2626\n",
      "Epoch 991/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4397.9932 - val_loss: 1196.5052\n",
      "Epoch 992/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4380.2261 - val_loss: 1197.1906\n",
      "Epoch 993/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4401.9512 - val_loss: 1197.1792\n",
      "Epoch 994/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4387.6147 - val_loss: 1197.0564\n",
      "Epoch 995/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4378.5791 - val_loss: 1195.9744\n",
      "Epoch 996/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4378.6460 - val_loss: 1196.3191\n",
      "Epoch 997/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4404.9497 - val_loss: 1196.0747\n",
      "Epoch 998/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4389.5200 - val_loss: 1201.7242\n",
      "Epoch 999/1000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 4377.7715 - val_loss: 1195.9065\n",
      "Epoch 1000/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4375.8906 - val_loss: 1198.2761\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"mean_squared_error\", optimizer=keras.optimizers.SGD(learning_rate=0.1))\n",
    "history = model.fit(X_train_full, y_train_full, epochs=1000, validation_data=(X_test, y_test))\n",
    "# 绘制训练 & 验证的损失值\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "ea6d7457",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) ', 'for plot_model/model_to_dot to work.')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "keras.utils.plot_model(model, \"my_fashion_mnist_model.png\", show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "c18253f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 59)                3540      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 96)                5760      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 110)               10670     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 58)                6438      \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 59        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 26,467\n",
      "Trainable params: 26,467\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "fabbd76d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66.08862642670636\n",
      "32.71391253338841\n",
      "(array([], dtype=int64),)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(np.min(np.sqrt(history.history['loss'])))\n",
    "print(np.min(np.sqrt(history.history['val_loss'])))\n",
    "test = np.sqrt(history.history['val_loss'])\n",
    "print(np.where(test==67.94991836823647))\n",
    "plt.plot(np.sqrt(history.history['loss']))\n",
    "plt.plot(np.sqrt(history.history['val_loss']))\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('LUT_RMSE')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "58d9d3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(n_hidden=1, n_neurons=30, learning_rate=1e-3, input_shape=[59]):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.InputLayer(input_shape=input_shape))\n",
    "    for layer in range(n_hidden):\n",
    "        model.add(keras.layers.Dense(n_neurons, activation=\"relu\"))\n",
    "    model.add(keras.layers.Dense(1))\n",
    "    optimizer = keras.optimizers.SGD(learning_rate=learning_rate)\n",
    "    model.compile(loss=\"mse\", optimizer=optimizer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2547e47e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_3(n_neurons=30, learning_rate=1e-3, input_shape=[59],unit1=1,unit2=2,unit3=3):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.InputLayer(input_shape=input_shape))\n",
    "    model.add(keras.layers.Dense(unit1, activation=\"relu\"))\n",
    "    model.add(keras.layers.Dense(unit2, activation=\"relu\"))\n",
    "    model.add(keras.layers.Dense(unit3, activation=\"relu\"))\n",
    "    model.add(keras.layers.Dense(1))\n",
    "    optimizer = keras.optimizers.SGD(learning_rate=learning_rate)\n",
    "    model.compile(loss=\"mse\", optimizer=optimizer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c8dac366",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-42-0c5b676cc640>:2: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead.\n",
      "  keras_reg = keras.wrappers.scikit_learn.KerasRegressor(build_model_3)\n"
     ]
    }
   ],
   "source": [
    "keras.backend.clear_session()\n",
    "keras_reg = keras.wrappers.scikit_learn.KerasRegressor(build_model_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "90b4b8af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.wrappers.scikit_learn.KerasRegressor at 0x201e46e9d00>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "706b07e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Epoch 1/1000\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 2581.7661 - val_loss: 8183.1021\n",
      "Epoch 2/1000\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 2577.4253 - val_loss: 8177.1968\n",
      "Epoch 3/1000\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 2573.2720 - val_loss: 8172.0273\n",
      "Epoch 4/1000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 2569.4792 - val_loss: 8166.8677\n",
      "Epoch 5/1000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 2565.7747 - val_loss: 8161.4795\n",
      "Epoch 6/1000\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 2561.6885 - val_loss: 8155.8589\n",
      "Epoch 7/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 2557.4260 - val_loss: 8149.7173\n",
      "Epoch 8/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 2552.8655 - val_loss: 8143.4854\n",
      "Epoch 9/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 2548.2969 - val_loss: 8137.2476\n",
      "Epoch 10/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 2543.5325 - val_loss: 8130.5586\n",
      "Epoch 11/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 2538.4832 - val_loss: 8123.5371\n",
      "Epoch 12/1000\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 2532.7607 - val_loss: 8114.7417\n",
      "Epoch 13/1000\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 2526.2297 - val_loss: 8103.5327\n",
      "Epoch 14/1000\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 2517.2427 - val_loss: 8092.1353\n",
      "Epoch 15/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 2508.4512 - val_loss: 8077.9829\n",
      "Epoch 16/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 2497.3643 - val_loss: 8062.3062\n",
      "Epoch 17/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 2485.1919 - val_loss: 8045.5859\n",
      "Epoch 18/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 2471.7317 - val_loss: 8024.8135\n",
      "Epoch 19/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 2455.5022 - val_loss: 7996.0996\n",
      "Epoch 20/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 2432.3628 - val_loss: 7959.9229\n",
      "Epoch 21/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 2404.5073 - val_loss: 7921.6377\n",
      "Epoch 22/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 2372.7861 - val_loss: 7866.2373\n",
      "Epoch 23/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 2329.1995 - val_loss: 7785.7690\n",
      "Epoch 24/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 2263.5276 - val_loss: 7688.4180\n",
      "Epoch 25/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 2194.3943 - val_loss: 7570.7388\n",
      "Epoch 26/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 2091.5142 - val_loss: 7388.9629\n",
      "Epoch 27/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1953.6572 - val_loss: 7168.6626\n",
      "Epoch 28/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 1802.2737 - val_loss: 6939.8545\n",
      "Epoch 29/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1640.7407 - val_loss: 6679.7383\n",
      "Epoch 30/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1491.3041 - val_loss: 6476.8530\n",
      "Epoch 31/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 1402.1271 - val_loss: 6332.5371\n",
      "Epoch 32/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 1331.1287 - val_loss: 6191.8633\n",
      "Epoch 33/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 1261.8734 - val_loss: 6194.5161\n",
      "Epoch 34/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 1205.0345 - val_loss: 6103.2998\n",
      "Epoch 35/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 1153.1321 - val_loss: 6013.7412\n",
      "Epoch 36/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 1082.2584 - val_loss: 5922.5288\n",
      "Epoch 37/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 1040.7474 - val_loss: 5821.1279\n",
      "Epoch 38/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1000.5421 - val_loss: 5770.6304\n",
      "Epoch 39/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 920.7319 - val_loss: 5755.9678\n",
      "Epoch 40/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 888.9952 - val_loss: 5757.4155\n",
      "Epoch 41/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 801.2085 - val_loss: 5662.9365\n",
      "Epoch 42/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 766.0025 - val_loss: 5564.4790\n",
      "Epoch 43/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 706.1921 - val_loss: 5529.3228\n",
      "Epoch 44/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 685.2397 - val_loss: 5455.9214\n",
      "Epoch 45/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 624.7719 - val_loss: 5469.6411\n",
      "Epoch 46/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 581.4453 - val_loss: 5497.0122\n",
      "Epoch 47/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 583.3064 - val_loss: 5379.5479\n",
      "Epoch 48/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 494.5613 - val_loss: 5474.8115\n",
      "Epoch 49/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 536.8981 - val_loss: 5318.2573\n",
      "Epoch 50/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 529.7639 - val_loss: 5361.8467\n",
      "Epoch 51/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 413.0300 - val_loss: 5417.9277\n",
      "Epoch 52/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 404.2343 - val_loss: 5459.7930\n",
      "Epoch 53/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 422.9102 - val_loss: 5488.7798\n",
      "Epoch 54/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 443.6044 - val_loss: 5385.4312\n",
      "Epoch 55/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 345.5406 - val_loss: 5330.9033\n",
      "Epoch 56/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 378.2655 - val_loss: 5265.8457\n",
      "Epoch 57/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 342.8748 - val_loss: 5351.7134\n",
      "Epoch 58/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 331.1469 - val_loss: 5287.3237\n",
      "Epoch 59/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 299.8481 - val_loss: 5355.8252\n",
      "Epoch 60/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 307.1220 - val_loss: 5399.4849\n",
      "Epoch 61/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 302.4916 - val_loss: 5381.0254\n",
      "Epoch 62/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 306.4095 - val_loss: 5419.5278\n",
      "Epoch 63/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 279.2845 - val_loss: 5346.5254\n",
      "Epoch 64/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 273.4164 - val_loss: 5427.8223\n",
      "Epoch 65/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 265.4727 - val_loss: 5343.2812\n",
      "Epoch 66/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 286.7190 - val_loss: 5303.1812\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2320.5815\n",
      "[CV] END learning_rate=0.00018186948722105108, unit1=76, unit2=107, unit3=75; total time=   2.8s\n",
      "Epoch 1/1000\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 3445.0007 - val_loss: 8176.7656\n",
      "Epoch 2/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 3438.0588 - val_loss: 8169.6582\n",
      "Epoch 3/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 3431.6074 - val_loss: 8162.6108\n",
      "Epoch 4/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 3425.1958 - val_loss: 8155.0146\n",
      "Epoch 5/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 3418.2139 - val_loss: 8147.3721\n",
      "Epoch 6/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 3411.0317 - val_loss: 8139.0098\n",
      "Epoch 7/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 3402.9441 - val_loss: 8128.5786\n",
      "Epoch 8/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 3393.3374 - val_loss: 8118.1924\n",
      "Epoch 9/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 3383.4055 - val_loss: 8105.5859\n",
      "Epoch 10/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 3371.4260 - val_loss: 8091.5815\n",
      "Epoch 11/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 3357.9460 - val_loss: 8074.2095\n",
      "Epoch 12/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 3341.0583 - val_loss: 8053.0571\n",
      "Epoch 13/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 3320.4175 - val_loss: 8027.2256\n",
      "Epoch 14/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 3295.3208 - val_loss: 7995.9873\n",
      "Epoch 15/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 3264.8184 - val_loss: 7954.6392\n",
      "Epoch 16/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 3221.3225 - val_loss: 7893.9067\n",
      "Epoch 17/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 3161.3020 - val_loss: 7820.0029\n",
      "Epoch 18/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 3082.2107 - val_loss: 7703.4312\n",
      "Epoch 19/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 2961.1924 - val_loss: 7535.8706\n",
      "Epoch 20/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 2785.8142 - val_loss: 7259.7427\n",
      "Epoch 21/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 2514.2981 - val_loss: 6954.8149\n",
      "Epoch 22/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 2224.4844 - val_loss: 6581.4009\n",
      "Epoch 23/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 1927.7876 - val_loss: 6308.6274\n",
      "Epoch 24/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 1729.1670 - val_loss: 6211.7285\n",
      "Epoch 25/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1662.0092 - val_loss: 6131.0010\n",
      "Epoch 26/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 1567.6162 - val_loss: 6062.2817\n",
      "Epoch 27/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1519.9666 - val_loss: 5953.5835\n",
      "Epoch 28/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1436.8734 - val_loss: 5887.1597\n",
      "Epoch 29/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 1360.7045 - val_loss: 5882.5703\n",
      "Epoch 30/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 1337.9781 - val_loss: 5908.3286\n",
      "Epoch 31/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 1305.0299 - val_loss: 5850.4150\n",
      "Epoch 32/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 1202.0876 - val_loss: 5721.6182\n",
      "Epoch 33/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 1129.7596 - val_loss: 5622.4170\n",
      "Epoch 34/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 1131.9573 - val_loss: 5605.2241\n",
      "Epoch 35/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1026.3916 - val_loss: 5521.1792\n",
      "Epoch 36/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 944.3164 - val_loss: 5537.7471\n",
      "Epoch 37/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 870.0682 - val_loss: 5458.1670\n",
      "Epoch 38/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 890.4119 - val_loss: 5433.9854\n",
      "Epoch 39/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 865.3226 - val_loss: 5372.9365\n",
      "Epoch 40/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 711.7557 - val_loss: 5369.5620\n",
      "Epoch 41/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 655.9250 - val_loss: 5328.8960\n",
      "Epoch 42/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 643.8452 - val_loss: 5340.5449\n",
      "Epoch 43/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 629.8104 - val_loss: 5350.1333\n",
      "Epoch 44/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 595.7843 - val_loss: 5325.2173\n",
      "Epoch 45/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 538.7975 - val_loss: 5226.9663\n",
      "Epoch 46/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 541.0966 - val_loss: 5230.6772\n",
      "Epoch 47/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 486.6088 - val_loss: 5254.2725\n",
      "Epoch 48/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 470.2966 - val_loss: 5219.1997\n",
      "Epoch 49/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 457.4986 - val_loss: 5433.6572\n",
      "Epoch 50/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 556.1573 - val_loss: 5214.4780\n",
      "Epoch 51/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 466.0753 - val_loss: 5109.5195\n",
      "Epoch 52/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 396.0202 - val_loss: 5185.8438\n",
      "Epoch 53/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 431.2897 - val_loss: 5074.8076\n",
      "Epoch 54/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 407.5780 - val_loss: 5061.7246\n",
      "Epoch 55/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 448.6795 - val_loss: 5101.1968\n",
      "Epoch 56/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 312.6188 - val_loss: 5182.6138\n",
      "Epoch 57/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 320.0550 - val_loss: 5128.0693\n",
      "Epoch 58/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 335.1983 - val_loss: 5247.0068\n",
      "Epoch 59/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 350.7267 - val_loss: 5193.5190\n",
      "Epoch 60/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 288.1852 - val_loss: 5156.3369\n",
      "Epoch 61/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 288.8170 - val_loss: 5180.5054\n",
      "Epoch 62/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 252.9456 - val_loss: 5026.9346\n",
      "Epoch 63/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 252.1895 - val_loss: 5213.3345\n",
      "Epoch 64/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 241.7623 - val_loss: 5093.1431\n",
      "Epoch 65/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 224.6129 - val_loss: 5073.4614\n",
      "Epoch 66/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 223.7356 - val_loss: 5204.5635\n",
      "Epoch 67/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 242.5787 - val_loss: 5111.0684\n",
      "Epoch 68/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 205.9980 - val_loss: 5009.2280\n",
      "Epoch 69/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 234.1663 - val_loss: 5169.5200\n",
      "Epoch 70/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 204.6789 - val_loss: 5150.9541\n",
      "Epoch 71/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 198.2972 - val_loss: 5176.9927\n",
      "Epoch 72/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 210.2419 - val_loss: 5168.6846\n",
      "Epoch 73/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 196.4243 - val_loss: 5122.4106\n",
      "Epoch 74/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 188.3685 - val_loss: 5167.3013\n",
      "Epoch 75/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 238.6574 - val_loss: 5167.0142\n",
      "Epoch 76/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 171.5430 - val_loss: 5162.0942\n",
      "Epoch 77/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 169.3509 - val_loss: 5105.2095\n",
      "Epoch 78/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 188.3606 - val_loss: 5237.0259\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 826.1903\n",
      "[CV] END learning_rate=0.00018186948722105108, unit1=76, unit2=107, unit3=75; total time=   2.8s\n",
      "Epoch 1/1000\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 2933.7695 - val_loss: 8179.3667\n",
      "Epoch 2/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 2928.0449 - val_loss: 8173.1943\n",
      "Epoch 3/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 2922.5352 - val_loss: 8167.0254\n",
      "Epoch 4/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 2916.9543 - val_loss: 8160.7314\n",
      "Epoch 5/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 2911.2466 - val_loss: 8154.1636\n",
      "Epoch 6/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 2905.1980 - val_loss: 8146.8838\n",
      "Epoch 7/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 2898.5437 - val_loss: 8139.1636\n",
      "Epoch 8/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 17ms/step - loss: 2891.6162 - val_loss: 8130.5288\n",
      "Epoch 9/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 2883.5957 - val_loss: 8121.7588\n",
      "Epoch 10/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 2875.5044 - val_loss: 8111.8062\n",
      "Epoch 11/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 2866.6270 - val_loss: 8101.5327\n",
      "Epoch 12/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 2856.7192 - val_loss: 8089.1792\n",
      "Epoch 13/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 2845.1831 - val_loss: 8075.0474\n",
      "Epoch 14/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 2831.2524 - val_loss: 8057.2646\n",
      "Epoch 15/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 2814.6074 - val_loss: 8037.0908\n",
      "Epoch 16/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 2794.7395 - val_loss: 8010.8335\n",
      "Epoch 17/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 2769.2502 - val_loss: 7976.4644\n",
      "Epoch 18/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 2735.4851 - val_loss: 7931.8848\n",
      "Epoch 19/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 2691.7283 - val_loss: 7872.0571\n",
      "Epoch 20/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 2633.1582 - val_loss: 7779.1553\n",
      "Epoch 21/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 2540.6504 - val_loss: 7662.7080\n",
      "Epoch 22/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 2429.5518 - val_loss: 7514.2432\n",
      "Epoch 23/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 2285.4062 - val_loss: 7294.4795\n",
      "Epoch 24/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 2080.8286 - val_loss: 7023.8804\n",
      "Epoch 25/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1858.8320 - val_loss: 6736.8286\n",
      "Epoch 26/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 1647.3558 - val_loss: 6548.2461\n",
      "Epoch 27/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 1515.6152 - val_loss: 6382.8433\n",
      "Epoch 28/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 1447.7471 - val_loss: 6372.1812\n",
      "Epoch 29/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 1390.4189 - val_loss: 6276.5039\n",
      "Epoch 30/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 1406.8341 - val_loss: 6308.9067\n",
      "Epoch 31/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1316.4443 - val_loss: 6182.2026\n",
      "Epoch 32/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 1231.6611 - val_loss: 6112.3276\n",
      "Epoch 33/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 1187.5367 - val_loss: 6152.6816\n",
      "Epoch 34/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1127.9200 - val_loss: 6048.3179\n",
      "Epoch 35/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 1076.0312 - val_loss: 5997.7808\n",
      "Epoch 36/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 1116.7584 - val_loss: 6072.0591\n",
      "Epoch 37/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 1013.0714 - val_loss: 5956.0908\n",
      "Epoch 38/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 903.1765 - val_loss: 5879.4468\n",
      "Epoch 39/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 893.7028 - val_loss: 5806.8027\n",
      "Epoch 40/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 810.3319 - val_loss: 5869.1172\n",
      "Epoch 41/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 777.3904 - val_loss: 5926.1216\n",
      "Epoch 42/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 725.7477 - val_loss: 5730.3467\n",
      "Epoch 43/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 659.2721 - val_loss: 5701.9648\n",
      "Epoch 44/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 606.3693 - val_loss: 5790.6885\n",
      "Epoch 45/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 572.6705 - val_loss: 5635.9424\n",
      "Epoch 46/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 599.5609 - val_loss: 5728.4121\n",
      "Epoch 47/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 510.2158 - val_loss: 5595.7065\n",
      "Epoch 48/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 483.9771 - val_loss: 5682.7847\n",
      "Epoch 49/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 468.8159 - val_loss: 5814.6909\n",
      "Epoch 50/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 460.3004 - val_loss: 5764.3481\n",
      "Epoch 51/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 439.5612 - val_loss: 5744.7500\n",
      "Epoch 52/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 466.2480 - val_loss: 5727.7632\n",
      "Epoch 53/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 376.6070 - val_loss: 5655.1851\n",
      "Epoch 54/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 443.2229 - val_loss: 5845.9927\n",
      "Epoch 55/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 363.7586 - val_loss: 5609.3911\n",
      "Epoch 56/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 349.1674 - val_loss: 5598.5664\n",
      "Epoch 57/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 340.4841 - val_loss: 5712.8906\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1310.6058\n",
      "[CV] END learning_rate=0.00018186948722105108, unit1=76, unit2=107, unit3=75; total time=   2.3s\n",
      "Epoch 1/1000\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 2538.2708 - val_loss: 7645.5947\n",
      "Epoch 2/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 84545.8438 - val_loss: 16462.1562\n",
      "Epoch 3/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 2957802490346876464307899731411992576.0000 - val_loss: inf\n",
      "Epoch 4/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: nan - val_loss: nan\n",
      "Epoch 5/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: nan - val_loss: nan\n",
      "Epoch 6/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: nan - val_loss: nan\n",
      "Epoch 7/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: nan - val_loss: nan\n",
      "Epoch 8/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: nan - val_loss: nan\n",
      "Epoch 9/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: nan - val_loss: nan\n",
      "Epoch 11/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: nan - val_loss: nan\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan\n",
      "[CV] END learning_rate=0.009063759187891344, unit1=12, unit2=64, unit3=89; total time=   0.6s\n",
      "Epoch 1/1000\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 3383.3638 - val_loss: 7584.2441\n",
      "Epoch 2/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 6469.3618 - val_loss: 8114.0449\n",
      "Epoch 3/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 3328.1492 - val_loss: 7758.3691\n",
      "Epoch 4/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 3238.0488 - val_loss: 10788.4443\n",
      "Epoch 5/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 4196.1392 - val_loss: 7894.9351\n",
      "Epoch 6/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 3158.3337 - val_loss: 7814.5874\n",
      "Epoch 7/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 3086.7058 - val_loss: 7732.4658\n",
      "Epoch 8/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 3003.9045 - val_loss: 7563.2993\n",
      "Epoch 9/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 2622.3650 - val_loss: 14999.1953\n",
      "Epoch 10/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 9430.6543 - val_loss: 7624.9297\n",
      "Epoch 11/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 2927.6309 - val_loss: 7571.0371\n",
      "Epoch 12/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 2871.6738 - val_loss: 7501.7979\n",
      "Epoch 13/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 2793.8823 - val_loss: 7351.2759\n",
      "Epoch 14/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 2637.8865 - val_loss: 7139.0024\n",
      "Epoch 15/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 2509.5410 - val_loss: 7069.8940\n",
      "Epoch 16/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 2576.3252 - val_loss: 7127.9756\n",
      "Epoch 17/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 2541.5293 - val_loss: 7172.4673\n",
      "Epoch 18/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 2517.3962 - val_loss: 7071.3882\n",
      "Epoch 19/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 2509.1919 - val_loss: 7071.8979\n",
      "Epoch 20/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 2548.0400 - val_loss: 7094.9336\n",
      "Epoch 21/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 2533.8735 - val_loss: 7073.4551\n",
      "Epoch 22/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 2516.8892 - val_loss: 7086.3091\n",
      "Epoch 23/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 2496.0159 - val_loss: 7117.3027\n",
      "Epoch 24/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 2497.1211 - val_loss: 7076.4810\n",
      "Epoch 25/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 2586.6284 - val_loss: 7070.1177\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1660.6091\n",
      "[CV] END learning_rate=0.009063759187891344, unit1=12, unit2=64, unit3=89; total time=   1.1s\n",
      "Epoch 1/1000\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 2857.9094 - val_loss: 7189.6191\n",
      "Epoch 2/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 1125338.1250 - val_loss: 10103.2578\n",
      "Epoch 3/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 240659609751797104640.0000 - val_loss: inf\n",
      "Epoch 4/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: nan - val_loss: nan\n",
      "Epoch 5/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: nan - val_loss: nan\n",
      "Epoch 6/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: nan - val_loss: nan\n",
      "Epoch 7/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: nan - val_loss: nan\n",
      "Epoch 8/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: nan - val_loss: nan\n",
      "Epoch 9/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: nan - val_loss: nan\n",
      "Epoch 11/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: nan - val_loss: nan\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan\n",
      "[CV] END learning_rate=0.009063759187891344, unit1=12, unit2=64, unit3=89; total time=   0.6s\n",
      "Epoch 1/1000\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 2543.6714 - val_loss: 7802.9971\n",
      "Epoch 2/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 1965.1556 - val_loss: 599658.0625\n",
      "Epoch 3/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 10888902656.0000 - val_loss: inf\n",
      "Epoch 4/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: nan - val_loss: nan\n",
      "Epoch 5/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: nan - val_loss: nan\n",
      "Epoch 6/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: nan - val_loss: nan\n",
      "Epoch 7/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: nan - val_loss: nan\n",
      "Epoch 8/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: nan - val_loss: nan\n",
      "Epoch 9/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: nan - val_loss: nan\n",
      "Epoch 11/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: nan - val_loss: nan\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan\n",
      "[CV] END learning_rate=0.007315728173609639, unit1=74, unit2=62, unit3=49; total time=   0.6s\n",
      "Epoch 1/1000\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 3352.8040 - val_loss: 6445.1470\n",
      "Epoch 2/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 498931.5625 - val_loss: 50866.3828\n",
      "Epoch 3/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: inf - val_loss: nan\n",
      "Epoch 4/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: nan - val_loss: nan\n",
      "Epoch 5/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: nan - val_loss: nan\n",
      "Epoch 6/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: nan - val_loss: nan\n",
      "Epoch 7/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: nan - val_loss: nan\n",
      "Epoch 8/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: nan - val_loss: nan\n",
      "Epoch 9/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: nan - val_loss: nan\n",
      "Epoch 11/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: nan - val_loss: nan\n",
      "2/2 [==============================] - 0s 3ms/step - loss: nan\n",
      "[CV] END learning_rate=0.007315728173609639, unit1=74, unit2=62, unit3=49; total time=   0.6s\n",
      "Epoch 1/1000\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 2852.3652 - val_loss: 6663.0571\n",
      "Epoch 2/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 22663.4512 - val_loss: 8264.9961\n",
      "Epoch 3/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 12080.4121 - val_loss: 633321717497856.0000\n",
      "Epoch 4/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: nan - val_loss: nan\n",
      "Epoch 5/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: nan - val_loss: nan\n",
      "Epoch 6/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: nan - val_loss: nan\n",
      "Epoch 7/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: nan - val_loss: nan\n",
      "Epoch 8/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: nan - val_loss: nan\n",
      "Epoch 9/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: nan - val_loss: nan\n",
      "Epoch 11/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: nan - val_loss: nan\n",
      "2/2 [==============================] - 0s 3ms/step - loss: nan\n",
      "[CV] END learning_rate=0.007315728173609639, unit1=74, unit2=62, unit3=49; total time=   0.6s\n",
      "Epoch 1/1000\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 2574.3823 - val_loss: 8155.9902\n",
      "Epoch 2/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 2553.7068 - val_loss: 8124.3101\n",
      "Epoch 3/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 2529.2566 - val_loss: 8082.4771\n",
      "Epoch 4/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 2496.1938 - val_loss: 8025.6455\n",
      "Epoch 5/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 2450.0161 - val_loss: 7934.1870\n",
      "Epoch 6/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 2378.8679 - val_loss: 7798.9771\n",
      "Epoch 7/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 2273.5618 - val_loss: 7580.6982\n",
      "Epoch 8/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 2127.8340 - val_loss: 7306.4170\n",
      "Epoch 9/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 2042.3726 - val_loss: 7313.8589\n",
      "Epoch 10/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 2041.4457 - val_loss: 7108.3662\n",
      "Epoch 11/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 1996.3885 - val_loss: 7106.2339\n",
      "Epoch 12/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 2010.9697 - val_loss: 7163.9941\n",
      "Epoch 13/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 1994.7184 - val_loss: 7096.1895\n",
      "Epoch 14/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 1975.9244 - val_loss: 7156.7812\n",
      "Epoch 15/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 2010.1584 - val_loss: 7200.5591\n",
      "Epoch 16/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 1927.8822 - val_loss: 7009.2456\n",
      "Epoch 17/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1764.3927 - val_loss: 6959.2021\n",
      "Epoch 18/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 1495.6605 - val_loss: 7426.1494\n",
      "Epoch 19/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 1631.1520 - val_loss: 5709.6616\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 1489.8267 - val_loss: 8122.1768\n",
      "Epoch 21/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 2529.5503 - val_loss: 8092.7803\n",
      "Epoch 22/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 2509.5911 - val_loss: 8067.8105\n",
      "Epoch 23/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 2490.8323 - val_loss: 8034.1177\n",
      "Epoch 24/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 2465.8696 - val_loss: 7998.1318\n",
      "Epoch 25/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 2438.5935 - val_loss: 7953.5791\n",
      "Epoch 26/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 2404.7373 - val_loss: 7890.8638\n",
      "Epoch 27/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 2356.6006 - val_loss: 7799.9297\n",
      "Epoch 28/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 2289.0686 - val_loss: 7639.2158\n",
      "Epoch 29/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 2176.4800 - val_loss: 7434.3950\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 2973.2454\n",
      "[CV] END learning_rate=0.0013464320273500377, unit1=3, unit2=126, unit3=73; total time=   1.4s\n",
      "Epoch 1/1000\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 3435.3503 - val_loss: 8142.3276\n",
      "Epoch 2/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 3395.2104 - val_loss: 8086.8188\n",
      "Epoch 3/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 3334.0261 - val_loss: 7980.8838\n",
      "Epoch 4/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 3201.9771 - val_loss: 7662.8994\n",
      "Epoch 5/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 2706.9622 - val_loss: 6518.5259\n",
      "Epoch 6/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 1734.9346 - val_loss: 5914.7661\n",
      "Epoch 7/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 1220.8479 - val_loss: 6383.0405\n",
      "Epoch 8/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 4967.5469 - val_loss: 8145.3877\n",
      "Epoch 9/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 3395.0029 - val_loss: 8104.7314\n",
      "Epoch 10/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 3368.3921 - val_loss: 8085.4077\n",
      "Epoch 11/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 3349.9397 - val_loss: 8063.7095\n",
      "Epoch 12/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 3329.5391 - val_loss: 8040.8408\n",
      "Epoch 13/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 3307.2222 - val_loss: 8012.7373\n",
      "Epoch 14/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 3279.7637 - val_loss: 7978.3481\n",
      "Epoch 15/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 3245.6287 - val_loss: 7927.5571\n",
      "Epoch 16/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 3192.5691 - val_loss: 7853.7588\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1853.0249\n",
      "[CV] END learning_rate=0.0013464320273500377, unit1=3, unit2=126, unit3=73; total time=   0.8s\n",
      "Epoch 1/1000\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 2923.5745 - val_loss: 8151.8691\n",
      "Epoch 2/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 2895.2754 - val_loss: 8109.5298\n",
      "Epoch 3/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 2852.7461 - val_loss: 8043.9341\n",
      "Epoch 4/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 2780.1892 - val_loss: 7892.9321\n",
      "Epoch 5/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 2579.6265 - val_loss: 7323.5947\n",
      "Epoch 6/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 2091.3062 - val_loss: 7739.6943\n",
      "Epoch 7/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 2249.8708 - val_loss: 6233.7124\n",
      "Epoch 8/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 2426.4448 - val_loss: 8110.1870\n",
      "Epoch 9/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 2861.4624 - val_loss: 8080.1929\n",
      "Epoch 10/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 2835.5547 - val_loss: 8047.2617\n",
      "Epoch 11/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 2805.8965 - val_loss: 8010.6318\n",
      "Epoch 12/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 2772.3440 - val_loss: 7965.8721\n",
      "Epoch 13/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 2729.8452 - val_loss: 7895.6621\n",
      "Epoch 14/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 2661.9568 - val_loss: 7796.0723\n",
      "Epoch 15/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 2567.0808 - val_loss: 7647.6865\n",
      "Epoch 16/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 2424.6353 - val_loss: 7404.4585\n",
      "Epoch 17/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 2252.8801 - val_loss: 7238.9326\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2442.4827\n",
      "[CV] END learning_rate=0.0013464320273500377, unit1=3, unit2=126, unit3=73; total time=   0.8s\n",
      "Epoch 1/1000\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 2575.1194 - val_loss: 8167.3320\n",
      "Epoch 2/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 2566.2600 - val_loss: 8155.1909\n",
      "Epoch 3/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 2557.5735 - val_loss: 8142.3994\n",
      "Epoch 4/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 2548.4353 - val_loss: 8129.2007\n",
      "Epoch 5/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 2538.5674 - val_loss: 8113.3091\n",
      "Epoch 6/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 2526.6816 - val_loss: 8092.0142\n",
      "Epoch 7/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 2510.9182 - val_loss: 8067.7168\n",
      "Epoch 8/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 2491.5488 - val_loss: 8030.5664\n",
      "Epoch 9/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 2463.5093 - val_loss: 7981.4912\n",
      "Epoch 10/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 2423.2124 - val_loss: 7901.7085\n",
      "Epoch 11/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 2361.3696 - val_loss: 7790.1396\n",
      "Epoch 12/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 2269.2781 - val_loss: 7605.9033\n",
      "Epoch 13/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 2125.6875 - val_loss: 7262.3179\n",
      "Epoch 14/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 1862.9606 - val_loss: 6755.8667\n",
      "Epoch 15/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 1541.0670 - val_loss: 6311.9243\n",
      "Epoch 16/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 1354.6450 - val_loss: 6169.7617\n",
      "Epoch 17/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 1316.6700 - val_loss: 6066.2217\n",
      "Epoch 18/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 1288.9060 - val_loss: 6057.6929\n",
      "Epoch 19/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 1112.7119 - val_loss: 5890.5493\n",
      "Epoch 20/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 998.0499 - val_loss: 5727.7695\n",
      "Epoch 21/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 997.4836 - val_loss: 5633.4629\n",
      "Epoch 22/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 865.7743 - val_loss: 5634.7959\n",
      "Epoch 23/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 792.9911 - val_loss: 5514.5176\n",
      "Epoch 24/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 949.3780 - val_loss: 5435.2319\n",
      "Epoch 25/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 613.7366 - val_loss: 5324.5601\n",
      "Epoch 26/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 550.8911 - val_loss: 5441.8125\n",
      "Epoch 27/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 533.8470 - val_loss: 5255.6118\n",
      "Epoch 28/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 446.0848 - val_loss: 5239.6641\n",
      "Epoch 29/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 419.1840 - val_loss: 5233.2153\n",
      "Epoch 30/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 389.3832 - val_loss: 5312.4058\n",
      "Epoch 31/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 14ms/step - loss: 461.7090 - val_loss: 5498.7109\n",
      "Epoch 32/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 355.3968 - val_loss: 5276.4019\n",
      "Epoch 33/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 321.3848 - val_loss: 5398.8159\n",
      "Epoch 34/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 320.0441 - val_loss: 5342.1743\n",
      "Epoch 35/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 444.7385 - val_loss: 5226.7788\n",
      "Epoch 36/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 302.3242 - val_loss: 5311.9058\n",
      "Epoch 37/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 283.2774 - val_loss: 5432.1006\n",
      "Epoch 38/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 275.5826 - val_loss: 5311.8560\n",
      "Epoch 39/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 425.5776 - val_loss: 5291.7417\n",
      "Epoch 40/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 282.4003 - val_loss: 5464.3154\n",
      "Epoch 41/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 388.2874 - val_loss: 5602.7700\n",
      "Epoch 42/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 368.4605 - val_loss: 5304.7798\n",
      "Epoch 43/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 269.9832 - val_loss: 5320.1606\n",
      "Epoch 44/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 239.2560 - val_loss: 5335.7153\n",
      "Epoch 45/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 354.2714 - val_loss: 5560.2100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2090.5276\n",
      "[CV] END learning_rate=0.00032165655238266904, unit1=88, unit2=106, unit3=85; total time=   1.8s\n",
      "Epoch 1/1000\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 3445.1521 - val_loss: 8174.2109\n",
      "Epoch 2/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 3435.2144 - val_loss: 8163.2217\n",
      "Epoch 3/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 3424.6604 - val_loss: 8151.9243\n",
      "Epoch 4/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 3413.5610 - val_loss: 8139.5996\n",
      "Epoch 5/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 3401.2136 - val_loss: 8125.2456\n",
      "Epoch 6/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 3387.1213 - val_loss: 8108.9609\n",
      "Epoch 7/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 3370.1411 - val_loss: 8087.3516\n",
      "Epoch 8/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 3347.8979 - val_loss: 8057.9902\n",
      "Epoch 9/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 3316.6023 - val_loss: 8013.9629\n",
      "Epoch 10/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 3268.0105 - val_loss: 7946.8418\n",
      "Epoch 11/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 3192.2629 - val_loss: 7835.3193\n",
      "Epoch 12/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 3061.2104 - val_loss: 7620.6450\n",
      "Epoch 13/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 2806.7295 - val_loss: 7179.2524\n",
      "Epoch 14/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 2306.8318 - val_loss: 6546.7280\n",
      "Epoch 15/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 1813.2606 - val_loss: 6275.2212\n",
      "Epoch 16/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 1627.7347 - val_loss: 6147.7725\n",
      "Epoch 17/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1527.2545 - val_loss: 6024.9751\n",
      "Epoch 18/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1497.1428 - val_loss: 5945.4302\n",
      "Epoch 19/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1423.2915 - val_loss: 5846.9307\n",
      "Epoch 20/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1289.2474 - val_loss: 5923.4487\n",
      "Epoch 21/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 1194.1479 - val_loss: 5663.5073\n",
      "Epoch 22/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 1342.5277 - val_loss: 5982.6226\n",
      "Epoch 23/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 1074.1208 - val_loss: 5560.9507\n",
      "Epoch 24/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 1047.3314 - val_loss: 5423.2412\n",
      "Epoch 25/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 1025.2362 - val_loss: 5499.1963\n",
      "Epoch 26/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 957.0852 - val_loss: 5302.4126\n",
      "Epoch 27/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 714.9860 - val_loss: 5245.3594\n",
      "Epoch 28/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 582.7863 - val_loss: 5461.3101\n",
      "Epoch 29/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 623.3770 - val_loss: 5825.5337\n",
      "Epoch 30/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 626.1703 - val_loss: 5276.2749\n",
      "Epoch 31/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 494.3526 - val_loss: 5153.9360\n",
      "Epoch 32/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 786.3616 - val_loss: 5580.2476\n",
      "Epoch 33/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 417.8303 - val_loss: 5214.1533\n",
      "Epoch 34/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1207.0225 - val_loss: 5409.6777\n",
      "Epoch 35/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 373.3984 - val_loss: 5166.6079\n",
      "Epoch 36/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 349.4490 - val_loss: 5236.0161\n",
      "Epoch 37/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 349.3465 - val_loss: 5240.6831\n",
      "Epoch 38/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 404.8076 - val_loss: 5223.4683\n",
      "Epoch 39/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 304.1807 - val_loss: 5138.8926\n",
      "Epoch 40/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 284.5930 - val_loss: 5266.4868\n",
      "Epoch 41/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 389.0981 - val_loss: 5273.3706\n",
      "Epoch 42/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 287.5768 - val_loss: 5184.3633\n",
      "Epoch 43/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 261.2291 - val_loss: 5020.6592\n",
      "Epoch 44/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 610.1248 - val_loss: 5456.2661\n",
      "Epoch 45/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 295.9216 - val_loss: 5222.9990\n",
      "Epoch 46/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 209.2123 - val_loss: 5079.6919\n",
      "Epoch 47/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 393.0382 - val_loss: 5009.2144\n",
      "Epoch 48/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 319.2090 - val_loss: 5131.1460\n",
      "Epoch 49/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 201.7109 - val_loss: 5163.5972\n",
      "Epoch 50/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 193.2630 - val_loss: 5088.4429\n",
      "Epoch 51/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 178.7518 - val_loss: 5218.7427\n",
      "Epoch 52/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 185.3472 - val_loss: 5122.9404\n",
      "Epoch 53/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 213.0795 - val_loss: 5118.9775\n",
      "Epoch 54/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 168.7219 - val_loss: 5126.5649\n",
      "Epoch 55/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 165.1318 - val_loss: 5138.2808\n",
      "Epoch 56/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 175.7825 - val_loss: 5240.2095\n",
      "Epoch 57/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 186.3243 - val_loss: 5313.0010\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 901.1464\n",
      "[CV] END learning_rate=0.00032165655238266904, unit1=88, unit2=106, unit3=85; total time=   2.2s\n",
      "Epoch 1/1000\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 2935.6960 - val_loss: 8177.7559\n",
      "Epoch 2/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 2925.8364 - val_loss: 8167.5132\n",
      "Epoch 3/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 2916.4771 - val_loss: 8156.7153\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 2906.6470 - val_loss: 8144.5254\n",
      "Epoch 5/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 2895.3860 - val_loss: 8129.8086\n",
      "Epoch 6/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 2881.9736 - val_loss: 8114.3882\n",
      "Epoch 7/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 2867.8901 - val_loss: 8096.2354\n",
      "Epoch 8/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 2849.9644 - val_loss: 8071.4795\n",
      "Epoch 9/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 2828.3538 - val_loss: 8041.6885\n",
      "Epoch 10/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 2797.1965 - val_loss: 7997.3984\n",
      "Epoch 11/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 2754.2668 - val_loss: 7929.7153\n",
      "Epoch 12/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 2683.6621 - val_loss: 7819.5488\n",
      "Epoch 13/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 2571.3721 - val_loss: 7639.6436\n",
      "Epoch 14/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 2387.0486 - val_loss: 7329.3809\n",
      "Epoch 15/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 2083.2715 - val_loss: 6860.6938\n",
      "Epoch 16/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 1763.9994 - val_loss: 6549.5620\n",
      "Epoch 17/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 1522.3672 - val_loss: 6293.9668\n",
      "Epoch 18/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 1561.2787 - val_loss: 6297.3633\n",
      "Epoch 19/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1369.1896 - val_loss: 6087.7358\n",
      "Epoch 20/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1242.6530 - val_loss: 6073.8511\n",
      "Epoch 21/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1304.1786 - val_loss: 5964.4731\n",
      "Epoch 22/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 1051.4188 - val_loss: 5837.9507\n",
      "Epoch 23/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 946.2916 - val_loss: 6039.4521\n",
      "Epoch 24/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1004.9548 - val_loss: 5850.4048\n",
      "Epoch 25/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 784.1042 - val_loss: 5858.9829\n",
      "Epoch 26/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 698.1058 - val_loss: 5693.2666\n",
      "Epoch 27/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 614.2593 - val_loss: 5575.8882\n",
      "Epoch 28/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 586.6035 - val_loss: 5650.3472\n",
      "Epoch 29/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 534.2458 - val_loss: 5792.7261\n",
      "Epoch 30/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 469.9225 - val_loss: 5646.7466\n",
      "Epoch 31/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 721.6630 - val_loss: 5737.3784\n",
      "Epoch 32/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 433.1978 - val_loss: 5602.0312\n",
      "Epoch 33/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 389.7840 - val_loss: 5878.0547\n",
      "Epoch 34/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 366.0741 - val_loss: 5607.8428\n",
      "Epoch 35/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 333.9540 - val_loss: 5693.7930\n",
      "Epoch 36/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 323.8515 - val_loss: 5656.7378\n",
      "Epoch 37/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 321.8593 - val_loss: 5746.1030\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1353.7810\n",
      "[CV] END learning_rate=0.00032165655238266904, unit1=88, unit2=106, unit3=85; total time=   1.5s\n",
      "Epoch 1/1000\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 2568.4539 - val_loss: 8142.0576\n",
      "Epoch 2/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 2538.9780 - val_loss: 8085.3545\n",
      "Epoch 3/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 2486.6362 - val_loss: 7970.7461\n",
      "Epoch 4/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 2362.1265 - val_loss: 7547.1636\n",
      "Epoch 5/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 1894.9436 - val_loss: 6320.8550\n",
      "Epoch 6/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 1731.0309 - val_loss: 7463.3164\n",
      "Epoch 7/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 1756.4174 - val_loss: 5863.7397\n",
      "Epoch 8/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 1197.9667 - val_loss: 6775.6567\n",
      "Epoch 9/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 1074.8073 - val_loss: 6219.5513\n",
      "Epoch 10/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 3012.9446 - val_loss: 8139.6484\n",
      "Epoch 11/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 2544.6001 - val_loss: 8124.2490\n",
      "Epoch 12/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 2534.0879 - val_loss: 8109.6895\n",
      "Epoch 13/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 2523.1077 - val_loss: 8093.2974\n",
      "Epoch 14/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 2510.6064 - val_loss: 8073.7427\n",
      "Epoch 15/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 2495.8254 - val_loss: 8049.1021\n",
      "Epoch 16/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 2476.9878 - val_loss: 8015.2920\n",
      "Epoch 17/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 2450.5549 - val_loss: 7967.5430\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 3566.9133\n",
      "[CV] END learning_rate=0.001013795819537981, unit1=80, unit2=145, unit3=28; total time=   0.8s\n",
      "Epoch 1/1000\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 3437.6946 - val_loss: 8148.7559\n",
      "Epoch 2/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 3404.8237 - val_loss: 8104.0449\n",
      "Epoch 3/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 3355.2664 - val_loss: 8014.8247\n",
      "Epoch 4/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 3234.9182 - val_loss: 7680.2168\n",
      "Epoch 5/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 2703.0098 - val_loss: 6330.2930\n",
      "Epoch 6/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 1651.3607 - val_loss: 6090.4077\n",
      "Epoch 7/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 1465.6727 - val_loss: 6126.0049\n",
      "Epoch 8/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 1637.1562 - val_loss: 6414.4365\n",
      "Epoch 9/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 1288.6176 - val_loss: 7385.1562\n",
      "Epoch 10/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1834.5452 - val_loss: 5896.2852\n",
      "Epoch 11/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 758.5538 - val_loss: 6932.6973\n",
      "Epoch 12/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1712.6641 - val_loss: 5841.5684\n",
      "Epoch 13/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 2453.3264 - val_loss: 8181.3965\n",
      "Epoch 14/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 3423.5354 - val_loss: 8118.9927\n",
      "Epoch 15/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 3382.2207 - val_loss: 8103.7559\n",
      "Epoch 16/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 3368.4397 - val_loss: 8089.2588\n",
      "Epoch 17/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 3354.8713 - val_loss: 8073.5542\n",
      "Epoch 18/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 3340.3394 - val_loss: 8058.2715\n",
      "Epoch 19/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 3325.4873 - val_loss: 8039.4336\n",
      "Epoch 20/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 3307.4084 - val_loss: 8017.9570\n",
      "Epoch 21/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 3285.8965 - val_loss: 7986.7007\n",
      "Epoch 22/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 3254.9363 - val_loss: 7945.5371\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1911.7738\n",
      "[CV] END learning_rate=0.001013795819537981, unit1=80, unit2=145, unit3=28; total time=   1.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 2926.9214 - val_loss: 8153.3921\n",
      "Epoch 2/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 2897.2434 - val_loss: 8108.3545\n",
      "Epoch 3/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 2851.6584 - val_loss: 8021.9487\n",
      "Epoch 4/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 2754.8645 - val_loss: 7801.0527\n",
      "Epoch 5/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 2453.4766 - val_loss: 6767.7891\n",
      "Epoch 6/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 1714.6482 - val_loss: 6104.6982\n",
      "Epoch 7/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 1872.2885 - val_loss: 5953.4551\n",
      "Epoch 8/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 1168.4767 - val_loss: 7074.7109\n",
      "Epoch 9/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 1706.9001 - val_loss: 7888.7588\n",
      "Epoch 10/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 2519.4504 - val_loss: 7256.9067\n",
      "Epoch 11/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 1397.9873 - val_loss: 7656.7070\n",
      "Epoch 12/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 4035.2493 - val_loss: 8127.6479\n",
      "Epoch 13/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 2879.3184 - val_loss: 8111.3936\n",
      "Epoch 14/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 2865.3154 - val_loss: 8095.4824\n",
      "Epoch 15/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 2851.6543 - val_loss: 8080.4351\n",
      "Epoch 16/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 2838.7244 - val_loss: 8065.6826\n",
      "Epoch 17/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 2825.8127 - val_loss: 8050.6655\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2989.6191\n",
      "[CV] END learning_rate=0.001013795819537981, unit1=80, unit2=145, unit3=28; total time=   0.8s\n",
      "Epoch 1/1000\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 2575.1128 - val_loss: 8152.4155\n",
      "Epoch 2/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 2551.0979 - val_loss: 8113.9883\n",
      "Epoch 3/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 2520.0667 - val_loss: 8054.3359\n",
      "Epoch 4/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 2465.4077 - val_loss: 7867.4990\n",
      "Epoch 5/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 2262.1245 - val_loss: 7105.4097\n",
      "Epoch 6/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 2217.3083 - val_loss: 8049.8560\n",
      "Epoch 7/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 2472.4822 - val_loss: 7994.4565\n",
      "Epoch 8/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 2426.7437 - val_loss: 7905.9717\n",
      "Epoch 9/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 2348.1738 - val_loss: 7696.9551\n",
      "Epoch 10/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 2144.2224 - val_loss: 6987.2388\n",
      "Epoch 11/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 1356.3314 - val_loss: 5722.1616\n",
      "Epoch 12/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1166.4478 - val_loss: 7240.7876\n",
      "Epoch 13/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1439.5991 - val_loss: 6346.0747\n",
      "Epoch 14/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 613.2487 - val_loss: 24766.1367\n",
      "Epoch 15/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 11911.3613 - val_loss: 8071.0493\n",
      "Epoch 16/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 2490.5144 - val_loss: 8038.1440\n",
      "Epoch 17/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 2468.8506 - val_loss: 8003.3013\n",
      "Epoch 18/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 2441.4595 - val_loss: 7942.8433\n",
      "Epoch 19/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 2386.6414 - val_loss: 7771.9629\n",
      "Epoch 20/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 2213.4893 - val_loss: 7178.5000\n",
      "Epoch 21/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1806.8104 - val_loss: 7205.6870\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 3030.9980\n",
      "[CV] END learning_rate=0.0017544161473511712, unit1=19, unit2=34, unit3=82; total time=   1.0s\n",
      "Epoch 1/1000\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 3433.1394 - val_loss: 8134.5991\n",
      "Epoch 2/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 3384.5737 - val_loss: 8063.0430\n",
      "Epoch 3/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 3289.8574 - val_loss: 7771.2217\n",
      "Epoch 4/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 2798.7131 - val_loss: 6895.7671\n",
      "Epoch 5/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 3397.1880 - val_loss: 8135.5542\n",
      "Epoch 6/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 3389.3452 - val_loss: 8092.9180\n",
      "Epoch 7/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 3353.0254 - val_loss: 8061.0547\n",
      "Epoch 8/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 3322.6846 - val_loss: 8027.1377\n",
      "Epoch 9/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 3289.8232 - val_loss: 7986.6768\n",
      "Epoch 10/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 3250.4231 - val_loss: 7935.8940\n",
      "Epoch 11/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 3197.3403 - val_loss: 7862.2202\n",
      "Epoch 12/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 3122.5872 - val_loss: 7757.9824\n",
      "Epoch 13/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 3019.8323 - val_loss: 7586.5303\n",
      "Epoch 14/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 2838.0708 - val_loss: 7342.6064\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1587.4926\n",
      "[CV] END learning_rate=0.0017544161473511712, unit1=19, unit2=34, unit3=82; total time=   0.7s\n",
      "Epoch 1/1000\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 2915.7639 - val_loss: 8118.5161\n",
      "Epoch 2/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 2855.8015 - val_loss: 7981.4507\n",
      "Epoch 3/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 2652.8606 - val_loss: 7185.9126\n",
      "Epoch 4/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 3459.8269 - val_loss: 8171.7202\n",
      "Epoch 5/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 2901.7129 - val_loss: 8107.5269\n",
      "Epoch 6/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 2860.1038 - val_loss: 8082.0317\n",
      "Epoch 7/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 2837.5950 - val_loss: 8053.6538\n",
      "Epoch 8/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 2811.2356 - val_loss: 8018.8467\n",
      "Epoch 9/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 2778.5276 - val_loss: 7970.8579\n",
      "Epoch 10/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 2733.4229 - val_loss: 7907.1870\n",
      "Epoch 11/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 2673.9004 - val_loss: 7814.0664\n",
      "Epoch 12/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 2577.4177 - val_loss: 7640.8057\n",
      "Epoch 13/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 2395.3601 - val_loss: 7147.6450\n",
      "Epoch 14/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1993.0420 - val_loss: 7053.0879\n",
      "Epoch 15/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 1503.5686 - val_loss: 18730.6680\n",
      "Epoch 16/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 8850.4307 - val_loss: 7990.6870\n",
      "Epoch 17/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 2758.7729 - val_loss: 7969.5747\n",
      "Epoch 18/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 2742.8184 - val_loss: 7952.4453\n",
      "Epoch 19/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 2728.5981 - val_loss: 7936.7993\n",
      "Epoch 20/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 2714.7324 - val_loss: 7920.3647\n",
      "Epoch 21/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 2700.6521 - val_loss: 7902.1826\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 2683.9612 - val_loss: 7877.7100\n",
      "Epoch 23/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 2660.3389 - val_loss: 7833.2095\n",
      "Epoch 24/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 2607.9536 - val_loss: 7652.9927\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2684.7227\n",
      "[CV] END learning_rate=0.0017544161473511712, unit1=19, unit2=34, unit3=82; total time=   1.0s\n",
      "Epoch 1/1000\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 2543.2114 - val_loss: 7859.6274\n",
      "Epoch 2/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 39390.7422 - val_loss: 8509.1973\n",
      "Epoch 3/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 2670.8982 - val_loss: 7708.1260\n",
      "Epoch 4/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 3341.7983 - val_loss: 572794112.0000\n",
      "Epoch 5/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: inf - val_loss: nan\n",
      "Epoch 6/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: nan - val_loss: nan\n",
      "Epoch 7/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: nan - val_loss: nan\n",
      "Epoch 8/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: nan - val_loss: nan\n",
      "Epoch 9/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: nan - val_loss: nan\n",
      "Epoch 11/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: nan - val_loss: nan\n",
      "Epoch 12/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: nan - val_loss: nan\n",
      "Epoch 13/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: nan - val_loss: nan\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan\n",
      "[CV] END learning_rate=0.006609624932254667, unit1=25, unit2=89, unit3=44; total time=   0.8s\n",
      "Epoch 1/1000\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 3390.7612 - val_loss: 7597.7876\n",
      "Epoch 2/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 14494.3770 - val_loss: 8209.1123\n",
      "Epoch 3/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 3447.7314 - val_loss: 8123.9062\n",
      "Epoch 4/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 3364.9800 - val_loss: 7982.4541\n",
      "Epoch 5/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 2717.3147 - val_loss: 1047572.4375\n",
      "Epoch 6/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 122857313009664.0000 - val_loss: 83564765184.0000\n",
      "Epoch 7/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 81695956992.0000 - val_loss: 77152059392.0000\n",
      "Epoch 8/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 75426627584.0000 - val_loss: 71231471616.0000\n",
      "Epoch 9/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 69638389760.0000 - val_loss: 65765208064.0000\n",
      "Epoch 10/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 64294334464.0000 - val_loss: 60718419968.0000\n",
      "Epoch 11/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 59360378880.0000 - val_loss: 56058949632.0000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 56053813248.0000\n",
      "[CV] END learning_rate=0.006609624932254667, unit1=25, unit2=89, unit3=44; total time=   0.6s\n",
      "Epoch 1/1000\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 2877.1970 - val_loss: 7437.7085\n",
      "Epoch 2/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 3032.0786 - val_loss: 8090.6641\n",
      "Epoch 3/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 2828.0557 - val_loss: 7973.3530\n",
      "Epoch 4/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 2688.3684 - val_loss: 7532.0688\n",
      "Epoch 5/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 2041.9020 - val_loss: 8000.4927\n",
      "Epoch 6/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 2729.8274 - val_loss: 7825.3467\n",
      "Epoch 7/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 2552.7732 - val_loss: 7430.3579\n",
      "Epoch 8/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 2136.3779 - val_loss: 7442.1382\n",
      "Epoch 9/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 2524.6711 - val_loss: 7805.5244\n",
      "Epoch 10/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 2562.3914 - val_loss: 7572.4785\n",
      "Epoch 11/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 2342.9766 - val_loss: 7233.1494\n",
      "Epoch 12/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 2194.6833 - val_loss: 7097.0317\n",
      "Epoch 13/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 2151.7026 - val_loss: 7243.6396\n",
      "Epoch 14/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 2151.2566 - val_loss: 7094.9888\n",
      "Epoch 15/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 2083.0959 - val_loss: 7067.9082\n",
      "Epoch 16/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 2076.5566 - val_loss: 7149.6265\n",
      "Epoch 17/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 2055.4346 - val_loss: 11215.2578\n",
      "Epoch 18/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 4991.4780 - val_loss: 7752.5200\n",
      "Epoch 19/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 2551.0894 - val_loss: 7704.5635\n",
      "Epoch 20/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 2512.8181 - val_loss: 7664.8936\n",
      "Epoch 21/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 2479.9233 - val_loss: 7625.6377\n",
      "Epoch 22/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 2448.2620 - val_loss: 7588.1636\n",
      "Epoch 23/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 2419.0820 - val_loss: 7554.0874\n",
      "Epoch 24/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 2390.4304 - val_loss: 7518.0386\n",
      "Epoch 25/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 2360.7566 - val_loss: 7470.0327\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2572.6497\n",
      "[CV] END learning_rate=0.006609624932254667, unit1=25, unit2=89, unit3=44; total time=   1.1s\n",
      "Epoch 1/1000\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 2584.0945 - val_loss: 8188.9126\n",
      "Epoch 2/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 2581.6230 - val_loss: 8185.2759\n",
      "Epoch 3/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 2579.1221 - val_loss: 8181.9570\n",
      "Epoch 4/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 2576.7371 - val_loss: 8178.3926\n",
      "Epoch 5/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 2574.2832 - val_loss: 8175.1533\n",
      "Epoch 6/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 2571.9800 - val_loss: 8171.5835\n",
      "Epoch 7/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 2569.4277 - val_loss: 8167.8188\n",
      "Epoch 8/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 2566.8386 - val_loss: 8164.4824\n",
      "Epoch 9/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 2564.4119 - val_loss: 8160.9824\n",
      "Epoch 10/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 2561.9785 - val_loss: 8157.5547\n",
      "Epoch 11/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 2559.4246 - val_loss: 8153.7280\n",
      "Epoch 12/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 2556.7402 - val_loss: 8150.1792\n",
      "Epoch 13/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 2554.1401 - val_loss: 8146.0605\n",
      "Epoch 14/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 2551.1538 - val_loss: 8142.0054\n",
      "Epoch 15/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 2548.2166 - val_loss: 8137.9180\n",
      "Epoch 16/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 2545.2185 - val_loss: 8133.1138\n",
      "Epoch 17/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 2541.7295 - val_loss: 8128.7295\n",
      "Epoch 18/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 2538.5137 - val_loss: 8123.3921\n",
      "Epoch 19/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 2534.6511 - val_loss: 8118.5708\n",
      "Epoch 20/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 2531.1614 - val_loss: 8113.6182\n",
      "Epoch 21/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 2527.4331 - val_loss: 8107.4985\n",
      "Epoch 22/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 2522.9888 - val_loss: 8101.6870\n",
      "Epoch 23/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 2518.7913 - val_loss: 8095.4165\n",
      "Epoch 24/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 2514.1028 - val_loss: 8088.5718\n",
      "Epoch 25/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 2509.0923 - val_loss: 8081.4111\n",
      "Epoch 26/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 2503.8689 - val_loss: 8073.3638\n",
      "Epoch 27/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 2498.1365 - val_loss: 8065.1880\n",
      "Epoch 28/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 2491.8645 - val_loss: 8054.5000\n",
      "Epoch 29/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 2484.4053 - val_loss: 8044.3608\n",
      "Epoch 30/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 2476.5676 - val_loss: 8033.1709\n",
      "Epoch 31/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 2468.5815 - val_loss: 8021.2759\n",
      "Epoch 32/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 2459.1548 - val_loss: 8005.5850\n",
      "Epoch 33/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 2447.5398 - val_loss: 7986.9341\n",
      "Epoch 34/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 2433.4651 - val_loss: 7967.2485\n",
      "Epoch 35/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 2418.6199 - val_loss: 7944.1685\n",
      "Epoch 36/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 2401.4475 - val_loss: 7918.5527\n",
      "Epoch 37/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 2382.2798 - val_loss: 7887.8130\n",
      "Epoch 38/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 2359.9192 - val_loss: 7852.6348\n",
      "Epoch 39/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 2332.8120 - val_loss: 7812.4106\n",
      "Epoch 40/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 2303.2339 - val_loss: 7766.8135\n",
      "Epoch 41/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 2268.7786 - val_loss: 7705.4873\n",
      "Epoch 42/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 2222.2043 - val_loss: 7630.1382\n",
      "Epoch 43/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 2165.8613 - val_loss: 7539.8271\n",
      "Epoch 44/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 2102.9712 - val_loss: 7416.5161\n",
      "Epoch 45/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 2009.4396 - val_loss: 7294.3877\n",
      "Epoch 46/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1922.5735 - val_loss: 7152.6089\n",
      "Epoch 47/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 1833.6317 - val_loss: 7010.2915\n",
      "Epoch 48/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 1738.2263 - val_loss: 6807.6855\n",
      "Epoch 49/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1605.9177 - val_loss: 6643.9453\n",
      "Epoch 50/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 1524.2249 - val_loss: 6536.0420\n",
      "Epoch 51/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 1464.7185 - val_loss: 6377.0171\n",
      "Epoch 52/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 1387.5968 - val_loss: 6317.3633\n",
      "Epoch 53/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 1363.3497 - val_loss: 6203.0723\n",
      "Epoch 54/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 1307.8071 - val_loss: 6151.9995\n",
      "Epoch 55/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1273.6962 - val_loss: 6101.7158\n",
      "Epoch 56/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1239.6185 - val_loss: 6073.6665\n",
      "Epoch 57/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 1208.5388 - val_loss: 6036.4033\n",
      "Epoch 58/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 1201.1323 - val_loss: 6029.8652\n",
      "Epoch 59/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1166.3145 - val_loss: 5943.5967\n",
      "Epoch 60/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1117.7777 - val_loss: 5906.5391\n",
      "Epoch 61/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 1080.2880 - val_loss: 5885.1118\n",
      "Epoch 62/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 1064.7129 - val_loss: 5820.7095\n",
      "Epoch 63/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 1039.0439 - val_loss: 5776.9712\n",
      "Epoch 64/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 1008.0841 - val_loss: 5737.3438\n",
      "Epoch 65/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 1032.9733 - val_loss: 5749.0356\n",
      "Epoch 66/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 917.8019 - val_loss: 5729.6738\n",
      "Epoch 67/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 924.1439 - val_loss: 5754.0679\n",
      "Epoch 68/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 907.9083 - val_loss: 5710.4507\n",
      "Epoch 69/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 855.1122 - val_loss: 5633.8062\n",
      "Epoch 70/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 847.5864 - val_loss: 5632.0039\n",
      "Epoch 71/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 798.4725 - val_loss: 5616.7993\n",
      "Epoch 72/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 770.8411 - val_loss: 5536.4570\n",
      "Epoch 73/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 751.0967 - val_loss: 5551.5737\n",
      "Epoch 74/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 744.2711 - val_loss: 5563.9863\n",
      "Epoch 75/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 708.7344 - val_loss: 5451.1538\n",
      "Epoch 76/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 669.0544 - val_loss: 5415.4189\n",
      "Epoch 77/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 655.7883 - val_loss: 5472.5645\n",
      "Epoch 78/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 632.1239 - val_loss: 5477.7070\n",
      "Epoch 79/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 616.1349 - val_loss: 5357.0015\n",
      "Epoch 80/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 600.8829 - val_loss: 5405.4116\n",
      "Epoch 81/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 548.9899 - val_loss: 5321.4248\n",
      "Epoch 82/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 534.4321 - val_loss: 5302.7461\n",
      "Epoch 83/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 518.1324 - val_loss: 5326.4326\n",
      "Epoch 84/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 482.2251 - val_loss: 5303.9795\n",
      "Epoch 85/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 489.1546 - val_loss: 5258.1880\n",
      "Epoch 86/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 488.0869 - val_loss: 5257.7095\n",
      "Epoch 87/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 445.8393 - val_loss: 5292.6816\n",
      "Epoch 88/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 434.2792 - val_loss: 5293.5483\n",
      "Epoch 89/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 421.4928 - val_loss: 5261.3564\n",
      "Epoch 90/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 425.6769 - val_loss: 5310.0181\n",
      "Epoch 91/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 407.1219 - val_loss: 5234.1987\n",
      "Epoch 92/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 391.1553 - val_loss: 5221.7632\n",
      "Epoch 93/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 416.5610 - val_loss: 5301.9688\n",
      "Epoch 94/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 396.1334 - val_loss: 5247.0278\n",
      "Epoch 95/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 369.3297 - val_loss: 5251.9624\n",
      "Epoch 96/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 364.5603 - val_loss: 5267.0771\n",
      "Epoch 97/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 14ms/step - loss: 376.4108 - val_loss: 5283.5771\n",
      "Epoch 98/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 353.5494 - val_loss: 5254.4497\n",
      "Epoch 99/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 358.5667 - val_loss: 5309.3755\n",
      "Epoch 100/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 378.6680 - val_loss: 5267.7490\n",
      "Epoch 101/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 336.2569 - val_loss: 5249.1729\n",
      "Epoch 102/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 331.2366 - val_loss: 5211.8740\n",
      "Epoch 103/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 327.1549 - val_loss: 5252.9487\n",
      "Epoch 104/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 333.3980 - val_loss: 5265.6719\n",
      "Epoch 105/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 332.8058 - val_loss: 5301.9224\n",
      "Epoch 106/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 321.1533 - val_loss: 5253.1250\n",
      "Epoch 107/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 309.3648 - val_loss: 5264.5518\n",
      "Epoch 108/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 315.5195 - val_loss: 5292.8193\n",
      "Epoch 109/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 317.5775 - val_loss: 5200.6455\n",
      "Epoch 110/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 318.6927 - val_loss: 5267.0654\n",
      "Epoch 111/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 306.3336 - val_loss: 5288.6675\n",
      "Epoch 112/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 297.5210 - val_loss: 5282.8301\n",
      "Epoch 113/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 305.8849 - val_loss: 5245.5200\n",
      "Epoch 114/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 301.8229 - val_loss: 5210.6533\n",
      "Epoch 115/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 285.4649 - val_loss: 5238.1987\n",
      "Epoch 116/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 281.6357 - val_loss: 5275.2471\n",
      "Epoch 117/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 288.4440 - val_loss: 5225.7261\n",
      "Epoch 118/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 274.2436 - val_loss: 5230.7915\n",
      "Epoch 119/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 268.2664 - val_loss: 5257.2319\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1811.2327\n",
      "[CV] END learning_rate=0.0001074063096070056, unit1=58, unit2=110, unit3=96; total time=   4.4s\n",
      "Epoch 1/1000\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 3448.7954 - val_loss: 8183.5962\n",
      "Epoch 2/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 3445.0098 - val_loss: 8179.6479\n",
      "Epoch 3/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 3441.4810 - val_loss: 8176.0635\n",
      "Epoch 4/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 3437.8411 - val_loss: 8171.9854\n",
      "Epoch 5/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 3433.9285 - val_loss: 8167.9990\n",
      "Epoch 6/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 3430.1370 - val_loss: 8163.7432\n",
      "Epoch 7/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 3426.0525 - val_loss: 8159.4795\n",
      "Epoch 8/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 3421.8687 - val_loss: 8155.1123\n",
      "Epoch 9/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 3417.6882 - val_loss: 8150.6484\n",
      "Epoch 10/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 3413.3293 - val_loss: 8145.6997\n",
      "Epoch 11/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 3408.6355 - val_loss: 8140.7202\n",
      "Epoch 12/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 3403.7410 - val_loss: 8135.3921\n",
      "Epoch 13/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 3398.4688 - val_loss: 8129.3677\n",
      "Epoch 14/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 3392.5752 - val_loss: 8122.3750\n",
      "Epoch 15/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 3385.8855 - val_loss: 8115.8608\n",
      "Epoch 16/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 3379.3215 - val_loss: 8108.1885\n",
      "Epoch 17/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 3371.9182 - val_loss: 8100.6323\n",
      "Epoch 18/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 3364.2332 - val_loss: 8091.4673\n",
      "Epoch 19/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 3355.1287 - val_loss: 8081.1885\n",
      "Epoch 20/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 3344.8281 - val_loss: 8070.2803\n",
      "Epoch 21/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 3334.0938 - val_loss: 8058.4785\n",
      "Epoch 22/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 3321.9590 - val_loss: 8044.0405\n",
      "Epoch 23/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 3307.3914 - val_loss: 8028.0718\n",
      "Epoch 24/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 3291.1401 - val_loss: 8009.1167\n",
      "Epoch 25/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 3272.6804 - val_loss: 7989.1016\n",
      "Epoch 26/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 3251.3809 - val_loss: 7962.9976\n",
      "Epoch 27/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 3224.8877 - val_loss: 7931.7783\n",
      "Epoch 28/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 3194.1570 - val_loss: 7895.7065\n",
      "Epoch 29/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 3155.8567 - val_loss: 7851.1880\n",
      "Epoch 30/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 3112.0112 - val_loss: 7799.1045\n",
      "Epoch 31/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 3056.1633 - val_loss: 7729.1582\n",
      "Epoch 32/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 2984.2676 - val_loss: 7637.4888\n",
      "Epoch 33/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 2888.5874 - val_loss: 7524.6782\n",
      "Epoch 34/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 2773.9285 - val_loss: 7388.9336\n",
      "Epoch 35/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 2637.4670 - val_loss: 7209.5044\n",
      "Epoch 36/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 2453.1582 - val_loss: 7002.4600\n",
      "Epoch 37/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 2265.3193 - val_loss: 6736.0952\n",
      "Epoch 38/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 2020.9861 - val_loss: 6569.6914\n",
      "Epoch 39/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 1885.2802 - val_loss: 6446.0586\n",
      "Epoch 40/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1817.8984 - val_loss: 6379.3564\n",
      "Epoch 41/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 1734.2695 - val_loss: 6312.9385\n",
      "Epoch 42/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1682.6451 - val_loss: 6248.0088\n",
      "Epoch 43/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 1673.5865 - val_loss: 6221.2617\n",
      "Epoch 44/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 1599.4435 - val_loss: 6182.8604\n",
      "Epoch 45/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 1577.4816 - val_loss: 6167.1616\n",
      "Epoch 46/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1536.6287 - val_loss: 6129.9526\n",
      "Epoch 47/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 1503.9214 - val_loss: 6067.6299\n",
      "Epoch 48/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1474.0662 - val_loss: 6028.1724\n",
      "Epoch 49/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 1432.0930 - val_loss: 6011.7222\n",
      "Epoch 50/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1426.1381 - val_loss: 5964.3740\n",
      "Epoch 51/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 1342.2119 - val_loss: 5936.3164\n",
      "Epoch 52/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 1340.0186 - val_loss: 5885.2080\n",
      "Epoch 53/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 1291.5288 - val_loss: 5850.3496\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1258.1411 - val_loss: 5816.3467\n",
      "Epoch 55/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 1210.7994 - val_loss: 5793.8257\n",
      "Epoch 56/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 1196.4158 - val_loss: 5773.6948\n",
      "Epoch 57/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1155.0830 - val_loss: 5731.1973\n",
      "Epoch 58/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1131.6066 - val_loss: 5741.6128\n",
      "Epoch 59/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 1099.5282 - val_loss: 5708.9292\n",
      "Epoch 60/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 1056.9626 - val_loss: 5708.9092\n",
      "Epoch 61/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1029.0555 - val_loss: 5679.9126\n",
      "Epoch 62/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 1003.8606 - val_loss: 5637.2510\n",
      "Epoch 63/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 953.3766 - val_loss: 5596.3184\n",
      "Epoch 64/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 960.2739 - val_loss: 5617.8550\n",
      "Epoch 65/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 933.1657 - val_loss: 5588.6138\n",
      "Epoch 66/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 877.0089 - val_loss: 5548.8252\n",
      "Epoch 67/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 854.1805 - val_loss: 5508.4805\n",
      "Epoch 68/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 806.7605 - val_loss: 5491.6782\n",
      "Epoch 69/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 797.5943 - val_loss: 5430.2910\n",
      "Epoch 70/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 790.2390 - val_loss: 5445.8237\n",
      "Epoch 71/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 729.7156 - val_loss: 5416.5752\n",
      "Epoch 72/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 725.1026 - val_loss: 5455.0054\n",
      "Epoch 73/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 695.2841 - val_loss: 5357.4971\n",
      "Epoch 74/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 652.8344 - val_loss: 5367.8994\n",
      "Epoch 75/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 629.4372 - val_loss: 5343.8970\n",
      "Epoch 76/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 614.8841 - val_loss: 5385.7925\n",
      "Epoch 77/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 591.2786 - val_loss: 5289.4946\n",
      "Epoch 78/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 579.7278 - val_loss: 5271.4277\n",
      "Epoch 79/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 556.9806 - val_loss: 5266.5957\n",
      "Epoch 80/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 534.9334 - val_loss: 5236.7510\n",
      "Epoch 81/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 507.4145 - val_loss: 5287.7759\n",
      "Epoch 82/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 509.0279 - val_loss: 5324.6177\n",
      "Epoch 83/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 519.4891 - val_loss: 5272.7339\n",
      "Epoch 84/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 484.1104 - val_loss: 5242.9199\n",
      "Epoch 85/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 492.6035 - val_loss: 5255.1743\n",
      "Epoch 86/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 458.9694 - val_loss: 5170.8970\n",
      "Epoch 87/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 442.2809 - val_loss: 5180.4976\n",
      "Epoch 88/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 414.6652 - val_loss: 5210.4990\n",
      "Epoch 89/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 399.2545 - val_loss: 5188.7700\n",
      "Epoch 90/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 409.8956 - val_loss: 5149.6025\n",
      "Epoch 91/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 389.8741 - val_loss: 5162.5039\n",
      "Epoch 92/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 393.6039 - val_loss: 5199.6060\n",
      "Epoch 93/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 431.0198 - val_loss: 5227.6323\n",
      "Epoch 94/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 367.9296 - val_loss: 5117.2554\n",
      "Epoch 95/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 365.1457 - val_loss: 5102.0415\n",
      "Epoch 96/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 343.2210 - val_loss: 5166.5771\n",
      "Epoch 97/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 345.5437 - val_loss: 5082.4868\n",
      "Epoch 98/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 329.0558 - val_loss: 5218.4248\n",
      "Epoch 99/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 333.4254 - val_loss: 5072.3882\n",
      "Epoch 100/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 322.3547 - val_loss: 5152.7441\n",
      "Epoch 101/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 301.9078 - val_loss: 5138.5996\n",
      "Epoch 102/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 307.7301 - val_loss: 5138.1592\n",
      "Epoch 103/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 303.3337 - val_loss: 5220.7910\n",
      "Epoch 104/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 314.9952 - val_loss: 5205.5435\n",
      "Epoch 105/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 289.4325 - val_loss: 5144.6299\n",
      "Epoch 106/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 272.9525 - val_loss: 5116.5161\n",
      "Epoch 107/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 273.8242 - val_loss: 5207.3198\n",
      "Epoch 108/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 271.8630 - val_loss: 5117.8066\n",
      "Epoch 109/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 253.3293 - val_loss: 5118.8081\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 692.2780\n",
      "[CV] END learning_rate=0.0001074063096070056, unit1=58, unit2=110, unit3=96; total time=   3.9s\n",
      "Epoch 1/1000\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 2925.7368 - val_loss: 8173.7842\n",
      "Epoch 2/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 2923.4392 - val_loss: 8171.1792\n",
      "Epoch 3/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 2921.0176 - val_loss: 8168.5254\n",
      "Epoch 4/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 2918.6377 - val_loss: 8165.8223\n",
      "Epoch 5/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 2916.1294 - val_loss: 8162.8862\n",
      "Epoch 6/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 2913.4895 - val_loss: 8160.0371\n",
      "Epoch 7/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 2910.9136 - val_loss: 8156.9912\n",
      "Epoch 8/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 2908.1411 - val_loss: 8153.7847\n",
      "Epoch 9/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 2905.3430 - val_loss: 8150.6479\n",
      "Epoch 10/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 2902.4993 - val_loss: 8147.4526\n",
      "Epoch 11/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 2899.5710 - val_loss: 8144.0474\n",
      "Epoch 12/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 2896.5571 - val_loss: 8140.5723\n",
      "Epoch 13/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 2893.3457 - val_loss: 8136.7329\n",
      "Epoch 14/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 2889.8503 - val_loss: 8132.4810\n",
      "Epoch 15/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 2886.0020 - val_loss: 8128.1792\n",
      "Epoch 16/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 2882.0911 - val_loss: 8123.7759\n",
      "Epoch 17/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 2878.1270 - val_loss: 8119.2856\n",
      "Epoch 18/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 2873.9292 - val_loss: 8114.2539\n",
      "Epoch 19/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 2869.3164 - val_loss: 8108.8794\n",
      "Epoch 20/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 2864.5164 - val_loss: 8103.2544\n",
      "Epoch 21/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 2859.2200 - val_loss: 8097.4136\n",
      "Epoch 22/1000\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 2853.8684 - val_loss: 8089.7905\n",
      "Epoch 23/1000\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 2846.7793 - val_loss: 8081.7490\n",
      "Epoch 24/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 2839.3657 - val_loss: 8073.8193\n",
      "Epoch 25/1000\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 2832.0659 - val_loss: 8065.5503\n",
      "Epoch 26/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 2824.4177 - val_loss: 8055.8423\n",
      "Epoch 27/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 2815.5098 - val_loss: 8045.2788\n",
      "Epoch 28/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 2805.5334 - val_loss: 8033.5356\n",
      "Epoch 29/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 2794.5317 - val_loss: 8020.1479\n",
      "Epoch 30/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 2782.0254 - val_loss: 8004.7559\n",
      "Epoch 31/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 2768.1074 - val_loss: 7989.1240\n",
      "Epoch 32/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 2752.9502 - val_loss: 7969.8521\n",
      "Epoch 33/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 2735.3081 - val_loss: 7949.0503\n",
      "Epoch 34/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 2715.3457 - val_loss: 7922.9565\n",
      "Epoch 35/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 2690.3323 - val_loss: 7893.5693\n",
      "Epoch 36/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 2662.5061 - val_loss: 7854.1924\n",
      "Epoch 37/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 2624.5605 - val_loss: 7809.8477\n",
      "Epoch 38/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 2582.5732 - val_loss: 7758.0776\n",
      "Epoch 39/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 2533.9536 - val_loss: 7696.7905\n",
      "Epoch 40/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 2475.6472 - val_loss: 7620.5229\n",
      "Epoch 41/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 2402.3279 - val_loss: 7519.7056\n",
      "Epoch 42/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 2311.4685 - val_loss: 7414.5215\n",
      "Epoch 43/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 2216.6421 - val_loss: 7290.2446\n",
      "Epoch 44/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 2098.7295 - val_loss: 7136.6304\n",
      "Epoch 45/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 1968.5319 - val_loss: 6987.0459\n",
      "Epoch 46/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 1847.0117 - val_loss: 6844.5117\n",
      "Epoch 47/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 1733.7433 - val_loss: 6697.0659\n",
      "Epoch 48/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 1624.3970 - val_loss: 6582.6162\n",
      "Epoch 49/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 1549.5266 - val_loss: 6492.6699\n",
      "Epoch 50/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 1503.2826 - val_loss: 6441.5317\n",
      "Epoch 51/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 1473.5508 - val_loss: 6423.7656\n",
      "Epoch 52/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 1453.8002 - val_loss: 6383.9150\n",
      "Epoch 53/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 1410.0139 - val_loss: 6314.1450\n",
      "Epoch 54/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 1367.9161 - val_loss: 6279.8711\n",
      "Epoch 55/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 1345.0771 - val_loss: 6275.5029\n",
      "Epoch 56/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 1332.9357 - val_loss: 6270.3389\n",
      "Epoch 57/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 1302.5768 - val_loss: 6234.6396\n",
      "Epoch 58/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 1294.1080 - val_loss: 6228.8545\n",
      "Epoch 59/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 1233.1892 - val_loss: 6183.6455\n",
      "Epoch 60/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 1220.7953 - val_loss: 6149.2285\n",
      "Epoch 61/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 1167.3896 - val_loss: 6090.8120\n",
      "Epoch 62/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 1130.0869 - val_loss: 6064.3530\n",
      "Epoch 63/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 1129.2170 - val_loss: 6003.0439\n",
      "Epoch 64/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 1085.4175 - val_loss: 5966.6113\n",
      "Epoch 65/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 1052.5575 - val_loss: 5989.2241\n",
      "Epoch 66/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 1015.4468 - val_loss: 6025.5112\n",
      "Epoch 67/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 982.2592 - val_loss: 5980.6108\n",
      "Epoch 68/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 933.7876 - val_loss: 5912.7754\n",
      "Epoch 69/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 906.3254 - val_loss: 5932.2974\n",
      "Epoch 70/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 865.0538 - val_loss: 5874.2559\n",
      "Epoch 71/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 837.7150 - val_loss: 5886.4619\n",
      "Epoch 72/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 812.8344 - val_loss: 5823.6309\n",
      "Epoch 73/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 789.4510 - val_loss: 5784.7329\n",
      "Epoch 74/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 770.9796 - val_loss: 5780.9150\n",
      "Epoch 75/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 698.0140 - val_loss: 5778.6382\n",
      "Epoch 76/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 691.7670 - val_loss: 5783.3530\n",
      "Epoch 77/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 667.7956 - val_loss: 5729.1587\n",
      "Epoch 78/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 643.2983 - val_loss: 5673.4976\n",
      "Epoch 79/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 603.8833 - val_loss: 5779.2607\n",
      "Epoch 80/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 583.9520 - val_loss: 5806.2734\n",
      "Epoch 81/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 560.6050 - val_loss: 5720.9839\n",
      "Epoch 82/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 519.6876 - val_loss: 5708.0449\n",
      "Epoch 83/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 535.9913 - val_loss: 5725.8936\n",
      "Epoch 84/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 487.0374 - val_loss: 5693.5303\n",
      "Epoch 85/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 467.3751 - val_loss: 5639.6182\n",
      "Epoch 86/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 459.6305 - val_loss: 5761.8481\n",
      "Epoch 87/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 446.4232 - val_loss: 5727.8120\n",
      "Epoch 88/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 426.3800 - val_loss: 5681.5957\n",
      "Epoch 89/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 412.4660 - val_loss: 5636.1543\n",
      "Epoch 90/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 402.4809 - val_loss: 5647.6934\n",
      "Epoch 91/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 391.2851 - val_loss: 5688.8164\n",
      "Epoch 92/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 395.0880 - val_loss: 5650.0078\n",
      "Epoch 93/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 369.9179 - val_loss: 5642.0127\n",
      "Epoch 94/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 368.2887 - val_loss: 5600.0693\n",
      "Epoch 95/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 365.9574 - val_loss: 5699.9170\n",
      "Epoch 96/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 352.4049 - val_loss: 5680.1108\n",
      "Epoch 97/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 342.8171 - val_loss: 5659.8647\n",
      "Epoch 98/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 14ms/step - loss: 337.5673 - val_loss: 5663.0371\n",
      "Epoch 99/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 331.4713 - val_loss: 5671.1699\n",
      "Epoch 100/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 328.5071 - val_loss: 5623.7539\n",
      "Epoch 101/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 334.4139 - val_loss: 5687.2378\n",
      "Epoch 102/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 317.1582 - val_loss: 5655.4854\n",
      "Epoch 103/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 319.1084 - val_loss: 5668.9976\n",
      "Epoch 104/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 306.3084 - val_loss: 5621.2368\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1275.3761\n",
      "[CV] END learning_rate=0.0001074063096070056, unit1=58, unit2=110, unit3=96; total time=   3.6s\n",
      "Epoch 1/1000\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 2563.9915 - val_loss: 8093.1855\n",
      "Epoch 2/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 2473.5457 - val_loss: 7651.2109\n",
      "Epoch 3/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 2160.5239 - val_loss: 8164.5527\n",
      "Epoch 4/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 2538.8330 - val_loss: 8075.9038\n",
      "Epoch 5/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 2490.8301 - val_loss: 8018.1104\n",
      "Epoch 6/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 2445.1506 - val_loss: 7930.6436\n",
      "Epoch 7/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 2370.1597 - val_loss: 7733.4932\n",
      "Epoch 8/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 2170.2151 - val_loss: 6595.9229\n",
      "Epoch 9/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 1660.9119 - val_loss: 237549.5312\n",
      "Epoch 10/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 89507.5156 - val_loss: 7927.2256\n",
      "Epoch 11/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 3769.2935 - val_loss: 8124.0605\n",
      "Epoch 12/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 2529.2317 - val_loss: 8084.8633\n",
      "Epoch 13/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 2502.1028 - val_loss: 8051.0620\n",
      "Epoch 14/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 2477.6135 - val_loss: 8016.6177\n",
      "Epoch 15/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 2453.9934 - val_loss: 7986.4756\n",
      "Epoch 16/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 2432.6414 - val_loss: 7954.0371\n",
      "Epoch 17/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 2410.6160 - val_loss: 7925.2354\n",
      "Epoch 18/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 2391.1870 - val_loss: 7898.8188\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 3491.8745\n",
      "[CV] END learning_rate=0.003944783267943095, unit1=73, unit2=18, unit3=73; total time=   0.8s\n",
      "Epoch 1/1000\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 3429.5559 - val_loss: 8112.2686\n",
      "Epoch 2/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 3348.1550 - val_loss: 7929.3218\n",
      "Epoch 3/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 2903.9229 - val_loss: 6140.2866\n",
      "Epoch 4/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 21313.1465 - val_loss: 8268.8281\n",
      "Epoch 5/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 3576.3140 - val_loss: 8088.8696\n",
      "Epoch 6/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 3279.4204 - val_loss: 7272.4941\n",
      "Epoch 7/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 484168.3438 - val_loss: 400149824.0000\n",
      "Epoch 8/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: inf - val_loss: nan\n",
      "Epoch 9/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: nan - val_loss: nan\n",
      "Epoch 11/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: nan - val_loss: nan\n",
      "Epoch 12/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: nan - val_loss: nan\n",
      "Epoch 13/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: nan - val_loss: nan\n",
      "2/2 [==============================] - 0s 3ms/step - loss: nan\n",
      "[CV] END learning_rate=0.003944783267943095, unit1=73, unit2=18, unit3=73; total time=   0.6s\n",
      "Epoch 1/1000\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 2909.0781 - val_loss: 8064.5586\n",
      "Epoch 2/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 2724.5378 - val_loss: 6325.3735\n",
      "Epoch 3/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 1935.0018 - val_loss: 252593.9375\n",
      "Epoch 4/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 74690.3594 - val_loss: 8224.4648\n",
      "Epoch 5/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 2917.3042 - val_loss: 7825.5479\n",
      "Epoch 6/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 6918.0103 - val_loss: 3006257.0000\n",
      "Epoch 7/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: inf - val_loss: nan\n",
      "Epoch 8/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: nan - val_loss: nan\n",
      "Epoch 9/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: nan - val_loss: nan\n",
      "Epoch 11/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: nan - val_loss: nan\n",
      "Epoch 12/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: nan - val_loss: nan\n",
      "2/2 [==============================] - 0s 3ms/step - loss: nan\n",
      "[CV] END learning_rate=0.003944783267943095, unit1=73, unit2=18, unit3=73; total time=   0.6s\n",
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "H:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [-1485.79256185            nan            nan -2422.91764323\n",
      " -1448.48498535 -2822.76875814 -2434.40441895            nan\n",
      " -1259.6289266             nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 30ms/step - loss: 2984.2981 - val_loss: 8177.5479\n",
      "Epoch 2/1000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 2979.7119 - val_loss: 8172.0571\n",
      "Epoch 3/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 2975.3682 - val_loss: 8166.5649\n",
      "Epoch 4/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 2970.7778 - val_loss: 8161.0908\n",
      "Epoch 5/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 2966.3057 - val_loss: 8155.4824\n",
      "Epoch 6/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 2961.7871 - val_loss: 8149.7041\n",
      "Epoch 7/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 2956.9075 - val_loss: 8143.5576\n",
      "Epoch 8/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 2951.8645 - val_loss: 8137.0659\n",
      "Epoch 9/1000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 2946.4878 - val_loss: 8130.3203\n",
      "Epoch 10/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 2940.8894 - val_loss: 8123.0562\n",
      "Epoch 11/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 2934.8489 - val_loss: 8115.2280\n",
      "Epoch 12/1000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 2928.1917 - val_loss: 8106.6191\n",
      "Epoch 13/1000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 2920.9583 - val_loss: 8096.9688\n",
      "Epoch 14/1000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 2912.7590 - val_loss: 8086.2842\n",
      "Epoch 15/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 2903.8081 - val_loss: 8074.1714\n",
      "Epoch 16/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 2893.4551 - val_loss: 8060.4985\n",
      "Epoch 17/1000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 2882.1406 - val_loss: 8044.8564\n",
      "Epoch 18/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 2868.2688 - val_loss: 8026.4702\n",
      "Epoch 19/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 2852.6619 - val_loss: 8004.8335\n",
      "Epoch 20/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 2833.9158 - val_loss: 7978.7246\n",
      "Epoch 21/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 2810.7146 - val_loss: 7947.0708\n",
      "Epoch 22/1000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 2783.1655 - val_loss: 7907.4341\n",
      "Epoch 23/1000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 2748.9736 - val_loss: 7858.6367\n",
      "Epoch 24/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 2706.0071 - val_loss: 7796.7861\n",
      "Epoch 25/1000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 2648.8965 - val_loss: 7716.2144\n",
      "Epoch 26/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 2577.0232 - val_loss: 7609.5830\n",
      "Epoch 27/1000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 2480.8911 - val_loss: 7471.0220\n",
      "Epoch 28/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 2364.3247 - val_loss: 7297.0103\n",
      "Epoch 29/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 2208.7566 - val_loss: 7077.0464\n",
      "Epoch 30/1000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 2036.1183 - val_loss: 6837.8691\n",
      "Epoch 31/1000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 1866.2738 - val_loss: 6614.1577\n",
      "Epoch 32/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 1720.2333 - val_loss: 6413.6147\n",
      "Epoch 33/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 1607.8846 - val_loss: 6288.8906\n",
      "Epoch 34/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 1568.6643 - val_loss: 6213.8374\n",
      "Epoch 35/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 1527.1466 - val_loss: 6185.3760\n",
      "Epoch 36/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 1500.0894 - val_loss: 6151.4302\n",
      "Epoch 37/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 1444.4464 - val_loss: 6094.3315\n",
      "Epoch 38/1000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 1405.8497 - val_loss: 6044.3193\n",
      "Epoch 39/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 1391.1012 - val_loss: 6027.6675\n",
      "Epoch 40/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 1345.3181 - val_loss: 5963.1455\n",
      "Epoch 41/1000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 1306.2739 - val_loss: 5938.3027\n",
      "Epoch 42/1000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 1282.1776 - val_loss: 5900.7188\n",
      "Epoch 43/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 1254.4092 - val_loss: 5827.4727\n",
      "Epoch 44/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 1211.2938 - val_loss: 5775.3950\n",
      "Epoch 45/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 1173.6299 - val_loss: 5735.0088\n",
      "Epoch 46/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 1151.4426 - val_loss: 5695.0356\n",
      "Epoch 47/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 1105.7686 - val_loss: 5680.8394\n",
      "Epoch 48/1000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 1117.1183 - val_loss: 5620.9048\n",
      "Epoch 49/1000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 1039.5872 - val_loss: 5614.8052\n",
      "Epoch 50/1000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 1016.6445 - val_loss: 5612.6782\n",
      "Epoch 51/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 965.9054 - val_loss: 5568.4795\n",
      "Epoch 52/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 937.2679 - val_loss: 5521.0952\n",
      "Epoch 53/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 909.4072 - val_loss: 5488.2837\n",
      "Epoch 54/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 889.9010 - val_loss: 5463.4624\n",
      "Epoch 55/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 861.0898 - val_loss: 5398.5474\n",
      "Epoch 56/1000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 833.0790 - val_loss: 5407.5615\n",
      "Epoch 57/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 783.3212 - val_loss: 5400.2324\n",
      "Epoch 58/1000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 807.9651 - val_loss: 5463.3613\n",
      "Epoch 59/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 740.9355 - val_loss: 5339.5312\n",
      "Epoch 60/1000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 709.7903 - val_loss: 5310.2515\n",
      "Epoch 61/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 694.3879 - val_loss: 5264.7446\n",
      "Epoch 62/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 689.2849 - val_loss: 5268.1260\n",
      "Epoch 63/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 675.0152 - val_loss: 5217.6958\n",
      "Epoch 64/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 664.5883 - val_loss: 5236.7891\n",
      "Epoch 65/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 630.2940 - val_loss: 5274.6206\n",
      "Epoch 66/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 613.4866 - val_loss: 5255.2388\n",
      "Epoch 67/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 588.7855 - val_loss: 5173.1831\n",
      "Epoch 68/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 598.9386 - val_loss: 5232.4609\n",
      "Epoch 69/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 552.1909 - val_loss: 5173.1104\n",
      "Epoch 70/1000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 534.2944 - val_loss: 5170.6582\n",
      "Epoch 71/1000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 520.6933 - val_loss: 5160.1802\n",
      "Epoch 72/1000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 513.7271 - val_loss: 5203.7158\n",
      "Epoch 73/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 525.9949 - val_loss: 5122.4580\n",
      "Epoch 74/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 491.7039 - val_loss: 5201.6968\n",
      "Epoch 75/1000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 485.8639 - val_loss: 5144.0391\n",
      "Epoch 76/1000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 470.7430 - val_loss: 5114.6655\n",
      "Epoch 77/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 478.1724 - val_loss: 5091.6777\n",
      "Epoch 78/1000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 476.2841 - val_loss: 5135.4810\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 454.0162 - val_loss: 5113.7886\n",
      "Epoch 80/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 469.2382 - val_loss: 5071.1191\n",
      "Epoch 81/1000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 474.4254 - val_loss: 5068.4429\n",
      "Epoch 82/1000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 445.3460 - val_loss: 5113.4019\n",
      "Epoch 83/1000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 428.1314 - val_loss: 5119.1030\n",
      "Epoch 84/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 429.0365 - val_loss: 5029.0918\n",
      "Epoch 85/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 437.1215 - val_loss: 5086.4722\n",
      "Epoch 86/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 405.7032 - val_loss: 5033.1909\n",
      "Epoch 87/1000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 398.0746 - val_loss: 5075.7827\n",
      "Epoch 88/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 387.7173 - val_loss: 5102.6587\n",
      "Epoch 89/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 413.1609 - val_loss: 5063.3594\n",
      "Epoch 90/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 377.3166 - val_loss: 5017.4253\n",
      "Epoch 91/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 405.6455 - val_loss: 4991.6821\n",
      "Epoch 92/1000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 383.4699 - val_loss: 5082.5806\n",
      "Epoch 93/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 363.5800 - val_loss: 5003.3843\n",
      "Epoch 94/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 365.1834 - val_loss: 4983.3457\n",
      "Epoch 95/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 356.2272 - val_loss: 5015.1201\n",
      "Epoch 96/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 359.2492 - val_loss: 5051.9126\n",
      "Epoch 97/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 354.3049 - val_loss: 5009.0161\n",
      "Epoch 98/1000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 346.6307 - val_loss: 5023.1245\n",
      "Epoch 99/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 370.3157 - val_loss: 4990.3267\n",
      "Epoch 100/1000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 336.6915 - val_loss: 4938.2939\n",
      "Epoch 101/1000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 353.7858 - val_loss: 4965.2900\n",
      "Epoch 102/1000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 324.0026 - val_loss: 4963.4419\n",
      "Epoch 103/1000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 317.3067 - val_loss: 4964.5088\n",
      "Epoch 104/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 327.6717 - val_loss: 4898.1514\n",
      "Epoch 105/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 333.2217 - val_loss: 4942.9131\n",
      "Epoch 106/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 313.7155 - val_loss: 4924.0381\n",
      "Epoch 107/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 302.9581 - val_loss: 4948.5967\n",
      "Epoch 108/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 309.3687 - val_loss: 4924.7798\n",
      "Epoch 109/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 306.0258 - val_loss: 4973.9258\n",
      "Epoch 110/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 324.5952 - val_loss: 4956.6777\n",
      "Epoch 111/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 290.0630 - val_loss: 4911.7690\n",
      "Epoch 112/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 289.8061 - val_loss: 4909.4390\n",
      "Epoch 113/1000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 293.0347 - val_loss: 4897.1411\n",
      "Epoch 114/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 278.2768 - val_loss: 4965.6929\n",
      "Epoch 115/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 282.2934 - val_loss: 4963.4839\n",
      "Epoch 116/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 294.3647 - val_loss: 4921.2539\n",
      "Epoch 117/1000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 276.0639 - val_loss: 4886.0420\n",
      "Epoch 118/1000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 281.6144 - val_loss: 4896.4492\n",
      "Epoch 119/1000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 265.5460 - val_loss: 4935.5400\n",
      "Epoch 120/1000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 267.1302 - val_loss: 4880.8076\n",
      "Epoch 121/1000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 258.8889 - val_loss: 4844.9263\n",
      "Epoch 122/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 257.4118 - val_loss: 4951.8262\n",
      "Epoch 123/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 274.9471 - val_loss: 4958.1504\n",
      "Epoch 124/1000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 291.8233 - val_loss: 4833.2388\n",
      "Epoch 125/1000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 266.6920 - val_loss: 4867.0444\n",
      "Epoch 126/1000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 247.8555 - val_loss: 4865.2051\n",
      "Epoch 127/1000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 249.0022 - val_loss: 4974.7979\n",
      "Epoch 128/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 257.6909 - val_loss: 4956.2207\n",
      "Epoch 129/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 257.3794 - val_loss: 4831.3389\n",
      "Epoch 130/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 247.5451 - val_loss: 4885.0151\n",
      "Epoch 131/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 262.4377 - val_loss: 4976.1016\n",
      "Epoch 132/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 245.2157 - val_loss: 4896.1987\n",
      "Epoch 133/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 237.0760 - val_loss: 4847.0493\n",
      "Epoch 134/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 227.2979 - val_loss: 4975.6167\n",
      "Epoch 135/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 236.6673 - val_loss: 4888.1743\n",
      "Epoch 136/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 223.4250 - val_loss: 4838.0571\n",
      "Epoch 137/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 228.2695 - val_loss: 4865.9658\n",
      "Epoch 138/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 219.5034 - val_loss: 4916.4468\n",
      "Epoch 139/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 219.9702 - val_loss: 4864.5352\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3,\n",
       "                   estimator=<keras.wrappers.scikit_learn.KerasRegressor object at 0x00000201E46E9D00>,\n",
       "                   param_distributions={'learning_rate': [0.00037896177388938045,\n",
       "                                                          0.00023654624838037315,\n",
       "                                                          0.0003371662054603376,\n",
       "                                                          0.008393083024295716,\n",
       "                                                          0.005745644407776698,\n",
       "                                                          0.0035904250477495985,\n",
       "                                                          0.009970850890059911,\n",
       "                                                          0.009743539091207155,\n",
       "                                                          0.00862676151178373,\n",
       "                                                          0.00312444976...\n",
       "                                                          0.0002296607974108677,\n",
       "                                                          0.00020813145027850355,\n",
       "                                                          0.001332580206163112, ...],\n",
       "                                        'unit1': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10,\n",
       "                                                  11, 12, 13, 14, 15, 16, 17,\n",
       "                                                  18, 19, 20, 21, 22, 23, 24,\n",
       "                                                  25, 26, 27, 28, 29, 30, ...],\n",
       "                                        'unit2': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10,\n",
       "                                                  11, 12, 13, 14, 15, 16, 17,\n",
       "                                                  18, 19, 20, 21, 22, 23, 24,\n",
       "                                                  25, 26, 27, 28, 29, 30, ...],\n",
       "                                        'unit3': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10,\n",
       "                                                  11, 12, 13, 14, 15, 16, 17,\n",
       "                                                  18, 19, 20, 21, 22, 23, 24,\n",
       "                                                  25, 26, 27, 28, 29, 30, ...]},\n",
       "                   verbose=2)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import reciprocal\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "param_distribs = {\n",
    "    \"unit1\": np.arange(1,100) .tolist(),\n",
    "    \"unit2\": np.arange(1,200) .tolist(),\n",
    "    \"unit3\": np.arange(1,100) .tolist(),\n",
    "    \"learning_rate\": reciprocal(1e-4, 1e-2)      .rvs(1000).tolist(),\n",
    "}\n",
    "\n",
    "rnd_search_cv = RandomizedSearchCV(keras_reg, param_distribs, n_iter=10,cv=3, verbose=2)\n",
    "rnd_search_cv.fit(X_train, y_train, epochs=1000,\n",
    "                  validation_data=(X_train_full, y_train_full),\n",
    "                  callbacks=[keras.callbacks.EarlyStopping(patience=10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "60013e8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'unit3': 96,\n",
       " 'unit2': 110,\n",
       " 'unit1': 58,\n",
       " 'learning_rate': 0.0001074063096070056}"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "cfab9ece",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1259.628926595052"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2269fbf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = rnd_search_cv.best_estimator_.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "e3736d4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([2.67152643, 0.83137592, 0.67554935, 1.0168612 , 1.88896688,\n",
       "        0.93499676, 0.95517135, 0.89790305, 4.03810056, 0.73698211]),\n",
       " 'std_fit_time': array([0.24922057, 0.22285616, 0.00262379, 0.20635229, 0.27842626,\n",
       "        0.08923131, 0.15205728, 0.19930532, 0.3017871 , 0.07791618]),\n",
       " 'mean_score_time': array([0.03591792, 0.03573887, 0.03590393, 0.08131941, 0.03590337,\n",
       "        0.0375673 , 0.03690163, 0.0362556 , 0.03523986, 0.03596894]),\n",
       " 'std_score_time': array([0.00081493, 0.00019216, 0.0014104 , 0.06186961, 0.00082576,\n",
       "        0.00094044, 0.00141063, 0.00045687, 0.0012446 , 0.00072309]),\n",
       " 'param_unit3': masked_array(data=[75, 89, 49, 73, 85, 28, 82, 44, 96, 73],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_unit2': masked_array(data=[107, 64, 62, 126, 106, 145, 34, 89, 110, 18],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_unit1': masked_array(data=[76, 12, 74, 3, 88, 80, 19, 25, 58, 73],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_learning_rate': masked_array(data=[0.00018186948722105108, 0.009063759187891344,\n",
       "                    0.007315728173609639, 0.0013464320273500377,\n",
       "                    0.00032165655238266904, 0.001013795819537981,\n",
       "                    0.0017544161473511712, 0.006609624932254667,\n",
       "                    0.0001074063096070056, 0.003944783267943095],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'unit3': 75,\n",
       "   'unit2': 107,\n",
       "   'unit1': 76,\n",
       "   'learning_rate': 0.00018186948722105108},\n",
       "  {'unit3': 89,\n",
       "   'unit2': 64,\n",
       "   'unit1': 12,\n",
       "   'learning_rate': 0.009063759187891344},\n",
       "  {'unit3': 49,\n",
       "   'unit2': 62,\n",
       "   'unit1': 74,\n",
       "   'learning_rate': 0.007315728173609639},\n",
       "  {'unit3': 73,\n",
       "   'unit2': 126,\n",
       "   'unit1': 3,\n",
       "   'learning_rate': 0.0013464320273500377},\n",
       "  {'unit3': 85,\n",
       "   'unit2': 106,\n",
       "   'unit1': 88,\n",
       "   'learning_rate': 0.00032165655238266904},\n",
       "  {'unit3': 28,\n",
       "   'unit2': 145,\n",
       "   'unit1': 80,\n",
       "   'learning_rate': 0.001013795819537981},\n",
       "  {'unit3': 82,\n",
       "   'unit2': 34,\n",
       "   'unit1': 19,\n",
       "   'learning_rate': 0.0017544161473511712},\n",
       "  {'unit3': 44,\n",
       "   'unit2': 89,\n",
       "   'unit1': 25,\n",
       "   'learning_rate': 0.006609624932254667},\n",
       "  {'unit3': 96,\n",
       "   'unit2': 110,\n",
       "   'unit1': 58,\n",
       "   'learning_rate': 0.0001074063096070056},\n",
       "  {'unit3': 73,\n",
       "   'unit2': 18,\n",
       "   'unit1': 73,\n",
       "   'learning_rate': 0.003944783267943095}],\n",
       " 'split0_test_score': array([-2320.58154297,            nan,            nan, -2973.24536133,\n",
       "        -2090.52758789, -3566.91333008, -3030.99804688,            nan,\n",
       "        -1811.23266602, -3491.87451172]),\n",
       " 'split1_test_score': array([-8.26190308e+02, -1.66060913e+03,             nan, -1.85302490e+03,\n",
       "        -9.01146362e+02, -1.91177380e+03, -1.58749255e+03, -5.60538132e+10,\n",
       "        -6.92278015e+02,             nan]),\n",
       " 'split2_test_score': array([-1310.60583496,            nan,            nan, -2442.48266602,\n",
       "        -1353.78100586, -2989.61914062, -2684.72265625, -2572.6496582 ,\n",
       "        -1275.37609863,            nan]),\n",
       " 'mean_test_score': array([-1485.79256185,            nan,            nan, -2422.91764323,\n",
       "        -1448.48498535, -2822.76875814, -2434.40441895,            nan,\n",
       "        -1259.6289266 ,            nan]),\n",
       " 'std_test_score': array([622.53197135,          nan,          nan, 457.53729303,\n",
       "        490.15885707, 685.93051181, 615.31641841,          nan,\n",
       "        456.94701206,          nan]),\n",
       " 'rank_test_score': array([ 3,  7,  8,  4,  2,  6,  5,  9,  1, 10])}"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "86201809",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in rnd_search_cv.cv_results_[\"param_learning_rate\"]:\n",
    "    plt.plot(rnd_search_cv.cv_results_[\"\"],rnd_search_cv.cv_results_[\"std_test_score\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "84c130a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "deep_predict = model.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "709e1ea2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7341936435864161"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "r2_score(y_valid,deep_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "f27847cb",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_valid_backup' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-106-bb35330fc7d7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX_valid_backup\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'X_valid_backup' is not defined"
     ]
    }
   ],
   "source": [
    "X_valid_backup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "18499e7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200     36\n",
       "142     15\n",
       "151      0\n",
       "114     72\n",
       "81       1\n",
       "43       0\n",
       "58     102\n",
       "175      1\n",
       "71      19\n",
       "166     20\n",
       "130      1\n",
       "13       1\n",
       "87       0\n",
       "208     38\n",
       "117      3\n",
       "122     71\n",
       "99       4\n",
       "50      20\n",
       "26      22\n",
       "11      47\n",
       "74     229\n",
       "141     90\n",
       "204      2\n",
       "77       2\n",
       "149     21\n",
       "192      1\n",
       "63       1\n",
       "12       4\n",
       "65       4\n",
       "51       4\n",
       "133      1\n",
       "2      100\n",
       "91       1\n",
       "191     38\n",
       "1       74\n",
       "112      9\n",
       "24       1\n",
       "46     948\n",
       "3        8\n",
       "179      0\n",
       "59      34\n",
       "164     32\n",
       "203     11\n",
       "Name: LUT, dtype: int64"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "410da835",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "127      1\n",
       "108     68\n",
       "69      14\n",
       "84       0\n",
       "97     123\n",
       "      ... \n",
       "106      0\n",
       "14     170\n",
       "92       1\n",
       "179      0\n",
       "102     44\n",
       "Name: LUT, Length: 169, dtype: int64"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6d695f1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 4ms/step - loss: 58.6963\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 29.1148\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 271.5947\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 397.6594\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 36.1284\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 19.6233\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 14.7397\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 12.1934\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 10.4712\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 9.0539\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 7.9604\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 7.0873\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 20.4979\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 18.3104\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 18.3919\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 20.9277\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 19.1724\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 19.1145\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 18.8052\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 17.8670\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 16.7895\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 17.6328\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 16.6086\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 22.4309\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 22.2753\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 21.2144\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 20.3069\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 19.7270\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 18.9854\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 22.5943\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 21.5300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.9708\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 22.6867\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 22.0928\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 21.4186\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 38.0179\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 37.1373\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 34.9858\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 33.2669\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 32.8241\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 31.3185\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 30.6014\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 30.5888\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 29.7860\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 29.0780\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 28.2926\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 29.5157\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 106.5273\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 110.8818\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 107.3441\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 105.1381\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 103.1913\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 101.1600\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 98.4603\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 96.8294\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 104.2235\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 102.0139\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 100.5642\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 109.9649\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 102.0766\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 98.7947\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 95.8264\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 94.8017\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 93.2702\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 90.8342\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 92.2116\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 90.9573\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 89.2453\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 88.1510\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 87.5336\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 85.0416\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 92.3764\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 91.3128\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 90.6328\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 89.2769\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 88.7812\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 87.1048\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 85.9496\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 86.0573\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 120.6456\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 117.8666\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 115.2217\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 113.4651\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 111.0241\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 109.3355\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 107.8142\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 106.4108\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 105.1943\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 103.3590\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 101.3632\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 100.7895\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 98.8514\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 99.6797\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 96.4760\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 95.2219\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 94.7791\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 93.3703\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 92.4026\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 93.3560\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 91.4674\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 90.0777\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 89.1898\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 87.4441\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 86.6578\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 85.7461\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 84.5649\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 101.3778\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 98.0089\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 96.8706\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 97.3413\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 94.9401\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 95.6776\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 94.2005\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 92.6235\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 92.6490\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 103.2650\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 100.8611\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 103.5039\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 102.8245\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 102.2060\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 101.1206\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 100.4673\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 101.2691\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 101.6557\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 99.4374\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 99.6614\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 123.6458\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 121.3547\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 121.8686\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 119.8205\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 120.7087\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 120.6280\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 120.4231\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 120.0824\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 119.4804\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_learning_curves(model, X_train_full, y_train_full)\n",
    "#plt.axis([0, 200, 0, 200])                         # not shown in the book\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "80d0ad85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 31.302113 ],\n",
       "       [ 13.202502 ],\n",
       "       [  1.4642506],\n",
       "       [ 17.41863  ],\n",
       "       [  1.4345452],\n",
       "       [ 15.217053 ],\n",
       "       [105.78109  ],\n",
       "       [  6.984596 ],\n",
       "       [ 22.208517 ],\n",
       "       [ 24.478987 ],\n",
       "       [ 10.146852 ],\n",
       "       [  2.697756 ],\n",
       "       [ 26.683569 ],\n",
       "       [ 40.61043  ],\n",
       "       [  2.24936  ],\n",
       "       [ 10.2791815],\n",
       "       [  3.617224 ],\n",
       "       [  7.230478 ],\n",
       "       [ 26.78847  ],\n",
       "       [ 40.987774 ],\n",
       "       [233.39195  ],\n",
       "       [ 73.843506 ],\n",
       "       [ 25.366823 ],\n",
       "       [  1.3949833],\n",
       "       [ 13.382822 ],\n",
       "       [  2.8901322],\n",
       "       [  1.9197996],\n",
       "       [  2.89565  ],\n",
       "       [ 24.560827 ],\n",
       "       [  5.523542 ],\n",
       "       [  5.0518036],\n",
       "       [ 95.76241  ],\n",
       "       [  2.3377774],\n",
       "       [ 38.192425 ],\n",
       "       [ 60.7633   ],\n",
       "       [  5.6340957],\n",
       "       [  2.9980829],\n",
       "       [950.7049   ],\n",
       "       [  9.212509 ],\n",
       "       [  2.8258276],\n",
       "       [ 33.661537 ],\n",
       "       [ 32.743523 ],\n",
       "       [ 18.795252 ]], dtype=float32)"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict = model.predict(X_valid)\n",
    "predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "f1500aa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200     36\n",
       "142     15\n",
       "151      0\n",
       "114     72\n",
       "81       1\n",
       "43       0\n",
       "58     102\n",
       "175      1\n",
       "71      19\n",
       "166     20\n",
       "130      1\n",
       "13       1\n",
       "87       0\n",
       "208     38\n",
       "117      3\n",
       "122     71\n",
       "99       4\n",
       "50      20\n",
       "26      22\n",
       "11      47\n",
       "74     229\n",
       "141     90\n",
       "204      2\n",
       "77       2\n",
       "149     21\n",
       "192      1\n",
       "63       1\n",
       "12       4\n",
       "65       4\n",
       "51       4\n",
       "133      1\n",
       "2      100\n",
       "91       1\n",
       "191     38\n",
       "1       74\n",
       "112      9\n",
       "24       1\n",
       "46     948\n",
       "3        8\n",
       "179      0\n",
       "59      34\n",
       "164     32\n",
       "203     11\n",
       "Name: LUT, dtype: int64"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "4d9a0ba2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(1)\n",
    "plt.clf()\n",
    "ax=plt.axes(aspect='equal')\n",
    "plt.scatter(y_valid,predict)\n",
    "plt.xlabel('True Values')\n",
    "plt.ylabel('ANN_LUT_Predictions')\n",
    "Lims=[0,150]\n",
    "plt.xlim(Lims)\n",
    "plt.ylim(Lims)\n",
    "plt.plot(Lims,Lims)\n",
    "plt.grid(False)\n",
    "    \n",
    "plt.figure(2)\n",
    "plt.clf()\n",
    "plt.hist(predict,bins=30)\n",
    "plt.xlabel('LUT_ANN_Prediction')\n",
    "plt.ylabel('Count')\n",
    "plt.grid(False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33806898",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
