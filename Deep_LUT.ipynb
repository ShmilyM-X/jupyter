{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be7433a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tarfile\n",
    "import urllib.request\n",
    "\n",
    "RES_PATH = os.path.join(\"res_datasets\",\"resourceing\")\n",
    "\n",
    "def fetch_resource_data(res_path=RES_PATH):\n",
    "    if not os.path.isdir(res_path):\n",
    "        os.makedirs(res_path)\n",
    "##创建文件夹路径函数\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_learning_curves(model, X, y):\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=10)\n",
    "    train_errors, val_errors = [], []\n",
    "    for m in range(1, len(X_train) + 1):\n",
    "        model.fit(X_train[:m], y_train[:m])\n",
    "        y_train_predict = model.predict(X_train[:m])\n",
    "        y_val_predict = model.predict(X_val)\n",
    "        train_errors.append(mean_squared_error(y_train[:m], y_train_predict))\n",
    "        val_errors.append(mean_squared_error(y_val, y_val_predict))\n",
    "\n",
    "    plt.plot(np.sqrt(train_errors), \"r-+\", linewidth=2, label=\"train\")\n",
    "    plt.plot(np.sqrt(val_errors), \"b-\", linewidth=3, label=\"val\")\n",
    "    plt.legend(loc=\"upper right\", fontsize=14)   # not shown in the book\n",
    "    plt.xlabel(\"Training set size\", fontsize=14) # not shown\n",
    "    plt.ylabel(\"RMSE\", fontsize=14)              # not shown\n",
    "    \n",
    "fetch_resource_data() ##调用创建\n",
    "\n",
    "##读取CSV文件\n",
    "import pandas as pd\n",
    "\n",
    "def load_res_data(res_path = RES_PATH,file_name=\"new_feature_1214.csv\"):\n",
    "    csv_path = os.path.join(RES_PATH,file_name)\n",
    "    return pd.read_csv(csv_path) \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0bfef604",
   "metadata": {},
   "outputs": [],
   "source": [
    "##数据处理\n",
    "resource_origin_data = load_res_data()  #get origin csv data\n",
    "\n",
    "#%matplotlib inline\n",
    "#import matplotlib.pyplot as plt\n",
    "#resource_origin_data.hist(bins=50, figsize=(20,15))\n",
    "#plt.show() #data plot show\n",
    "\n",
    "resource_origin_data_lut = resource_origin_data.dropna(subset = [\"FF\"])\n",
    "resource_origin_data_lut=resource_origin_data_lut.drop(\"LUT\",axis=1)\n",
    "resource_origin_data_lut=resource_origin_data_lut.drop(\"BUFG\",axis=1)\n",
    "resource_origin_data_lut=resource_origin_data_lut.drop(\"IO\",axis=1)\n",
    "resource_origin_data_lut=resource_origin_data_lut.drop(\"ModuleName\",axis=1)\n",
    "resource_origin_data_lut=resource_origin_data_lut.drop(\"PARAMETERVALUE\",axis=1)\n",
    "resource_origin_data_lut=resource_origin_data_lut.drop(\"ModuleInsts\",axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25d04eab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 212 entries, 0 to 229\n",
      "Data columns (total 60 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   ARITLSHIFT                 212 non-null    int64  \n",
      " 1   ARITLSHIFT_PORT_NUM        212 non-null    int64  \n",
      " 2   ARITLSHIFT_PORT_WIDTH      212 non-null    int64  \n",
      " 3   ARITLSHIFT_VALUE           212 non-null    int64  \n",
      " 4   ARITRSHIFT                 212 non-null    int64  \n",
      " 5   ARITRSHIFT_PORT_NUM        212 non-null    int64  \n",
      " 6   ARITRSHIFT_PORT_WIDTH      212 non-null    int64  \n",
      " 7   ARITRSHIFT_VALUE           212 non-null    int64  \n",
      " 8   AlwaysConstructs           212 non-null    int64  \n",
      " 9   AssignLHSPortNum           212 non-null    int64  \n",
      " 10  AssignLHSWidth             212 non-null    int64  \n",
      " 11  AssignRHSPortNum           212 non-null    int64  \n",
      " 12  AssignRHSWidth             212 non-null    int64  \n",
      " 13  AssignStmts                212 non-null    int64  \n",
      " 14  BLOCKINGASSIGN             212 non-null    int64  \n",
      " 15  BlockAssign_Left_PortNum   212 non-null    int64  \n",
      " 16  BlockAssign_Left_Width     212 non-null    int64  \n",
      " 17  BlockAssign_Right_PortNum  212 non-null    int64  \n",
      " 18  BlockAssign_Right_Width    212 non-null    int64  \n",
      " 19  CASECONDITIONNUM           212 non-null    int64  \n",
      " 20  CASECONDITIONWIDTH         212 non-null    int64  \n",
      " 21  CASEITEMCONDITIONNUM       212 non-null    int64  \n",
      " 22  CASEITEMCONDITIOWIDTH      212 non-null    int64  \n",
      " 23  CASEITEMNUM                212 non-null    int64  \n",
      " 24  CONDITIONALELSE            212 non-null    int64  \n",
      " 25  CONDITIONALIF              212 non-null    int64  \n",
      " 26  CONDITIONALIFWIDTH         212 non-null    int64  \n",
      " 27  CONDITIONALTHEN            212 non-null    int64  \n",
      " 28  FORBLOCK                   212 non-null    int64  \n",
      " 29  FORTIMES                   212 non-null    int64  \n",
      " 30  FUNCTIONCALL               212 non-null    int64  \n",
      " 31  FUNCTIONNUM                212 non-null    int64  \n",
      " 32  INDEXMEMRORY               212 non-null    int64  \n",
      " 33  INOUT                      212 non-null    int64  \n",
      " 34  INOUTWIDTH                 212 non-null    int64  \n",
      " 35  INPUT                      212 non-null    int64  \n",
      " 36  INPUTWIDTH                 212 non-null    int64  \n",
      " 37  MIN                        212 non-null    int64  \n",
      " 38  NonBlockLeftWidth          212 non-null    int64  \n",
      " 39  NonBlockRightWidth         212 non-null    int64  \n",
      " 40  NonBlockingAssign          212 non-null    int64  \n",
      " 41  NonBlockingLeftPortNum     212 non-null    int64  \n",
      " 42  NonBlockingRightPortNum    212 non-null    int64  \n",
      " 43  OUTPUT                     212 non-null    int64  \n",
      " 44  OUTPUTWIDTH                212 non-null    int64  \n",
      " 45  PARAMETERNUM               212 non-null    int64  \n",
      " 46  PLUS                       212 non-null    int64  \n",
      " 47  QUESTIONCOLON              212 non-null    int64  \n",
      " 48  QUESTIONCOLONELSE          212 non-null    int64  \n",
      " 49  QUESTIONCOLONIF            212 non-null    int64  \n",
      " 50  QUESTIONCOLONTHEN          212 non-null    int64  \n",
      " 51  REDAND                     212 non-null    int64  \n",
      " 52  REDAOR                     212 non-null    int64  \n",
      " 53  REDXOR                     212 non-null    int64  \n",
      " 54  REG                        212 non-null    int64  \n",
      " 55  REGWIDTH                   212 non-null    int64  \n",
      " 56  UnaryOperator              212 non-null    int64  \n",
      " 57  WIRENUM                    212 non-null    int64  \n",
      " 58  WIREWIDTH                  212 non-null    int64  \n",
      " 59  FF                         212 non-null    float64\n",
      "dtypes: float64(1), int64(59)\n",
      "memory usage: 101.0 KB\n"
     ]
    }
   ],
   "source": [
    "#数据信息\n",
    "resource_origin_data_lut.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "81c08573",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ARITLSHIFT</th>\n",
       "      <th>ARITLSHIFT_PORT_NUM</th>\n",
       "      <th>ARITLSHIFT_PORT_WIDTH</th>\n",
       "      <th>ARITLSHIFT_VALUE</th>\n",
       "      <th>ARITRSHIFT</th>\n",
       "      <th>ARITRSHIFT_PORT_NUM</th>\n",
       "      <th>ARITRSHIFT_PORT_WIDTH</th>\n",
       "      <th>ARITRSHIFT_VALUE</th>\n",
       "      <th>AlwaysConstructs</th>\n",
       "      <th>AssignLHSPortNum</th>\n",
       "      <th>...</th>\n",
       "      <th>QUESTIONCOLONTHEN</th>\n",
       "      <th>REDAND</th>\n",
       "      <th>REDAOR</th>\n",
       "      <th>REDXOR</th>\n",
       "      <th>REG</th>\n",
       "      <th>REGWIDTH</th>\n",
       "      <th>UnaryOperator</th>\n",
       "      <th>WIRENUM</th>\n",
       "      <th>WIREWIDTH</th>\n",
       "      <th>FF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>212.0</td>\n",
       "      <td>212.0</td>\n",
       "      <td>212.0</td>\n",
       "      <td>212.0</td>\n",
       "      <td>212.000000</td>\n",
       "      <td>212.000000</td>\n",
       "      <td>212.000000</td>\n",
       "      <td>212.000000</td>\n",
       "      <td>212.000000</td>\n",
       "      <td>212.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>212.000000</td>\n",
       "      <td>212.000000</td>\n",
       "      <td>212.000000</td>\n",
       "      <td>212.000000</td>\n",
       "      <td>212.000000</td>\n",
       "      <td>212.000000</td>\n",
       "      <td>212.000000</td>\n",
       "      <td>212.000000</td>\n",
       "      <td>212.000000</td>\n",
       "      <td>212.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.113208</td>\n",
       "      <td>0.070755</td>\n",
       "      <td>0.674528</td>\n",
       "      <td>0.386792</td>\n",
       "      <td>2.287736</td>\n",
       "      <td>2.924528</td>\n",
       "      <td>...</td>\n",
       "      <td>0.523585</td>\n",
       "      <td>3.886792</td>\n",
       "      <td>0.495283</td>\n",
       "      <td>0.561321</td>\n",
       "      <td>3.783019</td>\n",
       "      <td>124.339623</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>2.844340</td>\n",
       "      <td>13.976415</td>\n",
       "      <td>22.627358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.758156</td>\n",
       "      <td>0.524014</td>\n",
       "      <td>4.576129</td>\n",
       "      <td>2.801728</td>\n",
       "      <td>3.237406</td>\n",
       "      <td>10.205192</td>\n",
       "      <td>...</td>\n",
       "      <td>2.526525</td>\n",
       "      <td>8.233927</td>\n",
       "      <td>4.434353</td>\n",
       "      <td>4.076405</td>\n",
       "      <td>5.397041</td>\n",
       "      <td>705.919378</td>\n",
       "      <td>2.236863</td>\n",
       "      <td>8.446055</td>\n",
       "      <td>52.403144</td>\n",
       "      <td>59.159899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.750000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>26.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>127.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>8202.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>575.000000</td>\n",
       "      <td>768.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ARITLSHIFT  ARITLSHIFT_PORT_NUM  ARITLSHIFT_PORT_WIDTH  \\\n",
       "count       212.0                212.0                  212.0   \n",
       "mean          0.0                  0.0                    0.0   \n",
       "std           0.0                  0.0                    0.0   \n",
       "min           0.0                  0.0                    0.0   \n",
       "25%           0.0                  0.0                    0.0   \n",
       "50%           0.0                  0.0                    0.0   \n",
       "75%           0.0                  0.0                    0.0   \n",
       "max           0.0                  0.0                    0.0   \n",
       "\n",
       "       ARITLSHIFT_VALUE  ARITRSHIFT  ARITRSHIFT_PORT_NUM  \\\n",
       "count             212.0  212.000000           212.000000   \n",
       "mean                0.0    0.113208             0.070755   \n",
       "std                 0.0    0.758156             0.524014   \n",
       "min                 0.0    0.000000             0.000000   \n",
       "25%                 0.0    0.000000             0.000000   \n",
       "50%                 0.0    0.000000             0.000000   \n",
       "75%                 0.0    0.000000             0.000000   \n",
       "max                 0.0    8.000000             7.000000   \n",
       "\n",
       "       ARITRSHIFT_PORT_WIDTH  ARITRSHIFT_VALUE  AlwaysConstructs  \\\n",
       "count             212.000000        212.000000        212.000000   \n",
       "mean                0.674528          0.386792          2.287736   \n",
       "std                 4.576129          2.801728          3.237406   \n",
       "min                 0.000000          0.000000          0.000000   \n",
       "25%                 0.000000          0.000000          1.000000   \n",
       "50%                 0.000000          0.000000          1.000000   \n",
       "75%                 0.000000          0.000000          2.000000   \n",
       "max                56.000000         28.000000         24.000000   \n",
       "\n",
       "       AssignLHSPortNum  ...  QUESTIONCOLONTHEN      REDAND      REDAOR  \\\n",
       "count        212.000000  ...         212.000000  212.000000  212.000000   \n",
       "mean           2.924528  ...           0.523585    3.886792    0.495283   \n",
       "std           10.205192  ...           2.526525    8.233927    4.434353   \n",
       "min            0.000000  ...           0.000000    0.000000    0.000000   \n",
       "25%            0.000000  ...           0.000000    0.000000    0.000000   \n",
       "50%            1.000000  ...           0.000000    0.500000    0.000000   \n",
       "75%            2.000000  ...           0.000000    4.000000    0.000000   \n",
       "max          127.000000  ...          31.000000   55.000000   62.000000   \n",
       "\n",
       "           REDXOR         REG     REGWIDTH  UnaryOperator     WIRENUM  \\\n",
       "count  212.000000  212.000000   212.000000     212.000000  212.000000   \n",
       "mean     0.561321    3.783019   124.339623       0.250000    2.844340   \n",
       "std      4.076405    5.397041   705.919378       2.236863    8.446055   \n",
       "min      0.000000    0.000000     0.000000       0.000000    0.000000   \n",
       "25%      0.000000    1.000000     1.750000       0.000000    0.000000   \n",
       "50%      0.000000    2.000000     8.000000       0.000000    0.000000   \n",
       "75%      0.000000    4.000000    31.000000       0.000000    1.250000   \n",
       "max     56.000000   32.000000  8202.000000      32.000000   65.000000   \n",
       "\n",
       "        WIREWIDTH          FF  \n",
       "count  212.000000  212.000000  \n",
       "mean    13.976415   22.627358  \n",
       "std     52.403144   59.159899  \n",
       "min      0.000000    0.000000  \n",
       "25%      0.000000    0.000000  \n",
       "50%      0.000000    4.500000  \n",
       "75%      2.000000   26.000000  \n",
       "max    575.000000  768.000000  \n",
       "\n",
       "[8 rows x 60 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resource_origin_data_lut.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f73c8ca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'LUT'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3079\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3080\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3081\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'LUT'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-47747378101b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#相关性分析\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mcorr_matrix\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mresource_origin_data_lut\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcorr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mcorr_matrix\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"LUT\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mascending\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3022\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3023\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3024\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3025\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3026\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3080\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3081\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3082\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3083\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3084\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'LUT'"
     ]
    }
   ],
   "source": [
    "#相关性分析\n",
    "corr_matrix=resource_origin_data_lut.corr()\n",
    "corr_matrix[\"LUT\"].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2fd8d5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#特征优化\n",
    "resource_lut = resource_origin_data_lut[\"FF\"].copy() #label data\n",
    "resource_lut_data = resource_origin_data_lut.drop(\"FF\",axis=1) #feature data\n",
    "resource_label = list(resource_lut_data) #labal list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f8e7acfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#数据分割\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "#训练集、测试集、验证集\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(resource_lut_data, resource_lut, test_size=0.2,random_state=42)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b944044c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid_backup = X_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7eecddc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#数据标准化\n",
    "scaler = StandardScaler() \n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_valid = scaler.transform(X_valid)\n",
    "X_test = scaler.transform(X_test)\n",
    "X_train_full = scaler.transform(X_train_full)\n",
    "X_data_full = scaler.transform(resource_lut_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cf04fcac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#深度学习\n",
    "\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ebc9345f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(126, 59)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aba9a350",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "#input_ = keras.layers.Input(shape=X_train.shape[1:])\n",
    "#hidden1 = keras.layers.Dense(59, activation=\"relu\")(input_)\n",
    "#hidden2 = keras.layers.Dense(150, activation=\"relu\")(hidden1)\n",
    "#concat = keras.layers.concatenate([input_, hidden2])\n",
    "#output = keras.layers.Dense(1)(concat)\n",
    "#model = keras.models.Model(inputs=[input_], outputs=[output])\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(monitor='val_loss',patience=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "65cc32a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Input(shape=X_train.shape[1:]),\n",
    "    keras.layers.Dense(59, activation=\"relu\"),\n",
    "    #keras.layers.Dense(300, activation=\"relu\"),\n",
    "    keras.layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "eae277e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 48.1367 - val_loss: 633.6571\n",
      "Epoch 2/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 47.2324 - val_loss: 624.5901\n",
      "Epoch 3/1000\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 47.2766 - val_loss: 638.8510\n",
      "Epoch 4/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 47.2201 - val_loss: 624.0401\n",
      "Epoch 5/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 47.3379 - val_loss: 614.9003\n",
      "Epoch 6/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 46.8905 - val_loss: 638.0994\n",
      "Epoch 7/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 46.1754 - val_loss: 623.1658\n",
      "Epoch 8/1000\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 46.6706 - val_loss: 627.9679\n",
      "Epoch 9/1000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 46.2074 - val_loss: 619.4099\n",
      "Epoch 10/1000\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 46.8517 - val_loss: 625.2592\n",
      "Epoch 11/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 46.0938 - val_loss: 627.5946\n",
      "Epoch 12/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 45.2342 - val_loss: 622.1550\n",
      "Epoch 13/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 45.3386 - val_loss: 625.3115\n",
      "Epoch 14/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 44.5927 - val_loss: 637.7014\n",
      "Epoch 15/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 45.2194 - val_loss: 644.2430\n",
      "Epoch 16/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 45.2588 - val_loss: 625.3273\n",
      "Epoch 17/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 43.6228 - val_loss: 639.7054\n",
      "Epoch 18/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 44.8124 - val_loss: 634.3125\n",
      "Epoch 19/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 44.5705 - val_loss: 637.9084\n",
      "Epoch 20/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 43.3906 - val_loss: 632.6949\n",
      "Epoch 21/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 43.4993 - val_loss: 640.0870\n",
      "Epoch 22/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 43.5143 - val_loss: 643.5823\n",
      "Epoch 23/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 42.4074 - val_loss: 628.8145\n",
      "Epoch 24/1000\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 42.8649 - val_loss: 635.1385\n",
      "Epoch 25/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 43.2920 - val_loss: 617.2664\n",
      "Epoch 26/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 42.8685 - val_loss: 633.3325\n",
      "Epoch 27/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 41.8835 - val_loss: 632.5830\n",
      "Epoch 28/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 41.7769 - val_loss: 636.5908\n",
      "Epoch 29/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 41.9768 - val_loss: 632.5889\n",
      "Epoch 30/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 42.2527 - val_loss: 623.8547\n",
      "Epoch 31/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 41.2765 - val_loss: 632.0363\n",
      "Epoch 32/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 41.6121 - val_loss: 632.6956\n",
      "Epoch 33/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 41.5762 - val_loss: 622.7786\n",
      "Epoch 34/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 41.6622 - val_loss: 641.1851\n",
      "Epoch 35/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 40.6299 - val_loss: 617.1022\n",
      "Epoch 36/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 40.7224 - val_loss: 630.6049\n",
      "Epoch 37/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 40.2047 - val_loss: 638.6008\n",
      "Epoch 38/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 40.9260 - val_loss: 636.7764\n",
      "Epoch 39/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 39.8183 - val_loss: 640.1406\n",
      "Epoch 40/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 39.9860 - val_loss: 635.8111\n",
      "Epoch 41/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 39.5869 - val_loss: 633.4503\n",
      "Epoch 42/1000\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 39.0581 - val_loss: 633.9615\n",
      "Epoch 43/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 39.4547 - val_loss: 625.6234\n",
      "Epoch 44/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 39.0529 - val_loss: 636.1887\n",
      "Epoch 45/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 39.0790 - val_loss: 632.7253\n",
      "Epoch 46/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 38.9367 - val_loss: 624.5046\n",
      "Epoch 47/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 39.1077 - val_loss: 627.9383\n",
      "Epoch 48/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 38.1822 - val_loss: 637.8482\n",
      "Epoch 49/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 38.2756 - val_loss: 628.1006\n",
      "Epoch 50/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 38.3434 - val_loss: 622.4128\n",
      "Epoch 51/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 38.2965 - val_loss: 632.7537\n",
      "Epoch 52/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 37.8021 - val_loss: 628.2891\n",
      "Epoch 53/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 37.6174 - val_loss: 632.1835\n",
      "Epoch 54/1000\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 37.7904 - val_loss: 629.4972\n",
      "Epoch 55/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 37.7112 - val_loss: 637.2831\n",
      "Epoch 56/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 37.0159 - val_loss: 617.3704\n",
      "Epoch 57/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 37.5306 - val_loss: 639.4633\n",
      "Epoch 58/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 37.3361 - val_loss: 627.0210\n",
      "Epoch 59/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 36.9710 - val_loss: 631.2430\n",
      "Epoch 60/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 32.93 - 0s 7ms/step - loss: 36.8709 - val_loss: 624.8752\n",
      "Epoch 61/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 36.5119 - val_loss: 629.6833\n",
      "Epoch 62/1000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 36.5144 - val_loss: 624.5953\n",
      "Epoch 63/1000\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 36.1533 - val_loss: 632.2852\n",
      "Epoch 64/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 36.0133 - val_loss: 630.8925\n",
      "Epoch 65/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 36.0389 - val_loss: 631.7592\n",
      "Epoch 66/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 35.5561 - val_loss: 633.4652\n",
      "Epoch 67/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 35.8364 - val_loss: 620.1903\n",
      "Epoch 68/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 35.5326 - val_loss: 628.2490\n",
      "Epoch 69/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 35.1594 - val_loss: 624.3764\n",
      "Epoch 70/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 35.1794 - val_loss: 625.9440\n",
      "Epoch 71/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 35.3843 - val_loss: 626.6120\n",
      "Epoch 72/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 35.0617 - val_loss: 626.6426\n",
      "Epoch 73/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 34.8174 - val_loss: 620.9042\n",
      "Epoch 74/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 34.6308 - val_loss: 639.4637\n",
      "Epoch 75/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 35.1929 - val_loss: 635.8218\n",
      "Epoch 76/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 34.0985 - val_loss: 630.2188\n",
      "Epoch 77/1000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 33.8874 - val_loss: 630.6351\n",
      "Epoch 78/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 34.3431 - val_loss: 636.5109\n",
      "Epoch 79/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 33.9085 - val_loss: 628.9699\n",
      "Epoch 80/1000\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 33.8560 - val_loss: 633.2913\n",
      "Epoch 81/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 7ms/step - loss: 33.7392 - val_loss: 628.5367\n",
      "Epoch 82/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 33.9853 - val_loss: 631.3134\n",
      "Epoch 83/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 33.5712 - val_loss: 630.1542\n",
      "Epoch 84/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 33.5892 - val_loss: 632.5884\n",
      "Epoch 85/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 33.3364 - val_loss: 624.5475\n",
      "Epoch 86/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 33.7592 - val_loss: 628.6578\n",
      "Epoch 87/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 32.7536 - val_loss: 631.8531\n",
      "Epoch 88/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 44.32 - 0s 6ms/step - loss: 33.0308 - val_loss: 634.6805\n",
      "Epoch 89/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 32.4477 - val_loss: 625.1241\n",
      "Epoch 90/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 32.4282 - val_loss: 627.7293\n",
      "Epoch 91/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 32.4201 - val_loss: 629.5338\n",
      "Epoch 92/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 32.1485 - val_loss: 624.9182\n",
      "Epoch 93/1000\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 32.2117 - val_loss: 625.5051\n",
      "Epoch 94/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 31.9864 - val_loss: 625.5397\n",
      "Epoch 95/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 31.5360 - val_loss: 629.3445\n",
      "Epoch 96/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 31.9097 - val_loss: 624.1833\n",
      "Epoch 97/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 31.9680 - val_loss: 627.8600\n",
      "Epoch 98/1000\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 31.2464 - val_loss: 619.0294\n",
      "Epoch 99/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 31.2474 - val_loss: 634.4617\n",
      "Epoch 100/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 31.1359 - val_loss: 623.2180\n",
      "Epoch 101/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 30.9055 - val_loss: 629.2126\n",
      "Epoch 102/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 30.8744 - val_loss: 622.3430\n",
      "Epoch 103/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 30.7993 - val_loss: 628.1261\n",
      "Epoch 104/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 30.6739 - val_loss: 634.3964\n",
      "Epoch 105/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 30.6143 - val_loss: 629.2900\n",
      "Epoch 106/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 30.5229 - val_loss: 616.0901\n",
      "Epoch 107/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 30.4573 - val_loss: 625.6830\n",
      "Epoch 108/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 30.0505 - val_loss: 616.2311\n",
      "Epoch 109/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 30.4396 - val_loss: 622.7983\n",
      "Epoch 110/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 29.9614 - val_loss: 637.6812\n",
      "Epoch 111/1000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 30.0060 - val_loss: 618.3278\n",
      "Epoch 112/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 29.5724 - val_loss: 628.9412\n",
      "Epoch 113/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 29.8651 - val_loss: 619.6711\n",
      "Epoch 114/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 29.5317 - val_loss: 621.1127\n",
      "Epoch 115/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 29.7489 - val_loss: 621.8822\n",
      "Epoch 116/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 24.76 - 0s 6ms/step - loss: 28.9978 - val_loss: 619.3270\n",
      "Epoch 117/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 29.1401 - val_loss: 616.5502\n",
      "Epoch 118/1000\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 29.3448 - val_loss: 621.1285\n",
      "Epoch 119/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 28.7449 - val_loss: 625.2590\n",
      "Epoch 120/1000\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 28.7800 - val_loss: 615.2157\n",
      "Epoch 121/1000\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 28.8420 - val_loss: 618.7094\n",
      "Epoch 122/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 28.5997 - val_loss: 620.9670\n",
      "Epoch 123/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 28.5298 - val_loss: 615.3726\n",
      "Epoch 124/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 28.2396 - val_loss: 621.0173\n",
      "Epoch 125/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 28.5524 - val_loss: 619.8545\n",
      "Epoch 126/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 28.0935 - val_loss: 628.8588\n",
      "Epoch 127/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 28.0902 - val_loss: 622.7482\n",
      "Epoch 128/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 36.46 - 0s 6ms/step - loss: 28.1224 - val_loss: 624.0430\n",
      "Epoch 129/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 27.7604 - val_loss: 617.2552\n",
      "Epoch 130/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 19.69 - 0s 7ms/step - loss: 27.8825 - val_loss: 619.1777\n",
      "Epoch 131/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 27.6356 - val_loss: 626.3938\n",
      "Epoch 132/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 31.74 - 0s 7ms/step - loss: 27.6033 - val_loss: 618.4345\n",
      "Epoch 133/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 27.2891 - val_loss: 623.0508\n",
      "Epoch 134/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 27.5705 - val_loss: 611.5942\n",
      "Epoch 135/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 27.2595 - val_loss: 622.1739\n",
      "Epoch 136/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 27.1914 - val_loss: 618.9537\n",
      "Epoch 137/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 27.3844 - val_loss: 623.0651\n",
      "Epoch 138/1000\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 27.0797 - val_loss: 617.4425\n",
      "Epoch 139/1000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 27.1655 - val_loss: 612.5850\n",
      "Epoch 140/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 26.7403 - val_loss: 619.8003\n",
      "Epoch 141/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 26.7842 - val_loss: 618.8115\n",
      "Epoch 142/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 26.6125 - val_loss: 610.1701\n",
      "Epoch 143/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 26.5392 - val_loss: 619.4486\n",
      "Epoch 144/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 26.4834 - val_loss: 615.8312\n",
      "Epoch 145/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 26.1171 - val_loss: 620.1184\n",
      "Epoch 146/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 26.0921 - val_loss: 622.6522\n",
      "Epoch 147/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 25.9546 - val_loss: 616.3414\n",
      "Epoch 148/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 25.8373 - val_loss: 623.8679\n",
      "Epoch 149/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 25.9163 - val_loss: 615.8502\n",
      "Epoch 150/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 25.6925 - val_loss: 618.1970\n",
      "Epoch 151/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 25.2909 - val_loss: 621.3162\n",
      "Epoch 152/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 25.4387 - val_loss: 624.4571\n",
      "Epoch 153/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 25.5704 - val_loss: 620.7902\n",
      "Epoch 154/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 25.3320 - val_loss: 623.2751\n",
      "Epoch 155/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 25.0925 - val_loss: 617.2979\n",
      "Epoch 156/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 25.5382 - val_loss: 620.3660\n",
      "Epoch 157/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 24.6296 - val_loss: 615.8570\n",
      "Epoch 158/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 24.9258 - val_loss: 626.6457\n",
      "Epoch 159/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 6ms/step - loss: 25.0298 - val_loss: 619.1063\n",
      "Epoch 160/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 24.6532 - val_loss: 615.7574\n",
      "Epoch 161/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 24.7950 - val_loss: 609.1979\n",
      "Epoch 162/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 24.6269 - val_loss: 617.8691\n",
      "Epoch 163/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 24.4972 - val_loss: 614.8824\n",
      "Epoch 164/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 24.1319 - val_loss: 619.1309\n",
      "Epoch 165/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 24.2422 - val_loss: 619.6315\n",
      "Epoch 166/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 24.3370 - val_loss: 612.2744\n",
      "Epoch 167/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 24.1357 - val_loss: 615.5909\n",
      "Epoch 168/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 24.4838 - val_loss: 609.6124\n",
      "Epoch 169/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 24.1176 - val_loss: 611.9297\n",
      "Epoch 170/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 23.9910 - val_loss: 609.6622\n",
      "Epoch 171/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 23.7224 - val_loss: 618.2878\n",
      "Epoch 172/1000\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 23.6779 - val_loss: 620.5622\n",
      "Epoch 173/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 23.5477 - val_loss: 621.5200\n",
      "Epoch 174/1000\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 23.2467 - val_loss: 613.2027\n",
      "Epoch 175/1000\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 23.3208 - val_loss: 620.4359\n",
      "Epoch 176/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 23.3895 - val_loss: 616.2854\n",
      "Epoch 177/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 23.2668 - val_loss: 615.8542\n",
      "Epoch 178/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 22.9835 - val_loss: 617.8986\n",
      "Epoch 179/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 22.7151 - val_loss: 614.4485\n",
      "Epoch 180/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 23.3226 - val_loss: 619.3629\n",
      "Epoch 181/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 23.1072 - val_loss: 619.8832\n",
      "Epoch 182/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 22.8681 - val_loss: 606.4539\n",
      "Epoch 183/1000\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 23.1719 - val_loss: 618.5188\n",
      "Epoch 184/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 22.7821 - val_loss: 612.5553\n",
      "Epoch 185/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 22.4216 - val_loss: 618.5150\n",
      "Epoch 186/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 22.3889 - val_loss: 616.8961\n",
      "Epoch 187/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 22.3632 - val_loss: 620.0165\n",
      "Epoch 188/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 26.76 - 0s 5ms/step - loss: 22.3794 - val_loss: 612.3729\n",
      "Epoch 189/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 22.0377 - val_loss: 613.4998\n",
      "Epoch 190/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 22.1412 - val_loss: 613.0480\n",
      "Epoch 191/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 21.9111 - val_loss: 617.3776\n",
      "Epoch 192/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 22.0736 - val_loss: 613.1668\n",
      "Epoch 193/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 22.0750 - val_loss: 617.5141\n",
      "Epoch 194/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 21.7325 - val_loss: 611.9404\n",
      "Epoch 195/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 21.8677 - val_loss: 614.8699\n",
      "Epoch 196/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 21.5507 - val_loss: 612.6637\n",
      "Epoch 197/1000\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 21.5700 - val_loss: 613.4777\n",
      "Epoch 198/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 21.3207 - val_loss: 617.6676\n",
      "Epoch 199/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 21.2810 - val_loss: 610.7426\n",
      "Epoch 200/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 21.3585 - val_loss: 616.1345\n",
      "Epoch 201/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 21.6312 - val_loss: 614.5653\n",
      "Epoch 202/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 21.1413 - val_loss: 618.1823\n",
      "Epoch 203/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 21.2105 - val_loss: 606.7209\n",
      "Epoch 204/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 21.2864 - val_loss: 619.8162\n",
      "Epoch 205/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 21.1546 - val_loss: 617.0656\n",
      "Epoch 206/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 20.8252 - val_loss: 615.0251\n",
      "Epoch 207/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 20.8527 - val_loss: 620.0466\n",
      "Epoch 208/1000\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 20.7855 - val_loss: 610.0085\n",
      "Epoch 209/1000\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 20.8288 - val_loss: 611.2731\n",
      "Epoch 210/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 20.7785 - val_loss: 602.5697\n",
      "Epoch 211/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 20.9123 - val_loss: 617.1907\n",
      "Epoch 212/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 20.7485 - val_loss: 615.1288\n",
      "Epoch 213/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 20.3475 - val_loss: 610.0128\n",
      "Epoch 214/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 20.5567 - val_loss: 612.8904\n",
      "Epoch 215/1000\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 20.3379 - val_loss: 614.5483\n",
      "Epoch 216/1000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 20.3403 - val_loss: 618.2433\n",
      "Epoch 217/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 20.1759 - val_loss: 615.7946\n",
      "Epoch 218/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 20.0199 - val_loss: 611.9937\n",
      "Epoch 219/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 20.0373 - val_loss: 606.6363\n",
      "Epoch 220/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 17.68 - 0s 7ms/step - loss: 20.0013 - val_loss: 615.9793\n",
      "Epoch 221/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 19.9158 - val_loss: 610.0973\n",
      "Epoch 222/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 19.7896 - val_loss: 612.2452\n",
      "Epoch 223/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 19.6738 - val_loss: 616.8796\n",
      "Epoch 224/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 19.7485 - val_loss: 608.2285\n",
      "Epoch 225/1000\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 19.6938 - val_loss: 611.3397\n",
      "Epoch 226/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 19.6090 - val_loss: 613.6726\n",
      "Epoch 227/1000\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 19.4908 - val_loss: 615.1462\n",
      "Epoch 228/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 19.4719 - val_loss: 612.4149\n",
      "Epoch 229/1000\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 19.3833 - val_loss: 612.7733\n",
      "Epoch 230/1000\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 19.2187 - val_loss: 612.3023\n",
      "Epoch 231/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 19.8613 - val_loss: 606.5752\n",
      "Epoch 232/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 19.3223 - val_loss: 616.7659\n",
      "Epoch 233/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 19.2289 - val_loss: 614.7139\n",
      "Epoch 234/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 18.9584 - val_loss: 610.4362\n",
      "Epoch 235/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 19.1093 - val_loss: 611.8376\n",
      "Epoch 236/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 18.9513 - val_loss: 614.6591\n",
      "Epoch 237/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 18.8155 - val_loss: 604.9704\n",
      "Epoch 238/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 6ms/step - loss: 18.8227 - val_loss: 616.5960\n",
      "Epoch 239/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 18.7497 - val_loss: 608.0222\n",
      "Epoch 240/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 18.7265 - val_loss: 610.1851\n",
      "Epoch 241/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 18.6002 - val_loss: 608.2240\n",
      "Epoch 242/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 18.4529 - val_loss: 610.8840\n",
      "Epoch 243/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 18.4547 - val_loss: 612.1091\n",
      "Epoch 244/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 18.4627 - val_loss: 608.8085\n",
      "Epoch 245/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 18.5317 - val_loss: 613.9642\n",
      "Epoch 246/1000\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 18.5361 - val_loss: 609.2682\n",
      "Epoch 247/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 18.2928 - val_loss: 610.5966\n",
      "Epoch 248/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 18.3596 - val_loss: 606.0258\n",
      "Epoch 249/1000\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 18.2036 - val_loss: 611.7302\n",
      "Epoch 250/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 18.1105 - val_loss: 610.9976\n",
      "Epoch 251/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 18.1057 - val_loss: 610.0065\n",
      "Epoch 252/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 17.9928 - val_loss: 610.2490\n",
      "Epoch 253/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 17.8762 - val_loss: 610.4980\n",
      "Epoch 254/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 17.8120 - val_loss: 608.9001\n",
      "Epoch 255/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 17.7741 - val_loss: 612.7943\n",
      "Epoch 256/1000\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 18.1272 - val_loss: 609.6313\n",
      "Epoch 257/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 17.6223 - val_loss: 611.8727\n",
      "Epoch 258/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 17.7556 - val_loss: 613.8754\n",
      "Epoch 259/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 17.5043 - val_loss: 614.1409\n",
      "Epoch 260/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 17.6654 - val_loss: 606.6513\n",
      "Epoch 261/1000\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 17.4829 - val_loss: 611.8926\n",
      "Epoch 262/1000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 17.4428 - val_loss: 607.8942\n",
      "Epoch 263/1000\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 17.5984 - val_loss: 607.5084\n",
      "Epoch 264/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 17.2719 - val_loss: 618.1381\n",
      "Epoch 265/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 17.1904 - val_loss: 612.1403\n",
      "Epoch 266/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 17.1222 - val_loss: 616.9644\n",
      "Epoch 267/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 17.1725 - val_loss: 610.1044\n",
      "Epoch 268/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 17.4022 - val_loss: 614.2847\n",
      "Epoch 269/1000\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 17.1042 - val_loss: 611.2288\n",
      "Epoch 270/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 16.9469 - val_loss: 615.1925\n",
      "Epoch 271/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 16.8919 - val_loss: 608.0502\n",
      "Epoch 272/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 16.8422 - val_loss: 614.3350\n",
      "Epoch 273/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 16.9004 - val_loss: 610.8701\n",
      "Epoch 274/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 16.6560 - val_loss: 611.0213\n",
      "Epoch 275/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 16.5932 - val_loss: 614.5081\n",
      "Epoch 276/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 16.7585 - val_loss: 608.4420\n",
      "Epoch 277/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 16.6345 - val_loss: 613.8109\n",
      "Epoch 278/1000\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 16.5256 - val_loss: 608.9237\n",
      "Epoch 279/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 16.5192 - val_loss: 612.1383\n",
      "Epoch 280/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 16.4490 - val_loss: 621.2939\n",
      "Epoch 281/1000\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 16.5535 - val_loss: 615.6961\n",
      "Epoch 282/1000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 16.4108 - val_loss: 613.6393\n",
      "Epoch 283/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 16.3188 - val_loss: 609.8489\n",
      "Epoch 284/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 16.3860 - val_loss: 607.6771\n",
      "Epoch 285/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 16.1941 - val_loss: 615.8495\n",
      "Epoch 286/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 16.2293 - val_loss: 614.7396\n",
      "Epoch 287/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 16.0851 - val_loss: 609.1451\n",
      "Epoch 288/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 16.1966 - val_loss: 614.2719\n",
      "Epoch 289/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 15.9527 - val_loss: 614.5742\n",
      "Epoch 290/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 16.0173 - val_loss: 611.0790\n",
      "Epoch 291/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 15.9689 - val_loss: 611.2631\n",
      "Epoch 292/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 16.0021 - val_loss: 612.8330\n",
      "Epoch 293/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 15.7647 - val_loss: 610.1680\n",
      "Epoch 294/1000\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 16.0027 - val_loss: 610.5130\n",
      "Epoch 295/1000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 15.7397 - val_loss: 612.0601\n",
      "Epoch 296/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 15.6485 - val_loss: 608.9518\n",
      "Epoch 297/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 15.6592 - val_loss: 615.2857\n",
      "Epoch 298/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 15.6130 - val_loss: 614.3531\n",
      "Epoch 299/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 15.4928 - val_loss: 609.8893\n",
      "Epoch 300/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 15.6791 - val_loss: 612.0494\n",
      "Epoch 301/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 15.3940 - val_loss: 611.5504\n",
      "Epoch 302/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 15.6344 - val_loss: 609.7062\n",
      "Epoch 303/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 15.4960 - val_loss: 613.5427\n",
      "Epoch 304/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 15.3077 - val_loss: 605.3450\n",
      "Epoch 305/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 15.4582 - val_loss: 612.8030\n",
      "Epoch 306/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 15.3132 - val_loss: 613.4836\n",
      "Epoch 307/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 15.1784 - val_loss: 610.3685\n",
      "Epoch 308/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 15.2140 - val_loss: 611.1375\n",
      "Epoch 309/1000\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 15.1508 - val_loss: 613.1235\n",
      "Epoch 310/1000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 15.0032 - val_loss: 615.7773\n",
      "Epoch 311/1000\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 15.0170 - val_loss: 612.4296\n",
      "Epoch 312/1000\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 15.0507 - val_loss: 614.4811\n",
      "Epoch 313/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 15.0998 - val_loss: 613.5338\n",
      "Epoch 314/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 14.9995 - val_loss: 616.1647\n",
      "Epoch 315/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 15.0689 - val_loss: 613.4317\n",
      "Epoch 316/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 14.7176 - val_loss: 612.6340\n",
      "Epoch 317/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 6ms/step - loss: 14.6905 - val_loss: 615.4351\n",
      "Epoch 318/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 14.8203 - val_loss: 614.5372\n",
      "Epoch 319/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 14.7232 - val_loss: 614.9229\n",
      "Epoch 320/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 14.6821 - val_loss: 613.1473\n",
      "Epoch 321/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 14.8104 - val_loss: 613.5784\n",
      "Epoch 322/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 14.5192 - val_loss: 609.7369\n",
      "Epoch 323/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 14.5930 - val_loss: 618.0742\n",
      "Epoch 324/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 14.6526 - val_loss: 617.0938\n",
      "Epoch 325/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 14.4949 - val_loss: 616.4371\n",
      "Epoch 326/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 14.4853 - val_loss: 615.7037\n",
      "Epoch 327/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 14.3621 - val_loss: 613.8385\n",
      "Epoch 328/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 14.3037 - val_loss: 614.5097\n",
      "Epoch 329/1000\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 14.2816 - val_loss: 613.5634\n",
      "Epoch 330/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 14.2696 - val_loss: 612.3126\n",
      "Epoch 331/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 14.3454 - val_loss: 611.6523\n",
      "Epoch 332/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 14.2542 - val_loss: 614.5397\n",
      "Epoch 333/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 14.1283 - val_loss: 614.4474\n",
      "Epoch 334/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 14.1248 - val_loss: 612.2835\n",
      "Epoch 335/1000\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 14.0771 - val_loss: 614.0073\n",
      "Epoch 336/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 14.0082 - val_loss: 613.6022\n",
      "Epoch 337/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 14.4167 - val_loss: 603.9797\n",
      "Epoch 338/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 14.3927 - val_loss: 609.9571\n",
      "Epoch 339/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 13.9735 - val_loss: 611.3856\n",
      "Epoch 340/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 13.9336 - val_loss: 615.2412\n",
      "Epoch 341/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 14.0018 - val_loss: 614.7877\n",
      "Epoch 342/1000\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 14.0204 - val_loss: 613.6828\n",
      "Epoch 343/1000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 13.8481 - val_loss: 613.4733\n",
      "Epoch 344/1000\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 13.6503 - val_loss: 617.2076\n",
      "Epoch 345/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 13.9818 - val_loss: 608.8303\n",
      "Epoch 346/1000\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 13.8070 - val_loss: 613.5662\n",
      "Epoch 347/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 13.6559 - val_loss: 614.2743\n",
      "Epoch 348/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 13.6324 - val_loss: 616.3997\n",
      "Epoch 349/1000\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 13.4196 - val_loss: 614.2408\n",
      "Epoch 350/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 13.5321 - val_loss: 614.5448\n",
      "Epoch 351/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 13.7063 - val_loss: 617.9750\n",
      "Epoch 352/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 13.5584 - val_loss: 613.4571\n",
      "Epoch 353/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 13.3799 - val_loss: 615.4285\n",
      "Epoch 354/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 13.3343 - val_loss: 612.9481\n",
      "Epoch 355/1000\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 13.3300 - val_loss: 616.1998\n",
      "Epoch 356/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 13.2464 - val_loss: 611.7042\n",
      "Epoch 357/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 13.2578 - val_loss: 614.9282\n",
      "Epoch 358/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 13.2225 - val_loss: 616.9554\n",
      "Epoch 359/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 13.3560 - val_loss: 618.6775\n",
      "Epoch 360/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 13.2819 - val_loss: 615.7848\n",
      "Epoch 361/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 13.0831 - val_loss: 618.0061\n",
      "Epoch 362/1000\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 13.1129 - val_loss: 614.7098\n",
      "Epoch 363/1000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 13.0857 - val_loss: 615.6309\n",
      "Epoch 364/1000\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 13.1731 - val_loss: 615.1917\n",
      "Epoch 365/1000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 13.0772 - val_loss: 616.2900\n",
      "Epoch 366/1000\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 12.8804 - val_loss: 619.8059\n",
      "Epoch 367/1000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 12.9200 - val_loss: 616.5504\n",
      "Epoch 368/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 12.8295 - val_loss: 617.8488\n",
      "Epoch 369/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 12.8793 - val_loss: 616.1375\n",
      "Epoch 370/1000\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 12.7943 - val_loss: 618.9440\n",
      "Epoch 371/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 13.0542 - val_loss: 610.3163\n",
      "Epoch 372/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 12.7966 - val_loss: 622.4262\n",
      "Epoch 373/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 12.9645 - val_loss: 618.7342\n",
      "Epoch 374/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 12.7375 - val_loss: 617.7616\n",
      "Epoch 375/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 12.8417 - val_loss: 620.4443\n",
      "Epoch 376/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 12.5991 - val_loss: 614.9275\n",
      "Epoch 377/1000\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 12.6132 - val_loss: 617.9628\n",
      "Epoch 378/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 10.27 - 0s 8ms/step - loss: 12.6406 - val_loss: 619.3340\n",
      "Epoch 379/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 12.5400 - val_loss: 616.3004\n",
      "Epoch 380/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 12.6482 - val_loss: 619.7373\n",
      "Epoch 381/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 12.4236 - val_loss: 615.3428\n",
      "Epoch 382/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 12.4435 - val_loss: 620.8425\n",
      "Epoch 383/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 12.3652 - val_loss: 619.4578\n",
      "Epoch 384/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 12.5608 - val_loss: 621.6246\n",
      "Epoch 385/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 12.3143 - val_loss: 615.4663\n",
      "Epoch 386/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 12.3455 - val_loss: 619.1365\n",
      "Epoch 387/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 12.6015 - val_loss: 619.3292\n",
      "Epoch 388/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 12.2827 - val_loss: 619.3351\n",
      "Epoch 389/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 12.4463 - val_loss: 614.6599\n",
      "Epoch 390/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 12.4148 - val_loss: 617.3113\n",
      "Epoch 391/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 12.2679 - val_loss: 621.0455\n",
      "Epoch 392/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 12.1995 - val_loss: 620.9021\n",
      "Epoch 393/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 12.1335 - val_loss: 620.7548\n",
      "Epoch 394/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 12.0958 - val_loss: 620.4228\n",
      "Epoch 395/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 12.5424 - val_loss: 617.4373\n",
      "Epoch 396/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 8ms/step - loss: 12.2009 - val_loss: 622.6974\n",
      "Epoch 397/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 11.9077 - val_loss: 621.6516\n",
      "Epoch 398/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 12.1390 - val_loss: 621.1198\n",
      "Epoch 399/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 11.8684 - val_loss: 623.2460\n",
      "Epoch 400/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 11.8124 - val_loss: 620.7429\n",
      "Epoch 401/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 12.1730 - val_loss: 622.2730\n",
      "Epoch 402/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 11.7915 - val_loss: 621.3123\n",
      "Epoch 403/1000\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 11.8758 - val_loss: 620.4111\n",
      "Epoch 404/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 11.9628 - val_loss: 619.7501\n",
      "Epoch 405/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 11.7609 - val_loss: 624.2621\n",
      "Epoch 406/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 11.8465 - val_loss: 620.5752\n",
      "Epoch 407/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 11.7600 - val_loss: 622.1032\n",
      "Epoch 408/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 11.7723 - val_loss: 626.6180\n",
      "Epoch 409/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 11.7906 - val_loss: 624.9160\n",
      "Epoch 410/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 11.7312 - val_loss: 621.9030\n",
      "Epoch 411/1000\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 11.5625 - val_loss: 621.1754\n",
      "Epoch 412/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 11.5497 - val_loss: 624.3709\n",
      "Epoch 413/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 11.5203 - val_loss: 628.3879\n",
      "Epoch 414/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 11.8472 - val_loss: 625.7515\n",
      "Epoch 415/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 11.4475 - val_loss: 623.0255\n",
      "Epoch 416/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 11.4413 - val_loss: 624.6713\n",
      "Epoch 417/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 11.05 - 0s 6ms/step - loss: 11.4824 - val_loss: 621.5464\n",
      "Epoch 418/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 11.4865 - val_loss: 628.1440\n",
      "Epoch 419/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 11.3898 - val_loss: 624.5800\n",
      "Epoch 420/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 11.3649 - val_loss: 628.0973\n",
      "Epoch 421/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 8.622 - 0s 7ms/step - loss: 11.3371 - val_loss: 627.1810\n",
      "Epoch 422/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 11.3031 - val_loss: 625.0450\n",
      "Epoch 423/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 6.928 - 0s 6ms/step - loss: 11.2412 - val_loss: 624.4568\n",
      "Epoch 424/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 11.3264 - val_loss: 625.8876\n",
      "Epoch 425/1000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 11.2537 - val_loss: 627.7927\n",
      "Epoch 426/1000\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 11.2904 - val_loss: 629.2164\n",
      "Epoch 427/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 11.2582 - val_loss: 627.6415\n",
      "Epoch 428/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 11.1757 - val_loss: 626.8791\n",
      "Epoch 429/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 11.1444 - val_loss: 627.3036\n",
      "Epoch 430/1000\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 10.9907 - val_loss: 629.9761\n",
      "Epoch 431/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 10.9714 - val_loss: 631.0740\n",
      "Epoch 432/1000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 10.9726 - val_loss: 627.7226\n",
      "Epoch 433/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 10.9998 - val_loss: 626.5157\n",
      "Epoch 434/1000\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 10.9243 - val_loss: 630.5044\n",
      "Epoch 435/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 10.9413 - val_loss: 621.2130\n",
      "Epoch 436/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 11.0380 - val_loss: 628.5527\n",
      "Epoch 437/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 11.0123 - val_loss: 628.1357\n",
      "Epoch 438/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 10.9244 - val_loss: 622.6705\n",
      "Epoch 439/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 11.0058 - val_loss: 628.6161\n",
      "Epoch 440/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 10.8525 - val_loss: 628.1920\n",
      "Epoch 441/1000\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 10.7079 - val_loss: 632.0133\n",
      "Epoch 442/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 10.8065 - val_loss: 629.7249\n",
      "Epoch 443/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 10.7676 - val_loss: 628.4487\n",
      "Epoch 444/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 7.866 - 0s 6ms/step - loss: 10.6895 - val_loss: 629.9243\n",
      "Epoch 445/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 10.7370 - val_loss: 630.9034\n",
      "Epoch 446/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 10.5800 - val_loss: 631.2820\n",
      "Epoch 447/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 10.6525 - val_loss: 631.4532\n",
      "Epoch 448/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 10.5479 - val_loss: 632.2371\n",
      "Epoch 449/1000\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 10.6419 - val_loss: 632.6039\n",
      "Epoch 450/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 10.5277 - val_loss: 630.9161\n",
      "Epoch 451/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 10.5440 - val_loss: 634.8531\n",
      "Epoch 452/1000\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 10.7814 - val_loss: 634.4379\n",
      "Epoch 453/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 10.4899 - val_loss: 632.4865\n",
      "Epoch 454/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 10.5364 - val_loss: 635.4273\n",
      "Epoch 455/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 10.5587 - val_loss: 638.5605\n",
      "Epoch 456/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 10.4706 - val_loss: 635.8776\n",
      "Epoch 457/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 10.6319 - val_loss: 633.6354\n",
      "Epoch 458/1000\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 10.3571 - val_loss: 635.3163\n",
      "Epoch 459/1000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 10.3157 - val_loss: 637.2918\n",
      "Epoch 460/1000\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 10.2840 - val_loss: 635.1437\n",
      "Epoch 461/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 10.2665 - val_loss: 634.6249\n",
      "Epoch 462/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 10.3631 - val_loss: 637.6444\n",
      "Epoch 463/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 10.3418 - val_loss: 638.2065\n",
      "Epoch 464/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 10.4159 - val_loss: 635.6042\n",
      "Epoch 465/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 10.3016 - val_loss: 635.9877\n",
      "Epoch 466/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 10.1688 - val_loss: 638.8580\n",
      "Epoch 467/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 10.1399 - val_loss: 634.9820\n",
      "Epoch 468/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 10.1547 - val_loss: 638.9409\n",
      "Epoch 469/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 10.2090 - val_loss: 637.3868\n",
      "Epoch 470/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 10.0822 - val_loss: 637.1150\n",
      "Epoch 471/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 10.0580 - val_loss: 639.7186\n",
      "Epoch 472/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 10.0091 - val_loss: 637.0454\n",
      "Epoch 473/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 10.2052 - val_loss: 640.6996\n",
      "Epoch 474/1000\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 10.0241 - val_loss: 638.2599\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 475/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 10.0164 - val_loss: 640.9700\n",
      "Epoch 476/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 10.0407 - val_loss: 643.1230\n",
      "Epoch 477/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 9.9639 - val_loss: 638.5853\n",
      "Epoch 478/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 9.9320 - val_loss: 640.7221\n",
      "Epoch 479/1000\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 9.9151 - val_loss: 639.2511\n",
      "Epoch 480/1000\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 9.8792 - val_loss: 640.1595\n",
      "Epoch 481/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 9.7898 - val_loss: 641.0893\n",
      "Epoch 482/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 9.8406 - val_loss: 640.9843\n",
      "Epoch 483/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 9.7986 - val_loss: 638.6730\n",
      "Epoch 484/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 9.8174 - val_loss: 639.6338\n",
      "Epoch 485/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 9.7691 - val_loss: 641.9896\n",
      "Epoch 486/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 9.7659 - val_loss: 642.3509\n",
      "Epoch 487/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 9.8772 - val_loss: 639.9233\n",
      "Epoch 488/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 9.6910 - val_loss: 641.7758\n",
      "Epoch 489/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 9.7464 - val_loss: 643.0807\n",
      "Epoch 490/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 9.6833 - val_loss: 642.7106\n",
      "Epoch 491/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 9.5936 - val_loss: 642.5267\n",
      "Epoch 492/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 9.8082 - val_loss: 643.4983\n",
      "Epoch 493/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 9.7369 - val_loss: 640.6862\n",
      "Epoch 494/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 9.6086 - val_loss: 642.0461\n",
      "Epoch 495/1000\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 9.6136 - val_loss: 645.9195\n",
      "Epoch 496/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 9.7497 - val_loss: 643.3412\n",
      "Epoch 497/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 9.5842 - val_loss: 644.2234\n",
      "Epoch 498/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 9.6132 - val_loss: 646.7923\n",
      "Epoch 499/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 9.5138 - val_loss: 643.0350\n",
      "Epoch 500/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 9.4672 - val_loss: 643.3945\n",
      "Epoch 501/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 9.5736 - val_loss: 645.0975\n",
      "Epoch 502/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 9.4280 - val_loss: 642.6935\n",
      "Epoch 503/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 9.5427 - val_loss: 643.5397\n",
      "Epoch 504/1000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 9.5490 - val_loss: 647.7999\n",
      "Epoch 505/1000\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 9.3652 - val_loss: 645.6263\n",
      "Epoch 506/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 9.4460 - val_loss: 642.9539\n",
      "Epoch 507/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 9.4050 - val_loss: 647.8710\n",
      "Epoch 508/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 9.4190 - val_loss: 648.1123\n",
      "Epoch 509/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 9.6507 - val_loss: 648.8186\n",
      "Epoch 510/1000\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 9.3335 - val_loss: 647.7482\n",
      "Epoch 511/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 9.2708 - val_loss: 645.9006\n",
      "Epoch 512/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 9.3061 - val_loss: 648.0989\n",
      "Epoch 513/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 9.3155 - val_loss: 649.2720\n",
      "Epoch 514/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 9.2483 - val_loss: 647.6055\n",
      "Epoch 515/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 9.1810 - val_loss: 650.5693\n",
      "Epoch 516/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 9.1696 - val_loss: 646.8904\n",
      "Epoch 517/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 9.1578 - val_loss: 648.9551\n",
      "Epoch 518/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 9.0915 - val_loss: 650.1049\n",
      "Epoch 519/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 9.1452 - val_loss: 651.1940\n",
      "Epoch 520/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 9.1460 - val_loss: 649.0757\n",
      "Epoch 521/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 9.0984 - val_loss: 650.7036\n",
      "Epoch 522/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 9.1545 - val_loss: 649.8019\n",
      "Epoch 523/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 9.0799 - val_loss: 650.1185\n",
      "Epoch 524/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 8.9966 - val_loss: 650.4934\n",
      "Epoch 525/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 9.0610 - val_loss: 651.5404\n",
      "Epoch 526/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 8.9795 - val_loss: 650.5701\n",
      "Epoch 527/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 8.9909 - val_loss: 652.7671\n",
      "Epoch 528/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 9.0873 - val_loss: 654.1561\n",
      "Epoch 529/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 9.0435 - val_loss: 654.5679\n",
      "Epoch 530/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 8.9894 - val_loss: 651.5979\n",
      "Epoch 531/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 8.9276 - val_loss: 652.7032\n",
      "Epoch 532/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 10.03 - 0s 6ms/step - loss: 8.8407 - val_loss: 653.4297\n",
      "Epoch 533/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 9.0240 - val_loss: 654.2740\n",
      "Epoch 534/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 8.9046 - val_loss: 652.7956\n",
      "Epoch 535/1000\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 8.8475 - val_loss: 652.9404\n",
      "Epoch 536/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 7.066 - 0s 8ms/step - loss: 8.8713 - val_loss: 652.2880\n",
      "Epoch 537/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 8.7723 - val_loss: 654.2696\n",
      "Epoch 538/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 8.9773 - val_loss: 654.9031\n",
      "Epoch 539/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 8.8037 - val_loss: 656.5982\n",
      "Epoch 540/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 8.9077 - val_loss: 656.1571\n",
      "Epoch 541/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 8.7646 - val_loss: 651.6528\n",
      "Epoch 542/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 8.7317 - val_loss: 657.3803\n",
      "Epoch 543/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 8.8143 - val_loss: 654.1440\n",
      "Epoch 544/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 8.8658 - val_loss: 656.3581\n",
      "Epoch 545/1000\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 8.7045 - val_loss: 654.9542\n",
      "Epoch 546/1000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 8.6418 - val_loss: 657.2847\n",
      "Epoch 547/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 8.6423 - val_loss: 657.8540\n",
      "Epoch 548/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 8.5616 - val_loss: 657.3902\n",
      "Epoch 549/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 8.6872 - val_loss: 656.6638\n",
      "Epoch 550/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 8.6043 - val_loss: 657.5006\n",
      "Epoch 551/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 8.5550 - val_loss: 657.5789\n",
      "Epoch 552/1000\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 8.5388 - val_loss: 656.2566\n",
      "Epoch 553/1000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 8.5454 - val_loss: 658.5809\n",
      "Epoch 554/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 8.6871 - val_loss: 657.7343\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 555/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 8.5288 - val_loss: 659.9944\n",
      "Epoch 556/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 8.5407 - val_loss: 657.8748\n",
      "Epoch 557/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 8.4385 - val_loss: 657.5801\n",
      "Epoch 558/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 8.4354 - val_loss: 657.3433\n",
      "Epoch 559/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 8.5227 - val_loss: 655.9597\n",
      "Epoch 560/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 8.4748 - val_loss: 659.5253\n",
      "Epoch 561/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 5.793 - 0s 7ms/step - loss: 8.3957 - val_loss: 659.4715\n",
      "Epoch 562/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 8.3236 - val_loss: 660.2090\n",
      "Epoch 563/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 8.3686 - val_loss: 661.3177\n",
      "Epoch 564/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 7.289 - 0s 7ms/step - loss: 8.4133 - val_loss: 659.2018\n",
      "Epoch 565/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 8.4975 - val_loss: 661.1654\n",
      "Epoch 566/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 8.5679 - val_loss: 663.0120\n",
      "Epoch 567/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 8.2776 - val_loss: 661.0574\n",
      "Epoch 568/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 8.3219 - val_loss: 660.7697\n",
      "Epoch 569/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 8.3542 - val_loss: 661.2999\n",
      "Epoch 570/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 8.2756 - val_loss: 663.7553\n",
      "Epoch 571/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 8.3475 - val_loss: 665.3881\n",
      "Epoch 572/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 8.3523 - val_loss: 663.8256\n",
      "Epoch 573/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 8.2342 - val_loss: 662.3811\n",
      "Epoch 574/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 8.3816 - val_loss: 663.3502\n",
      "Epoch 575/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 8.2005 - val_loss: 665.9418\n",
      "Epoch 576/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 8.3109 - val_loss: 663.2690\n",
      "Epoch 577/1000\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 8.2314 - val_loss: 660.2932\n",
      "Epoch 578/1000\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 8.1859 - val_loss: 665.6938\n",
      "Epoch 579/1000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 8.2453 - val_loss: 664.0370\n",
      "Epoch 580/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 8.1615 - val_loss: 663.8539\n",
      "Epoch 581/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 8.1474 - val_loss: 663.8608\n",
      "Epoch 582/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 8.1035 - val_loss: 663.4097\n",
      "Epoch 583/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 8.0644 - val_loss: 663.8812\n",
      "Epoch 584/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 8.0292 - val_loss: 666.1981\n",
      "Epoch 585/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 8.0151 - val_loss: 666.8336\n",
      "Epoch 586/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 8.0586 - val_loss: 667.4788\n",
      "Epoch 587/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 8.0387 - val_loss: 664.5092\n",
      "Epoch 588/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 8.0743 - val_loss: 663.4512\n",
      "Epoch 589/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 7.9739 - val_loss: 667.8982\n",
      "Epoch 590/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 8.0444 - val_loss: 664.9905\n",
      "Epoch 591/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 8.1019 - val_loss: 665.7859\n",
      "Epoch 592/1000\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 7.9152 - val_loss: 668.6259\n",
      "Epoch 593/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 7.8898 - val_loss: 666.7958\n",
      "Epoch 594/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 7.9036 - val_loss: 668.9985\n",
      "Epoch 595/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 7.9777 - val_loss: 668.1049\n",
      "Epoch 596/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 7.9174 - val_loss: 668.8914\n",
      "Epoch 597/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 8.0474 - val_loss: 668.8895\n",
      "Epoch 598/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 7.9546 - val_loss: 666.5790\n",
      "Epoch 599/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 7.9619 - val_loss: 670.1783\n",
      "Epoch 600/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 7.8721 - val_loss: 670.1553\n",
      "Epoch 601/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 7.8623 - val_loss: 670.1469\n",
      "Epoch 602/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 7.8088 - val_loss: 669.6479\n",
      "Epoch 603/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 7.8216 - val_loss: 668.8983\n",
      "Epoch 604/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 7.7563 - val_loss: 670.5659\n",
      "Epoch 605/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 7.7366 - val_loss: 671.6961\n",
      "Epoch 606/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 7.7639 - val_loss: 673.1569\n",
      "Epoch 607/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 7.8330 - val_loss: 670.7993\n",
      "Epoch 608/1000\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 7.7987 - val_loss: 672.9660\n",
      "Epoch 609/1000\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 7.7743 - val_loss: 669.0612\n",
      "Epoch 610/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 8.0698 - val_loss: 672.5064\n",
      "Epoch 611/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 7.7139 - val_loss: 673.6255\n",
      "Epoch 612/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 7.7962 - val_loss: 673.8685\n",
      "Epoch 613/1000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 7.7475 - val_loss: 672.7920\n",
      "Epoch 614/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 7.6490 - val_loss: 672.5118\n",
      "Epoch 615/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 7.6314 - val_loss: 673.6949\n",
      "Epoch 616/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 7.8012 - val_loss: 669.3079\n",
      "Epoch 617/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 7.7846 - val_loss: 677.0198\n",
      "Epoch 618/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 7.6198 - val_loss: 672.1422\n",
      "Epoch 619/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 5.690 - 0s 6ms/step - loss: 7.6996 - val_loss: 672.2100\n",
      "Epoch 620/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 7.5410 - val_loss: 675.1432\n",
      "Epoch 621/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 7.6045 - val_loss: 672.1346\n",
      "Epoch 622/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 7.7494 - val_loss: 673.3051\n",
      "Epoch 623/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 7.5600 - val_loss: 676.6028\n",
      "Epoch 624/1000\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 7.6477 - val_loss: 670.9313\n",
      "Epoch 625/1000\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 7.5288 - val_loss: 675.0516\n",
      "Epoch 626/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 5.058 - 0s 8ms/step - loss: 7.4896 - val_loss: 676.2712\n",
      "Epoch 627/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 7.4287 - val_loss: 674.9402\n",
      "Epoch 628/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 7.5170 - val_loss: 674.5729\n",
      "Epoch 629/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 7.4808 - val_loss: 676.3666\n",
      "Epoch 630/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 7.5486 - val_loss: 677.8778\n",
      "Epoch 631/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 7.5037 - val_loss: 674.0344\n",
      "Epoch 632/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 7.4306 - val_loss: 676.7050\n",
      "Epoch 633/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 7.4157 - val_loss: 676.4739\n",
      "Epoch 634/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 7ms/step - loss: 7.3207 - val_loss: 677.3892\n",
      "Epoch 635/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 7.3430 - val_loss: 678.0214\n",
      "Epoch 636/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 5.336 - 0s 6ms/step - loss: 7.4033 - val_loss: 678.3367\n",
      "Epoch 637/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 7.3499 - val_loss: 679.6842\n",
      "Epoch 638/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 7.3735 - val_loss: 680.9247\n",
      "Epoch 639/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 7.4145 - val_loss: 680.2146\n",
      "Epoch 640/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 7.2772 - val_loss: 680.0926\n",
      "Epoch 641/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 7.2725 - val_loss: 680.6774\n",
      "Epoch 642/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 7.4042 - val_loss: 682.0178\n",
      "Epoch 643/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 7.3362 - val_loss: 678.0485\n",
      "Epoch 644/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 7.2810 - val_loss: 682.1149\n",
      "Epoch 645/1000\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 7.3455 - val_loss: 680.8047\n",
      "Epoch 646/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 7.2292 - val_loss: 682.5287\n",
      "Epoch 647/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 7.2613 - val_loss: 680.0303\n",
      "Epoch 648/1000\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 7.1998 - val_loss: 684.1014\n",
      "Epoch 649/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 4.263 - 0s 8ms/step - loss: 7.1909 - val_loss: 682.4230\n",
      "Epoch 650/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 7.1659 - val_loss: 683.0233\n",
      "Epoch 651/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 11.91 - 0s 3ms/step - loss: 7.2258 - val_loss: 685.0494\n",
      "Epoch 652/1000\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 7.4186 - val_loss: 681.9127\n",
      "Epoch 653/1000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 7.1789 - val_loss: 682.2753\n",
      "Epoch 654/1000\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 7.1749 - val_loss: 686.5101\n",
      "Epoch 655/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 12.24 - 0s 8ms/step - loss: 7.2105 - val_loss: 682.8886\n",
      "Epoch 656/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 7.3182 - val_loss: 681.8951\n",
      "Epoch 657/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 3.821 - 0s 7ms/step - loss: 7.1607 - val_loss: 684.9262\n",
      "Epoch 658/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 7.0429 - val_loss: 684.7603\n",
      "Epoch 659/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 7.0918 - val_loss: 684.4270\n",
      "Epoch 660/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 7.0612 - val_loss: 686.5966\n",
      "Epoch 661/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 7.0404 - val_loss: 685.9736\n",
      "Epoch 662/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 7.1172 - val_loss: 686.7540\n",
      "Epoch 663/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 7.1281 - val_loss: 684.4193\n",
      "Epoch 664/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 7.2121 - val_loss: 688.8005\n",
      "Epoch 665/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 7.0571 - val_loss: 685.9349\n",
      "Epoch 666/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 7.0143 - val_loss: 686.0214\n",
      "Epoch 667/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 6.9790 - val_loss: 689.5959\n",
      "Epoch 668/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 12.26 - 0s 7ms/step - loss: 6.9729 - val_loss: 686.5313\n",
      "Epoch 669/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 7.1296 - val_loss: 689.2693\n",
      "Epoch 670/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 6.9258 - val_loss: 687.9098\n",
      "Epoch 671/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 7.0367 - val_loss: 689.3049\n",
      "Epoch 672/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 6.8865 - val_loss: 689.6322\n",
      "Epoch 673/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 6.9200 - val_loss: 691.3878\n",
      "Epoch 674/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 6.9387 - val_loss: 691.9467\n",
      "Epoch 675/1000\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 6.8828 - val_loss: 689.3072\n",
      "Epoch 676/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 6.9580 - val_loss: 690.2912\n",
      "Epoch 677/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 6.8577 - val_loss: 692.2192\n",
      "Epoch 678/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 6.8616 - val_loss: 693.1302\n",
      "Epoch 679/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 4.803 - 0s 6ms/step - loss: 6.8430 - val_loss: 692.9961\n",
      "Epoch 680/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 6.8972 - val_loss: 692.2874\n",
      "Epoch 681/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 6.8050 - val_loss: 692.2082\n",
      "Epoch 682/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 6.8085 - val_loss: 693.1871\n",
      "Epoch 683/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 6.9305 - val_loss: 693.7957\n",
      "Epoch 684/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 6.8604 - val_loss: 695.3733\n",
      "Epoch 685/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 6.7846 - val_loss: 692.9006\n",
      "Epoch 686/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 6.8461 - val_loss: 696.2437\n",
      "Epoch 687/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 6.9383 - val_loss: 695.0967\n",
      "Epoch 688/1000\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 6.9052 - val_loss: 694.7201\n",
      "Epoch 689/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 6.8069 - val_loss: 695.6496\n",
      "Epoch 690/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 6.7897 - val_loss: 695.6532\n",
      "Epoch 691/1000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 6.7837 - val_loss: 693.5543\n",
      "Epoch 692/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 6.8283 - val_loss: 696.8875\n",
      "Epoch 693/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 6.7236 - val_loss: 696.4885\n",
      "Epoch 694/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 6.6863 - val_loss: 698.5370\n",
      "Epoch 695/1000\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 6.6662 - val_loss: 696.4106\n",
      "Epoch 696/1000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 6.7107 - val_loss: 694.7737\n",
      "Epoch 697/1000\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 6.8032 - val_loss: 694.4088\n",
      "Epoch 698/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 6.6851 - val_loss: 697.7879\n",
      "Epoch 699/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 6.6991 - val_loss: 699.1653\n",
      "Epoch 700/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 6.6163 - val_loss: 697.7646\n",
      "Epoch 701/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 6.7841 - val_loss: 697.8310\n",
      "Epoch 702/1000\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 6.5734 - val_loss: 699.0548\n",
      "Epoch 703/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 6.6364 - val_loss: 699.6619\n",
      "Epoch 704/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 6.5977 - val_loss: 699.6497\n",
      "Epoch 705/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 6.5665 - val_loss: 700.5040\n",
      "Epoch 706/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 6.8264 - val_loss: 700.1606\n",
      "Epoch 707/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 6.5109 - val_loss: 700.4030\n",
      "Epoch 708/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 6.5502 - val_loss: 701.0491\n",
      "Epoch 709/1000\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 6.5332 - val_loss: 702.7890\n",
      "Epoch 710/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 6.5227 - val_loss: 701.3199\n",
      "Epoch 711/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 6.6118 - val_loss: 703.0781\n",
      "Epoch 712/1000\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 6.4832 - val_loss: 702.7383\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 713/1000\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 6.4960 - val_loss: 702.3168\n",
      "Epoch 714/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 6.4287 - val_loss: 701.6616\n",
      "Epoch 715/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 6.4702 - val_loss: 705.2216\n",
      "Epoch 716/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 6.4440 - val_loss: 703.4961\n",
      "Epoch 717/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 6.345 - 0s 6ms/step - loss: 6.5435 - val_loss: 701.4037\n",
      "Epoch 718/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 6.4425 - val_loss: 705.5456\n",
      "Epoch 719/1000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 6.4917 - val_loss: 703.8859\n",
      "Epoch 720/1000\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 6.4064 - val_loss: 703.1008\n",
      "Epoch 721/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 6.4031 - val_loss: 704.4382\n",
      "Epoch 722/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 6.3642 - val_loss: 704.9519\n",
      "Epoch 723/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 6.4303 - val_loss: 705.2174\n",
      "Epoch 724/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 6.3610 - val_loss: 706.1882\n",
      "Epoch 725/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 6.3447 - val_loss: 707.3428\n",
      "Epoch 726/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 3.480 - 0s 7ms/step - loss: 6.4373 - val_loss: 706.7238\n",
      "Epoch 727/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 6.3685 - val_loss: 708.0114\n",
      "Epoch 728/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 6.3134 - val_loss: 707.6968\n",
      "Epoch 729/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 6.3088 - val_loss: 706.8807\n",
      "Epoch 730/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 6.3286 - val_loss: 707.8394\n",
      "Epoch 731/1000\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 6.3376 - val_loss: 707.7187\n",
      "Epoch 732/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 6.3694 - val_loss: 708.3822\n",
      "Epoch 733/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 6.2625 - val_loss: 708.0750\n",
      "Epoch 734/1000\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 6.2529 - val_loss: 708.3630\n",
      "Epoch 735/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 6.2957 - val_loss: 710.0876\n",
      "Epoch 736/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 6.2381 - val_loss: 709.7311\n",
      "Epoch 737/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 6.2191 - val_loss: 711.5283\n",
      "Epoch 738/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 6.2699 - val_loss: 709.1968\n",
      "Epoch 739/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 6.2313 - val_loss: 713.4599\n",
      "Epoch 740/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 6.3279 - val_loss: 712.0129\n",
      "Epoch 741/1000\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 6.2545 - val_loss: 711.6337\n",
      "Epoch 742/1000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 6.2820 - val_loss: 712.4655\n",
      "Epoch 743/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 6.1760 - val_loss: 711.9635\n",
      "Epoch 744/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 6.1697 - val_loss: 711.7539\n",
      "Epoch 745/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 6.1495 - val_loss: 712.2220\n",
      "Epoch 746/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 6.3116 - val_loss: 715.6804\n",
      "Epoch 747/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 6.1698 - val_loss: 714.2693\n",
      "Epoch 748/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 6.1267 - val_loss: 713.4332\n",
      "Epoch 749/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 6.2355 - val_loss: 714.4299\n",
      "Epoch 750/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 2.962 - 0s 7ms/step - loss: 6.2803 - val_loss: 714.3886\n",
      "Epoch 751/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 6.1070 - val_loss: 714.8994\n",
      "Epoch 752/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 6.0676 - val_loss: 715.1588\n",
      "Epoch 753/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 6.1180 - val_loss: 715.0188\n",
      "Epoch 754/1000\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 6.1054 - val_loss: 716.5699\n",
      "Epoch 755/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 6.0714 - val_loss: 715.9529\n",
      "Epoch 756/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 6.0370 - val_loss: 717.8677\n",
      "Epoch 757/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 6.1391 - val_loss: 716.2504\n",
      "Epoch 758/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 6.1528 - val_loss: 719.2276\n",
      "Epoch 759/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 6.1712 - val_loss: 718.3529\n",
      "Epoch 760/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 6.0479 - val_loss: 718.6741\n",
      "Epoch 761/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 6.0647 - val_loss: 720.2297\n",
      "Epoch 762/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 6.0903 - val_loss: 719.5070\n",
      "Epoch 763/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 6.2233 - val_loss: 724.1321\n",
      "Epoch 764/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 6.1443 - val_loss: 713.4460\n",
      "Epoch 765/1000\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 6.1570 - val_loss: 722.9121\n",
      "Epoch 766/1000\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 6.3000 - val_loss: 718.3730\n",
      "Epoch 767/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 6.1068 - val_loss: 720.7642\n",
      "Epoch 768/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 5.9716 - val_loss: 718.7465\n",
      "Epoch 769/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 5.9550 - val_loss: 723.3282\n",
      "Epoch 770/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 5.9324 - val_loss: 720.2155\n",
      "Epoch 771/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 5.9737 - val_loss: 722.1052\n",
      "Epoch 772/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 5.9603 - val_loss: 722.5883\n",
      "Epoch 773/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 5.9849 - val_loss: 721.1160\n",
      "Epoch 774/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 5.9877 - val_loss: 724.3071\n",
      "Epoch 775/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 5.9065 - val_loss: 720.6937\n",
      "Epoch 776/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 6.0701 - val_loss: 722.9861\n",
      "Epoch 777/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 5.9219 - val_loss: 721.5516\n",
      "Epoch 778/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 2.178 - 0s 6ms/step - loss: 5.9893 - val_loss: 725.6251\n",
      "Epoch 779/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 6.0209 - val_loss: 723.7296\n",
      "Epoch 780/1000\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 5.9193 - val_loss: 722.3680\n",
      "Epoch 781/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 5.8360 - val_loss: 724.7733\n",
      "Epoch 782/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 6.0507 - val_loss: 724.7576\n",
      "Epoch 783/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 5.8950 - val_loss: 722.7670\n",
      "Epoch 784/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 5.8329 - val_loss: 724.0972\n",
      "Epoch 785/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 5.8375 - val_loss: 724.2625\n",
      "Epoch 786/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 5.8455 - val_loss: 722.8387\n",
      "Epoch 787/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 5.9011 - val_loss: 726.0935\n",
      "Epoch 788/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 6.0558 - val_loss: 723.2236\n",
      "Epoch 789/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 7.570 - 0s 6ms/step - loss: 5.8149 - val_loss: 730.1395\n",
      "Epoch 790/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 5.9141 - val_loss: 727.3528\n",
      "Epoch 791/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 5.8386 - val_loss: 730.1714\n",
      "Epoch 792/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 8ms/step - loss: 5.9037 - val_loss: 729.2621\n",
      "Epoch 793/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 5.7948 - val_loss: 729.4286\n",
      "Epoch 794/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 5.7542 - val_loss: 728.3315\n",
      "Epoch 795/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 5.8723 - val_loss: 730.0951\n",
      "Epoch 796/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 5.7450 - val_loss: 728.7808\n",
      "Epoch 797/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 5.8263 - val_loss: 728.5262\n",
      "Epoch 798/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 5.8103 - val_loss: 728.5910\n",
      "Epoch 799/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 5.7197 - val_loss: 728.8879\n",
      "Epoch 800/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 5.6761 - val_loss: 730.6088\n",
      "Epoch 801/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 5.6930 - val_loss: 730.1221\n",
      "Epoch 802/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 5.6472 - val_loss: 730.3684\n",
      "Epoch 803/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 5.6337 - val_loss: 730.4115\n",
      "Epoch 804/1000\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 5.7017 - val_loss: 732.0187\n",
      "Epoch 805/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 5.6752 - val_loss: 730.0202\n",
      "Epoch 806/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 5.7171 - val_loss: 731.3837\n",
      "Epoch 807/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 5.8118 - val_loss: 732.6074\n",
      "Epoch 808/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 5.6084 - val_loss: 731.6237\n",
      "Epoch 809/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 5.6181 - val_loss: 731.8223\n",
      "Epoch 810/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 5.7047 - val_loss: 733.1471\n",
      "Epoch 811/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 5.6111 - val_loss: 732.3737\n",
      "Epoch 812/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 5.6442 - val_loss: 732.7736\n",
      "Epoch 813/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 5.6595 - val_loss: 730.7708\n",
      "Epoch 814/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 5.5976 - val_loss: 733.3948\n",
      "Epoch 815/1000\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 5.5794 - val_loss: 733.5112\n",
      "Epoch 816/1000\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 5.5665 - val_loss: 735.5386\n",
      "Epoch 817/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 5.6334 - val_loss: 733.2547\n",
      "Epoch 818/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 5.5948 - val_loss: 736.1453\n",
      "Epoch 819/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 5.5204 - val_loss: 734.2803\n",
      "Epoch 820/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 5.5601 - val_loss: 737.3600\n",
      "Epoch 821/1000\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 5.7131 - val_loss: 737.3997\n",
      "Epoch 822/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 5.5288 - val_loss: 738.1624\n",
      "Epoch 823/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 5.5957 - val_loss: 737.7144\n",
      "Epoch 824/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.466 - 0s 6ms/step - loss: 5.4992 - val_loss: 736.1854\n",
      "Epoch 825/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 5.4933 - val_loss: 738.0535\n",
      "Epoch 826/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 5.5060 - val_loss: 738.0192\n",
      "Epoch 827/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 5.6055 - val_loss: 738.3284\n",
      "Epoch 828/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 5.5345 - val_loss: 736.0674\n",
      "Epoch 829/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 5.4462 - val_loss: 738.0685\n",
      "Epoch 830/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 5.5430 - val_loss: 736.4218\n",
      "Epoch 831/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 5.4608 - val_loss: 739.3082\n",
      "Epoch 832/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 5.6416 - val_loss: 735.9631\n",
      "Epoch 833/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 5.4692 - val_loss: 739.4211\n",
      "Epoch 834/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 5.4667 - val_loss: 737.8761\n",
      "Epoch 835/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 5.5522 - val_loss: 740.3174\n",
      "Epoch 836/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 5.4593 - val_loss: 739.3346\n",
      "Epoch 837/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 5.3847 - val_loss: 739.7200\n",
      "Epoch 838/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 5.3952 - val_loss: 739.5311\n",
      "Epoch 839/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 5.4129 - val_loss: 738.5549\n",
      "Epoch 840/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 5.4098 - val_loss: 743.5526\n",
      "Epoch 841/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 5.5495 - val_loss: 743.0086\n",
      "Epoch 842/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 5.4578 - val_loss: 741.5969\n",
      "Epoch 843/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 5.3863 - val_loss: 742.6328\n",
      "Epoch 844/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 5.3974 - val_loss: 739.8838\n",
      "Epoch 845/1000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 5.3425 - val_loss: 742.4087\n",
      "Epoch 846/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 5.3883 - val_loss: 740.1157\n",
      "Epoch 847/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 5.4021 - val_loss: 742.5688\n",
      "Epoch 848/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 5.3685 - val_loss: 739.7732\n",
      "Epoch 849/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 5.4409 - val_loss: 743.7455\n",
      "Epoch 850/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 5.4002 - val_loss: 747.5446\n",
      "Epoch 851/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 5.3754 - val_loss: 745.9957\n",
      "Epoch 852/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 5.4442 - val_loss: 746.4814\n",
      "Epoch 853/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 5.3479 - val_loss: 746.1986\n",
      "Epoch 854/1000\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 5.3858 - val_loss: 747.2382\n",
      "Epoch 855/1000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 5.2646 - val_loss: 746.1445\n",
      "Epoch 856/1000\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 5.2724 - val_loss: 747.6684\n",
      "Epoch 857/1000\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 5.3213 - val_loss: 746.3885\n",
      "Epoch 858/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 5.2724 - val_loss: 746.3869\n",
      "Epoch 859/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 5.3696 - val_loss: 743.9957\n",
      "Epoch 860/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 5.2721 - val_loss: 746.6939\n",
      "Epoch 861/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 5.2541 - val_loss: 745.9820\n",
      "Epoch 862/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 5.2246 - val_loss: 748.1743\n",
      "Epoch 863/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 5.2406 - val_loss: 748.2863\n",
      "Epoch 864/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 2.438 - 0s 6ms/step - loss: 5.3257 - val_loss: 750.1345\n",
      "Epoch 865/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 5.2047 - val_loss: 750.4482\n",
      "Epoch 866/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 5.2140 - val_loss: 749.1976\n",
      "Epoch 867/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 5.3167 - val_loss: 746.9869\n",
      "Epoch 868/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 5.1613 - val_loss: 750.1620\n",
      "Epoch 869/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 5.1749 - val_loss: 747.9983\n",
      "Epoch 870/1000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 5.1498 - val_loss: 750.8838\n",
      "Epoch 871/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 5.1450 - val_loss: 750.2325\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 872/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 5.2808 - val_loss: 751.6630\n",
      "Epoch 873/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 5.2036 - val_loss: 749.1241\n",
      "Epoch 874/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 5.3636 - val_loss: 752.8690\n",
      "Epoch 875/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 5.1332 - val_loss: 753.6144\n",
      "Epoch 876/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 5.1515 - val_loss: 751.7013\n",
      "Epoch 877/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 5.1404 - val_loss: 753.9838\n",
      "Epoch 878/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 5.2240 - val_loss: 750.5113\n",
      "Epoch 879/1000\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 5.1863 - val_loss: 751.6108\n",
      "Epoch 880/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 5.3131 - val_loss: 751.7664\n",
      "Epoch 881/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 5.1248 - val_loss: 753.7845\n",
      "Epoch 882/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 5.0871 - val_loss: 753.7679\n",
      "Epoch 883/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 5.1271 - val_loss: 754.0409\n",
      "Epoch 884/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 5.0643 - val_loss: 754.0358\n",
      "Epoch 885/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 5.1821 - val_loss: 755.4051\n",
      "Epoch 886/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 5.0764 - val_loss: 753.8426\n",
      "Epoch 887/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 5.0456 - val_loss: 757.3939\n",
      "Epoch 888/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 5.1048 - val_loss: 756.7141\n",
      "Epoch 889/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 5.4317 - val_loss: 756.3432\n",
      "Epoch 890/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 5.0128 - val_loss: 755.5540\n",
      "Epoch 891/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 5.0979 - val_loss: 756.7363\n",
      "Epoch 892/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 5.0082 - val_loss: 756.8887\n",
      "Epoch 893/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 5.0034 - val_loss: 758.7429\n",
      "Epoch 894/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 4.9835 - val_loss: 757.3713\n",
      "Epoch 895/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 5.0887 - val_loss: 755.8309\n",
      "Epoch 896/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 4.9602 - val_loss: 758.1823\n",
      "Epoch 897/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 5.0827 - val_loss: 756.7533\n",
      "Epoch 898/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 4.9828 - val_loss: 756.6205\n",
      "Epoch 899/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 4.9508 - val_loss: 757.8640\n",
      "Epoch 900/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 4.9642 - val_loss: 758.3710\n",
      "Epoch 901/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 4.9723 - val_loss: 756.8672\n",
      "Epoch 902/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 4.9351 - val_loss: 760.9407\n",
      "Epoch 903/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 4.9794 - val_loss: 759.1453\n",
      "Epoch 904/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 5.0012 - val_loss: 759.4493\n",
      "Epoch 905/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 5.0273 - val_loss: 762.0828\n",
      "Epoch 906/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 4.8972 - val_loss: 760.7136\n",
      "Epoch 907/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 5.0431 - val_loss: 761.2135\n",
      "Epoch 908/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 4.8950 - val_loss: 759.3277\n",
      "Epoch 909/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 5.0057 - val_loss: 760.4614\n",
      "Epoch 910/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 4.9250 - val_loss: 762.8165\n",
      "Epoch 911/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 5.1504 - val_loss: 762.8593\n",
      "Epoch 912/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 4.8884 - val_loss: 762.2028\n",
      "Epoch 913/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 4.8942 - val_loss: 759.1310\n",
      "Epoch 914/1000\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 4.9265 - val_loss: 763.2007\n",
      "Epoch 915/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 4.8808 - val_loss: 761.7911\n",
      "Epoch 916/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 4.8431 - val_loss: 763.9333\n",
      "Epoch 917/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 5.0276 - val_loss: 760.5065\n",
      "Epoch 918/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 4.9116 - val_loss: 763.0039\n",
      "Epoch 919/1000\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 4.8536 - val_loss: 763.5273\n",
      "Epoch 920/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 4.9276 - val_loss: 765.8534\n",
      "Epoch 921/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 4.9217 - val_loss: 765.9140\n",
      "Epoch 922/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 4.9647 - val_loss: 763.3549\n",
      "Epoch 923/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 4.8035 - val_loss: 765.5913\n",
      "Epoch 924/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 4.8414 - val_loss: 765.4457\n",
      "Epoch 925/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 4.8180 - val_loss: 767.1144\n",
      "Epoch 926/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 4.9204 - val_loss: 764.1880\n",
      "Epoch 927/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 4.8118 - val_loss: 766.4972\n",
      "Epoch 928/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 4.8523 - val_loss: 769.0446\n",
      "Epoch 929/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 4.9080 - val_loss: 767.5038\n",
      "Epoch 930/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 4.8535 - val_loss: 765.4575\n",
      "Epoch 931/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 4.7605 - val_loss: 767.3592\n",
      "Epoch 932/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 4.7385 - val_loss: 766.8107\n",
      "Epoch 933/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 4.8390 - val_loss: 764.8658\n",
      "Epoch 934/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 4.7523 - val_loss: 769.5865\n",
      "Epoch 935/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 4.8189 - val_loss: 766.0370\n",
      "Epoch 936/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 4.7745 - val_loss: 770.0782\n",
      "Epoch 937/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 4.7325 - val_loss: 768.2309\n",
      "Epoch 938/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 9.625 - 0s 2ms/step - loss: 4.7387 - val_loss: 769.1496\n",
      "Epoch 939/1000\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 4.8889 - val_loss: 768.6422\n",
      "Epoch 940/1000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 4.7399 - val_loss: 772.3923\n",
      "Epoch 941/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 4.7698 - val_loss: 769.9596\n",
      "Epoch 942/1000\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 4.7750 - val_loss: 767.4113\n",
      "Epoch 943/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 4.8242 - val_loss: 769.4342\n",
      "Epoch 944/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 4.7475 - val_loss: 771.2883\n",
      "Epoch 945/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 4.8886 - val_loss: 768.8232\n",
      "Epoch 946/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 4.7117 - val_loss: 771.5198\n",
      "Epoch 947/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 4.7243 - val_loss: 767.6546\n",
      "Epoch 948/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 4.7475 - val_loss: 772.2684\n",
      "Epoch 949/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 4.7236 - val_loss: 773.5800\n",
      "Epoch 950/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 4.7462 - val_loss: 773.9355\n",
      "Epoch 951/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 4.7134 - val_loss: 771.4288\n",
      "Epoch 952/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 7ms/step - loss: 4.6776 - val_loss: 771.6894\n",
      "Epoch 953/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 4.7166 - val_loss: 772.5093\n",
      "Epoch 954/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 4.6243 - val_loss: 773.7936\n",
      "Epoch 955/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 4.6085 - val_loss: 775.7777\n",
      "Epoch 956/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 4.6811 - val_loss: 773.7304\n",
      "Epoch 957/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 4.6553 - val_loss: 771.9727\n",
      "Epoch 958/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 4.6864 - val_loss: 773.7392\n",
      "Epoch 959/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 4.6711 - val_loss: 774.7418\n",
      "Epoch 960/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 4.6474 - val_loss: 771.7485\n",
      "Epoch 961/1000\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 4.6584 - val_loss: 775.2374\n",
      "Epoch 962/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 4.6707 - val_loss: 772.5999\n",
      "Epoch 963/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 4.6884 - val_loss: 774.1343\n",
      "Epoch 964/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 4.5604 - val_loss: 774.1777\n",
      "Epoch 965/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 4.5857 - val_loss: 775.7686\n",
      "Epoch 966/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 4.6160 - val_loss: 776.7197\n",
      "Epoch 967/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 4.7394 - val_loss: 775.5508\n",
      "Epoch 968/1000\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 4.5497 - val_loss: 775.7947\n",
      "Epoch 969/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 4.6404 - val_loss: 778.0525\n",
      "Epoch 970/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 4.6047 - val_loss: 776.9852\n",
      "Epoch 971/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 4.5485 - val_loss: 775.6700\n",
      "Epoch 972/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 4.5178 - val_loss: 776.8476\n",
      "Epoch 973/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 4.5906 - val_loss: 776.1301\n",
      "Epoch 974/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 4.6064 - val_loss: 779.0590\n",
      "Epoch 975/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 4.5643 - val_loss: 777.0167\n",
      "Epoch 976/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 4.5541 - val_loss: 778.5238\n",
      "Epoch 977/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 4.5864 - val_loss: 779.5500\n",
      "Epoch 978/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 4.5222 - val_loss: 778.7211\n",
      "Epoch 979/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 4.4689 - val_loss: 777.7584\n",
      "Epoch 980/1000\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 4.5117 - val_loss: 777.1819\n",
      "Epoch 981/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 4.5054 - val_loss: 777.3274\n",
      "Epoch 982/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 4.4771 - val_loss: 779.5592\n",
      "Epoch 983/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 4.4481 - val_loss: 778.6285\n",
      "Epoch 984/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 4.4855 - val_loss: 781.5506\n",
      "Epoch 985/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 4.4453 - val_loss: 781.1036\n",
      "Epoch 986/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 4.109 - 0s 6ms/step - loss: 4.5077 - val_loss: 781.4709\n",
      "Epoch 987/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 4.4388 - val_loss: 781.7016\n",
      "Epoch 988/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 2.642 - 0s 7ms/step - loss: 4.4271 - val_loss: 779.3314\n",
      "Epoch 989/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 4.4094 - val_loss: 781.1943\n",
      "Epoch 990/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 4.4355 - val_loss: 780.5623\n",
      "Epoch 991/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 4.5840 - val_loss: 782.1133\n",
      "Epoch 992/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 4.4379 - val_loss: 780.9019\n",
      "Epoch 993/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 4.5015 - val_loss: 780.4498\n",
      "Epoch 994/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 4.4857 - val_loss: 784.9894\n",
      "Epoch 995/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 4.4444 - val_loss: 780.4005\n",
      "Epoch 996/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 4.3862 - val_loss: 782.6938\n",
      "Epoch 997/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 4.4007 - val_loss: 780.3223\n",
      "Epoch 998/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 4.3796 - val_loss: 783.7496\n",
      "Epoch 999/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 4.3683 - val_loss: 783.0491\n",
      "Epoch 1000/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 4.4061 - val_loss: 784.4399\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"mean_squared_error\", optimizer=keras.optimizers.SGD(learning_rate=1e-3))\n",
    "history = model.fit(X_train, y_train, epochs=1000, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "84c130a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "deep_predict = model.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cd4bd7ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25.013016611356576"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse = np.sqrt(625.6510)\n",
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "709e1ea2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07866630739466318"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "r2_score(y_valid,deep_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "f27847cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ARITLSHIFT</th>\n",
       "      <th>ARITLSHIFT_PORT_NUM</th>\n",
       "      <th>ARITLSHIFT_PORT_WIDTH</th>\n",
       "      <th>ARITLSHIFT_VALUE</th>\n",
       "      <th>ARITRSHIFT</th>\n",
       "      <th>ARITRSHIFT_PORT_NUM</th>\n",
       "      <th>ARITRSHIFT_PORT_WIDTH</th>\n",
       "      <th>ARITRSHIFT_VALUE</th>\n",
       "      <th>AlwaysConstructs</th>\n",
       "      <th>AssignLHSPortNum</th>\n",
       "      <th>...</th>\n",
       "      <th>QUESTIONCOLONIF</th>\n",
       "      <th>QUESTIONCOLONTHEN</th>\n",
       "      <th>REDAND</th>\n",
       "      <th>REDAOR</th>\n",
       "      <th>REDXOR</th>\n",
       "      <th>REG</th>\n",
       "      <th>REGWIDTH</th>\n",
       "      <th>UnaryOperator</th>\n",
       "      <th>WIRENUM</th>\n",
       "      <th>WIREWIDTH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>92</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>56</td>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>22</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>22</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>8202</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>68</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1088</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>43 rows × 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     ARITLSHIFT  ARITLSHIFT_PORT_NUM  ARITLSHIFT_PORT_WIDTH  ARITLSHIFT_VALUE  \\\n",
       "1             0                    0                      0                 0   \n",
       "74            0                    0                      0                 0   \n",
       "171           0                    0                      0                 0   \n",
       "195           0                    0                      0                 0   \n",
       "132           0                    0                      0                 0   \n",
       "64            0                    0                      0                 0   \n",
       "114           0                    0                      0                 0   \n",
       "106           0                    0                      0                 0   \n",
       "8             0                    0                      0                 0   \n",
       "209           0                    0                      0                 0   \n",
       "210           0                    0                      0                 0   \n",
       "82            0                    0                      0                 0   \n",
       "192           0                    0                      0                 0   \n",
       "173           0                    0                      0                 0   \n",
       "54            0                    0                      0                 0   \n",
       "203           0                    0                      0                 0   \n",
       "51            0                    0                      0                 0   \n",
       "137           0                    0                      0                 0   \n",
       "36            0                    0                      0                 0   \n",
       "62            0                    0                      0                 0   \n",
       "118           0                    0                      0                 0   \n",
       "16            0                    0                      0                 0   \n",
       "66            0                    0                      0                 0   \n",
       "120           0                    0                      0                 0   \n",
       "0             0                    0                      0                 0   \n",
       "202           0                    0                      0                 0   \n",
       "104           0                    0                      0                 0   \n",
       "174           0                    0                      0                 0   \n",
       "40            0                    0                      0                 0   \n",
       "153           0                    0                      0                 0   \n",
       "185           0                    0                      0                 0   \n",
       "43            0                    0                      0                 0   \n",
       "95            0                    0                      0                 0   \n",
       "175           0                    0                      0                 0   \n",
       "103           0                    0                      0                 0   \n",
       "124           0                    0                      0                 0   \n",
       "35            0                    0                      0                 0   \n",
       "67            0                    0                      0                 0   \n",
       "176           0                    0                      0                 0   \n",
       "157           0                    0                      0                 0   \n",
       "180           0                    0                      0                 0   \n",
       "187           0                    0                      0                 0   \n",
       "50            0                    0                      0                 0   \n",
       "\n",
       "     ARITRSHIFT  ARITRSHIFT_PORT_NUM  ARITRSHIFT_PORT_WIDTH  ARITRSHIFT_VALUE  \\\n",
       "1             0                    0                      0                 0   \n",
       "74            0                    0                      0                 0   \n",
       "171           0                    0                      0                 0   \n",
       "195           0                    0                      0                 0   \n",
       "132           0                    0                      0                 0   \n",
       "64            0                    0                      0                 0   \n",
       "114           0                    0                      0                 0   \n",
       "106           0                    0                      0                 0   \n",
       "8             7                    0                      0                28   \n",
       "209           0                    0                      0                 0   \n",
       "210           0                    0                      0                 0   \n",
       "82            0                    0                      0                 0   \n",
       "192           0                    0                      0                 0   \n",
       "173           0                    0                      0                 0   \n",
       "54            0                    0                      0                 0   \n",
       "203           0                    0                      0                 0   \n",
       "51            0                    0                      0                 0   \n",
       "137           0                    0                      0                 0   \n",
       "36            0                    0                      0                 0   \n",
       "62            0                    0                      0                 0   \n",
       "118           0                    0                      0                 0   \n",
       "16            0                    0                      0                 0   \n",
       "66            0                    0                      0                 0   \n",
       "120           0                    0                      0                 0   \n",
       "0             0                    0                      0                 0   \n",
       "202           0                    0                      0                 0   \n",
       "104           0                    0                      0                 0   \n",
       "174           0                    0                      0                 0   \n",
       "40            0                    0                      0                 0   \n",
       "153           0                    0                      0                 0   \n",
       "185           0                    0                      0                 0   \n",
       "43            0                    0                      0                 0   \n",
       "95            0                    0                      0                 0   \n",
       "175           0                    0                      0                 0   \n",
       "103           0                    0                      0                 0   \n",
       "124           0                    0                      0                 0   \n",
       "35            0                    0                      0                 0   \n",
       "67            0                    0                      0                 0   \n",
       "176           0                    0                      0                 0   \n",
       "157           0                    0                      0                 0   \n",
       "180           1                    1                      9                 1   \n",
       "187           0                    0                      0                 0   \n",
       "50            0                    0                      0                 0   \n",
       "\n",
       "     AlwaysConstructs  AssignLHSPortNum  ...  QUESTIONCOLONIF  \\\n",
       "1                   3                 3  ...                3   \n",
       "74                  1                 0  ...                0   \n",
       "171                 1                 0  ...                0   \n",
       "195                 0                 1  ...                0   \n",
       "132                 1                 0  ...                0   \n",
       "64                  1                 0  ...                0   \n",
       "114                 3                 0  ...                0   \n",
       "106                 1                 1  ...                1   \n",
       "8                   1                 7  ...                0   \n",
       "209                17                30  ...                5   \n",
       "210                 3                 5  ...                2   \n",
       "82                  0                 2  ...                0   \n",
       "192                 1                 3  ...                0   \n",
       "173                 1                 0  ...                0   \n",
       "54                  1                16  ...                0   \n",
       "203                 2                 7  ...                4   \n",
       "51                  2                 0  ...                0   \n",
       "137                 1                 0  ...                0   \n",
       "36                 19                22  ...                0   \n",
       "62                  1                 0  ...                0   \n",
       "118                 1                 0  ...                0   \n",
       "16                  0                 1  ...                0   \n",
       "66                  1                 0  ...                0   \n",
       "120                 2                11  ...                5   \n",
       "0                   2                 0  ...                0   \n",
       "202                 1                 1  ...                0   \n",
       "104                 1                 0  ...                0   \n",
       "174                 1                 0  ...                0   \n",
       "40                  2                 0  ...                0   \n",
       "153                 3                 4  ...                1   \n",
       "185                 1                 0  ...                0   \n",
       "43                  1                 0  ...                0   \n",
       "95                  1                 0  ...                0   \n",
       "175                 2                 0  ...                0   \n",
       "103                 0                 2  ...                0   \n",
       "124                 3                 0  ...                0   \n",
       "35                  2                 1  ...                0   \n",
       "67                  1                 0  ...                0   \n",
       "176                 3                 2  ...                0   \n",
       "157                 2                 0  ...                0   \n",
       "180                 2                 4  ...                0   \n",
       "187                 1                 0  ...                0   \n",
       "50                  1                 0  ...                0   \n",
       "\n",
       "     QUESTIONCOLONTHEN  REDAND  REDAOR  REDXOR  REG  REGWIDTH  UnaryOperator  \\\n",
       "1                    3       5       0       0    6        55              0   \n",
       "74                   0       1       0       0    0         0              0   \n",
       "171                  0       0       0       2    2        64              0   \n",
       "195                  0       0       0       0    0         0              0   \n",
       "132                  0       1       0       0    4        26              0   \n",
       "64                   0       0       0       0    1         1              0   \n",
       "114                  0       6       0       0    2        26              0   \n",
       "106                  1       0       0       0    3         3              0   \n",
       "8                    0       0       0       0    8        92              0   \n",
       "209                  5      35       0       0   18        63              1   \n",
       "210                  2       1       0       0    3        21              2   \n",
       "82                   0       0       0       0    0         0              0   \n",
       "192                  0       2       0       0    1        23              0   \n",
       "173                  0       0       0       0    1         8              0   \n",
       "54                   0       2       0      56    2        24              0   \n",
       "203                  4       6       0       0    3        56              0   \n",
       "51                   0       2       0       0    2        24              0   \n",
       "137                  0       1       0       0    1         1              0   \n",
       "36                   0      10       0       3   22        30              4   \n",
       "62                   0       0       0       0    1         8              0   \n",
       "118                  0       0       0       0    1         8              0   \n",
       "16                   0       2       1       0    0         0              1   \n",
       "66                   0       0       0       0    2         2              0   \n",
       "120                  5       3       0       0    2        22              0   \n",
       "0                    0       7       0       1    6        50              0   \n",
       "202                  0       0       0       0    2      8202              0   \n",
       "104                  0       0       0       0    2         2              0   \n",
       "174                  0       0       0       0    1         8              0   \n",
       "40                   0       1       0       0    2         2              0   \n",
       "153                  1       8       0       0   11        68              0   \n",
       "185                  0       0       0       0    4         6              0   \n",
       "43                   0       0       0       0    0         0              0   \n",
       "95                   0       0       0       0    1        32              0   \n",
       "175                  0       1       0       0    5        40              0   \n",
       "103                  0       1       0       1    0         0              0   \n",
       "124                  0       2       0       0    3        10              0   \n",
       "35                   0       2       1       0    4         6              0   \n",
       "67                   0       0       0       0    0         0              0   \n",
       "176                  0       8       0       0    3      1088              0   \n",
       "157                  0       0       0       0    3        24              0   \n",
       "180                  0       6       0       1    3        13              0   \n",
       "187                  0       0       0       0    2         2              0   \n",
       "50                   0       0       0       0    1         4              0   \n",
       "\n",
       "     WIRENUM  WIREWIDTH  \n",
       "1          5         50  \n",
       "74         0          0  \n",
       "171        0          0  \n",
       "195        0          0  \n",
       "132        0          0  \n",
       "64         0          0  \n",
       "114        0          0  \n",
       "106        0          0  \n",
       "8          7         90  \n",
       "209       47        194  \n",
       "210        9         24  \n",
       "82         0          0  \n",
       "192        7        103  \n",
       "173        0          0  \n",
       "54         1         16  \n",
       "203        1          1  \n",
       "51         0          0  \n",
       "137        0          0  \n",
       "36        24         24  \n",
       "62         0          0  \n",
       "118        0          0  \n",
       "16         5          5  \n",
       "66         0          0  \n",
       "120        2          2  \n",
       "0          5         29  \n",
       "202        0          0  \n",
       "104        0          0  \n",
       "174        0          0  \n",
       "40         0          0  \n",
       "153        3         49  \n",
       "185        0          0  \n",
       "43         0          0  \n",
       "95         0          0  \n",
       "175        0          0  \n",
       "103        0          0  \n",
       "124        0          0  \n",
       "35         0          0  \n",
       "67         0          0  \n",
       "176        0          0  \n",
       "157        2          9  \n",
       "180        3         19  \n",
       "187        0          0  \n",
       "50         0          0  \n",
       "\n",
       "[43 rows x 59 columns]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_valid_backup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "18499e7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "89       2.0\n",
       "209     54.0\n",
       "21      32.0\n",
       "87       1.0\n",
       "145      3.0\n",
       "28       0.0\n",
       "203    127.0\n",
       "72     276.0\n",
       "117      1.0\n",
       "11      47.0\n",
       "102     69.0\n",
       "67       1.0\n",
       "126     72.0\n",
       "48       2.0\n",
       "178     73.0\n",
       "131    104.0\n",
       "111      4.0\n",
       "149     22.0\n",
       "75      61.0\n",
       "181      4.0\n",
       "96     200.0\n",
       "143      1.0\n",
       "10      91.0\n",
       "61       4.0\n",
       "42       1.0\n",
       "68     102.0\n",
       "214     42.0\n",
       "130      3.0\n",
       "44       8.0\n",
       "190     34.0\n",
       "107     90.0\n",
       "60      20.0\n",
       "198      2.0\n",
       "47       2.0\n",
       "2      100.0\n",
       "119      4.0\n",
       "182     20.0\n",
       "33      22.0\n",
       "103      1.0\n",
       "115      0.0\n",
       "219     11.0\n",
       "62       4.0\n",
       "138      1.0\n",
       "Name: LUT, dtype: float64"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "410da835",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "140      1.0\n",
       "120     68.0\n",
       "80      14.0\n",
       "95       0.0\n",
       "109    123.0\n",
       "       ...  \n",
       "118      0.0\n",
       "17     170.0\n",
       "104      1.0\n",
       "195      0.0\n",
       "114     44.0\n",
       "Name: LUT, Length: 169, dtype: float64"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6d695f1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 4ms/step - loss: nan\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float32').",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-ae631dc3a8c5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mplot_learning_curves\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train_full\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_full\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m200\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m200\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m                         \u001b[1;31m# not shown in the book\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-1-a4e05c867e42>\u001b[0m in \u001b[0;36mplot_learning_curves\u001b[1;34m(model, X, y)\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[0my_train_predict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[0my_val_predict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m         \u001b[0mtrain_errors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmean_squared_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_predict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m         \u001b[0mval_errors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmean_squared_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val_predict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mH:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mH:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\u001b[0m in \u001b[0;36mmean_squared_error\u001b[1;34m(y_true, y_pred, sample_weight, multioutput, squared)\u001b[0m\n\u001b[0;32m    333\u001b[0m     \u001b[1;36m0.825\u001b[0m\u001b[1;33m...\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    334\u001b[0m     \"\"\"\n\u001b[1;32m--> 335\u001b[1;33m     y_type, y_true, y_pred, multioutput = _check_reg_targets(\n\u001b[0m\u001b[0;32m    336\u001b[0m         y_true, y_pred, multioutput)\n\u001b[0;32m    337\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mH:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\u001b[0m in \u001b[0;36m_check_reg_targets\u001b[1;34m(y_true, y_pred, multioutput, dtype)\u001b[0m\n\u001b[0;32m     88\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m     \u001b[0my_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 90\u001b[1;33m     \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mH:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mH:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    661\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    662\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 663\u001b[1;33m             _assert_all_finite(array,\n\u001b[0m\u001b[0;32m    664\u001b[0m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[0;32m    665\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mH:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[0;32m    101\u001b[0m                 not allow_nan and not np.isfinite(X).all()):\n\u001b[0;32m    102\u001b[0m             \u001b[0mtype_err\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'infinity'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mallow_nan\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m'NaN, infinity'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 103\u001b[1;33m             raise ValueError(\n\u001b[0m\u001b[0;32m    104\u001b[0m                     \u001b[0mmsg_err\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m                     (type_err,\n",
      "\u001b[1;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float32')."
     ]
    }
   ],
   "source": [
    "plot_learning_curves(model, X_train_full, y_train_full)\n",
    "plt.axis([0, 200, 0, 200])                         # not shown in the book\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "80d0ad85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-4.26856804e+00],\n",
       "       [ 6.14976959e+01],\n",
       "       [ 7.14575577e+01],\n",
       "       [ 1.98475468e+00],\n",
       "       [ 5.87914085e+00],\n",
       "       [ 5.88872147e+00],\n",
       "       [ 9.87386475e+01],\n",
       "       [ 3.38187134e+02],\n",
       "       [ 1.07103643e+01],\n",
       "       [ 4.65599022e+01],\n",
       "       [ 6.47305756e+01],\n",
       "       [ 1.73598111e+00],\n",
       "       [ 5.63512039e+01],\n",
       "       [ 1.87781124e+01],\n",
       "       [ 1.02937767e+02],\n",
       "       [ 5.95165443e+01],\n",
       "       [-2.63833046e+00],\n",
       "       [ 9.45659332e+01],\n",
       "       [ 7.27102585e+01],\n",
       "       [ 4.62103844e+00],\n",
       "       [ 2.21077612e+03],\n",
       "       [-1.76898277e+00],\n",
       "       [ 1.15266266e+02],\n",
       "       [ 1.36818256e+01],\n",
       "       [-1.79439914e+00],\n",
       "       [ 1.24464516e+02],\n",
       "       [ 3.08278275e+01],\n",
       "       [ 6.07139778e+00],\n",
       "       [ 3.37609787e+01],\n",
       "       [ 2.21376076e+01],\n",
       "       [ 1.62430725e+02],\n",
       "       [ 2.72856026e+01],\n",
       "       [ 1.37348976e+01],\n",
       "       [ 1.87781124e+01],\n",
       "       [ 1.26831169e+02],\n",
       "       [ 1.32390499e+01],\n",
       "       [ 1.33106308e+01],\n",
       "       [ 4.01074257e+01],\n",
       "       [ 1.92165196e+00],\n",
       "       [ 2.27660847e+00],\n",
       "       [ 3.53798904e+01],\n",
       "       [ 1.20109024e+01],\n",
       "       [ 9.93547559e-01]], dtype=float32)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict = model.predict(X_valid)\n",
    "predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "f1500aa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "89       2.0\n",
       "209     54.0\n",
       "21      32.0\n",
       "87       1.0\n",
       "145      3.0\n",
       "28       0.0\n",
       "203    127.0\n",
       "72     276.0\n",
       "117      1.0\n",
       "11      47.0\n",
       "102     69.0\n",
       "67       1.0\n",
       "126     72.0\n",
       "48       2.0\n",
       "178     73.0\n",
       "131    104.0\n",
       "111      4.0\n",
       "149     22.0\n",
       "75      61.0\n",
       "181      4.0\n",
       "96     200.0\n",
       "143      1.0\n",
       "10      91.0\n",
       "61       4.0\n",
       "42       1.0\n",
       "68     102.0\n",
       "214     42.0\n",
       "130      3.0\n",
       "44       8.0\n",
       "190     34.0\n",
       "107     90.0\n",
       "60      20.0\n",
       "198      2.0\n",
       "47       2.0\n",
       "2      100.0\n",
       "119      4.0\n",
       "182     20.0\n",
       "33      22.0\n",
       "103      1.0\n",
       "115      0.0\n",
       "219     11.0\n",
       "62       4.0\n",
       "138      1.0\n",
       "Name: LUT, dtype: float64"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "4d9a0ba2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAARkAAAEKCAYAAAAmUiEiAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAbkElEQVR4nO3de9RddX3n8feH8EAit0AJNCRBIgYwYEngEbHpWKyOQTttgoKGGVmppcRxwXgZypiIM4W1ZEkHwc7MUsdwGdKqSWOBkIqWRi5e2goECJAQUyIg5CIJYrjYEHL5zh97Hzg5Oc+5PM/5ncs+n9dazzrn7LP3Od/n9+x8sm+/31ZEYGaWyn6dLsDMis0hY2ZJOWTMLCmHjJkl5ZAxs6QcMmaWVLKQkTRa0v2SHpG0RtKV+fQjJK2Q9ET+eHjZMgskrZe0TtLMVLWZWfso1XUykgQcFBGvSBoAfgJ8GvgQ8EJEXC1pPnB4RHxO0lRgMXAGcAzwA+CEiNidpEAza4tkWzKReSV/OZD/BDALWJRPXwTMzp/PApZExI6IeApYTxY4ZtbD9k/54ZJGAQ8CbwW+GhH3STo6IjYDRMRmSUfls08Aflq2+IZ8WuVnzgPmARx00EGnn3TSSSl/BbO+9fwrO9j84qu89sv1z0fEuOF+TtKQyXd1pkkaC9wm6ZQas6vaR1T5zIXAQoDBwcFYuXJlK0o1szI3/PhJvnjHWv70lN/m/14w+IuRfFZbzi5FxDbgXuBs4DlJ4wHyxy35bBuASWWLTQQ2taM+M3tDKWA+cMpv87/Pnz7iz0t5dmlcvgWDpDHA+4CfAcuBuflsc4Hb8+fLgTmSDpQ0GZgC3J+qPjPbV2XADIwaeUSk3F0aDyzKj8vsByyNiO9K+hdgqaQLgWeA8wAiYo2kpcDjwC7gYp9ZMmufFAEDCU9ht4OPyZi1Rq2AkfRgRAwO97N9xa9Zn0u1BVPikDHrY6kDBhwyZn2rHQEDDhmzvtSugAGHjFnfaWfAgEPGrK+0O2DAIWPWNzoRMOCQMesLnQoYcMiYFV4nAwYcMmaF1umAAYeMWWF1Q8CAQ8askLolYMAhY1Y43RQw4JAxK5RuCxhwyJgVRjcGDDhkzAqhWwMGHDJmPa+bAwYcMmY9rdsDBhwyZj2rFwIGHDJmPalXAgYcMmY9p5cCBhwyZj2l1wIGHDJmPaMXAwYcMmY9oVcDBhwyZl2vlwMGHDJmXa3XAwYcMmZdqwgBAwlDRtIkSfdIWitpjaRP59OvkLRR0qr854NlyyyQtF7SOkkzU9Vm1u2KEjAA+yf87F3ApRHxkKRDgAclrcjf+0pEfLl8ZklTgTnAycAxwA8knRARuxPWaNZ1ihQwkHBLJiI2R8RD+fOXgbXAhBqLzAKWRMSOiHgKWA+ckao+s25UtICBNh2TkXQcMB24L590iaRHJd0k6fB82gTg2bLFNlA7lMwKpYgBA20IGUkHA7cAn4mIl4CvA8cD04DNwLWlWassHlU+b56klZJWbt26NU3RZm1W1ICBxCEjaYAsYL4VEbcCRMRzEbE7IvYA1/PGLtEGYFLZ4hOBTZWfGRELI2IwIgbHjRuXsnyztihywEDas0sCbgTWRsR1ZdPHl812DrA6f74cmCPpQEmTgSnA/anqM+sGRQ8YSHt2aQZwAfCYpFX5tM8D50uaRrYr9DTwCYCIWCNpKfA42Zmpi31myYqsHwIGEoZMRPyE6sdZvldjmauAq1LVZNYt+iVgwFf8mrVdPwUMOGTM2qrfAgYcMmZt048BAw4Zs7bo14ABh4xZcv0cMOCQMUuq3wMGHDJmyThgMv35W5sl5oB5Q//+5maJOGD21t+/vVmLOWD25RYwaxEHTHVuBbMWcMAMzS1hNkIOmNrcGmYj4ICpzy1iNkwOmMa4VcyGwQHTOLeMWZMcMM1x65g1wQHTPLeQWYMcMMPjVjJrgANm+NxSZnU4YEbGrWVWgwNm5NxiZkNwwLSGW82sCgdM67jlzCo4YFrLrWdWxgHTem5Bs5wDJg23ohkOmJSStaSkSZLukbRW0hpJn86nHyFphaQn8sfDy5ZZIGm9pHWSZqaqzaycAyatlK25C7g0It4GnAlcLGkqMB+4KyKmAHflr8nfmwOcDJwNfE3SqIT1mTlg2iBZi0bE5oh4KH/+MrAWmADMAhblsy0CZufPZwFLImJHRDwFrAfOSFWfmQOmPdrSqpKOA6YD9wFHR8RmyIIIOCqfbQLwbNliG/JplZ81T9JKSSu3bt2atG4rLgdM+yRvWUkHA7cAn4mIl2rNWmVa7DMhYmFEDEbE4Lhx41pVpvURB0x7JW1dSQNkAfOtiLg1n/ycpPH5++OBLfn0DcCkssUnAptS1mf9xwHTfinPLgm4EVgbEdeVvbUcmJs/nwvcXjZ9jqQDJU0GpgD3p6rP+o8DpjP2T/jZM4ALgMckrcqnfR64Glgq6ULgGeA8gIhYI2kp8DjZmamLI2J3wvqsjzhgOidZyETET6h+nAXgvUMscxVwVaqarD85YDrLrW2F5oDpPLe4FZYDpju41a2QHDDdwy1vheOA6S5ufSsUB0z3aegvIOl4SQfmz8+S9ClJY5NWZtYkB0x3avSvcAuwW9JbyS6wmwx8O1lVZk1ywHSvRv8SeyJiF3AO8FcR8VlgfLqyzBrngOlujf41dko6n6wbwHfzaQNpSjJrnAOm+zX6F/k48C7gqoh4Ku9b9M10ZZnV54DpDQ11K4iIx4FPlb1+iqwPkllHOGB6R0MhI2kGcAXw5nwZARERb0lXmll1Dpje0mgHyRuBzwIPAu4ZbR3jgOk9jYbMixHx/aSVmNXhgOlNjYbMPZKuAW4FdpQmlgYKN0vNAdO7Gg2Zd+aPg2XTAviD1pZjti8HTG9r9OzSe1IXYlaNA6b3Ndp36TBJ15VuRSLpWkmHpS7O+psDphga3V26CVgNfCR/fQHw/4APpSjKGrPs4Y1cc+c6Nm3bzjFjx3DZzBOZPX2fW1X1JAdMcTQaMsdHxIfLXl9ZNji4dcCyhzey4NbH2L4zu6Jg47btLLj1MYCeDxoHTLE0+tfbLun3Si/yi/O2pynJGnHNneteD5iS7Tt3c82d6zpUUWs4YIqn0S2ZTwKL8uMwAl4A/iRVUVbfpm3VM36o6b3AAVNMjZ5dWgWcKunQ/HWt281aGxwzdgwbqwTKMWPHdKCakXPAFFfNkJH0sYj4pqT/WjEdgIo7Q1obXTbzxL2OyQCMGRjFZTNP7GBVw+OAKbZ6WzIH5Y+HVHkvWlyLNaF0cLfXzy45YIqvZshExDfypz+IiH8qfy8/+GsdNHv6hJ4LlXIOmP7Q6F/1/zQ4zawhDpj+Ue+YzLuA3wXGVRyXORQYVWfZm4D/AGyJiFPyaVcAFwFb89k+HxHfy99bAFxINpTEpyLizqZ/G+sJDpj+Uu+vewBwMFkYHVL28xJwbp1lbwbOrjL9KxExLf8pBcxUYA5wcr7M1yTVDDHrTQ6Y/lPvmMwPgR9KujkiftHMB0fEjyQd1+Dss4AlEbEDeErSeuAM4F+a+U7rbg6Y/tToX/mG8pu5STpc0nB3Zy6R9KikmyQdnk+bADxbNs+GfNo+JM0rddTcunVrtVmsCzlg+lejf+kjI2Jb6UVE/Bo4ahjf93XgeGAasBm4Np+uKvNWPUUeEQsjYjAiBseNGzeMEqzdHDD9reGbu0k6tvRC0psZxnUyEfFcROyOiD3A9WS7RJBtuUwqm3UisKnZz7fu44CxRvsuXQ78RNIP89fvBuY1+2WSxkfE5vzlOWTDRwAsB74t6TrgGGAKcH+zn2/dxQFj0HjfpX+QdBpwJtmuzWcj4vlay0haDJwFHClpA/AXwFmSppFtBT0NfCL//DWSlgKPA7uAiyPCd0XoYQ4YK1HE0Hs9kk6KiJ/lAbOPTg8kPjg4GCtXruxkCVaFA6ZYJD0YEYP156yu3pbMpWQXz11b5T0PJG77cMBYpXrXyVyUP3ogcavLAWPV1OtWUHMM34i4tbXlWK9ywNhQ6u0u/VH+eBRZH6a789fvAe4lu9mb9TkHjNVSb3fp4wCSvgtMLZ1+ljQe+Gr68qzbOWCsnkbXiOPKrm8BeA44IUE91kMcMNaIRi/Guzfvq7SY7KzSHOCeZFVZ13PAWKMavRjvEknnkF3pC7AwIm5LV5Z1MweMNaPRLRmAh4CXI+IHkt4k6ZCIeDlVYTYyqe4u6YCxZjV6L+yLgL8DSmP+TgCWJarJRqh0d8mN27YTvHF3yWUPbxzR5zpgbDgaXUsuBmaQjYhHRDzB8IZ6sDYY6u6SV/79mmF/pgPGhqvRNWVHRLxWeiFpf3xLlK411F0kf/1vO4e1NeOAsZFodG35oaTPA2Mk/XvgO8DfpyvLRqLWXSSbvVe2A8ZGqtE15nNkdxh4jGx4hu8BX0hVlI1MrbtINnOvbAeMtULdtUbSfsBjEXF9RJwXEefmz7271KVmT5/A2DEDVd9r9F7ZDhhrlbprTj5U5iPlw29a97vij09mzMDed5Vp9F7ZDhhrpUavkxkPrJF0P/Cb0sSI+OMkVVlDal0LM9x7ZTtgrNUaDZkrk1ZhTStdC1M6VV26FgbYK2iauQDPAWMp1BtPZjTwn4G3kh30vTEidrWjMKttqGthrrlz3bCu7HXAWCr11qRFwCBZwHyA6sNwWgcMdZaombNHJQ4YS6ne7tLUiHg7gKQb8W1KusYxY8ewsUqgNHr2qMQBY6nVW6N2lp54N6m7XDbzxGGfPSpxwFg71NuSOVXSS/lzkV3x+1L+PCLi0KTV2ZCGe/aoxAFj7VJv+M1Rtd63zmr27FGJA8bayWtXn3HAWLs1M2iVJZRqkKlyDhjrBIdMF2jkwrqRcsBYpyRb0yTdJGmLpNVl046QtELSE/nj4WXvLZC0XtI6STNT1dWNal1Y1woOGOuklGvbzcDZFdPmA3dFxBTgrvw1kqaS3QHh5HyZr0nqm4POrbywrlIrAmbZwxuZcfXdTJ5/BzOuvnvEw3haf0kWMhHxI+CFismzyK4iJn+cXTZ9SUTsiIingPXAGalq6zZDXUDX7IV1lVoVMCnGC7b+0e7t5qNLN4nLH0vjBE8Ani2bb0M+bR+S5klaKWnl1q1bkxbbLq24sK5Sq3aRUu/KWfF1y4FfVZlWdVCsiFgILAQYHBwc1sBZ7TiT04yRXlhXqZXHYFLuyll/aHfIPCdpfERszu+nvSWfvgGYVDbfRGBTigLacSZnOIZ7YV2lVh/kbVUfKetf7d5dWg7MzZ/PBW4vmz5H0oGSJgNTSNQZs8ib/ynOIqXYlbP+kmxLRtJi4CzgSEkbgL8ArgaWSroQeAY4DyAi1khaCjwO7AIujojdVT94hIq6+Z/qNHWrd+Ws/yQLmYg4f4i33jvE/FcBV6Wqp6SIm/+pr4Np1a6c9ae+uyqraJv/vtDOul23nF1qmyJt/jtgrBf0XchAMTb/HTDWK7xm9iAHjPUSr509xgFjvcZraA9xwFgv8lraIxww1qu8pvYAB4z1Mq+tXc4BY73Oa2wXc8BYEXit7VIOGCuKvrwYrxOaGcPGAWNF4pCpotWDWjUzho0DxorGa3CFFGPaNjqGjQPGishrcYUUg1o1MoaNA8aKymtyhRSDWtW7G4EDxorMa3OFFLcnqTWGjQPGis5rdIUUg1rNnj6BL33o7UwYOwYBE8aO4Usfejv3rtvCF+9YC8Ajz27jjkc3j6R0s67ks0sVUg1qVTmGzWeWPMyyVW/ckGHTi692xV0TzFrNIVPFSAa1auT09w0/fnKvgCkpHWB2yFiROGRaqJHrYUrHYIbS63dNMKvkYzItVO/0d/lB3mMOG131M1LcNWHZwxuZcfXdTJ5/BzOuvtv3sba2csi0UK3T35Vnkf7b2Se15a4JKS4uNGuGQ6aFhtoKOXT0wD6nqSvPOI0dM8Dogf347N+uaunWRpHvmGm9wSHTQtVOfw/sJ158dWfV62BmT5/AP83/A77y0Wns2LWHX//bzpZvbRT1jpnWOxwyLVS5dXLY6AF27om6F9ql3NpIcXGhWTMcMi1W2jq5/A/fNuQWTKWUWxtFu2Om9Z6OnMKW9DTwMrAb2BURg5KOAP4WOA54GvhIRPy6E/WNVLNdBVLen7tId8y03tTJ62TeExHPl72eD9wVEVdLmp+//lxnShu+4fRFumzmiXtdXwOt3doowh0zrXd10+7SLGBR/nwRMLtzpQzPcDs7DtW3ycFgRdCpLZkA/lFSAN+IiIXA0RGxGSAiNks6qkO1Nay8C8GhowcaPgZTjbc2rKg6FTIzImJTHiQrJP2s0QUlzQPmARx77LGp6qursgvBi6/uZD/B+952tIdrMCvTkX8NEbEpf9wC3AacATwnaTxA/rhliGUXRsRgRAyOGzeuXSXvo9pp5z0B16341w5VZNad2h4ykg6SdEjpOfB+YDWwHJibzzYXuL3dtTXDF7mZNaYTu0tHA7dJKn3/tyPiHyQ9ACyVdCHwDHBeB2prWOkYTCVf5Ga2t7aHTEQ8CZxaZfqvgPe2o4aR3vLkhh8/+foxmD3xxnRf5Ga2r747QjnSXsnlp6mvOfdUn3Y2q6PvBq2q1U+oXkBUuw7mw6dPTFmuWc8rZMjU2h0a7gFb31XAbHgKFTLLHt7IFcvXsG37GwdkK4fAHE4/IQeM2fAV5l9L6VhLecCUlA+b0GyvZAeM2cgUZkum2rGWcqXdoWZ6JVcLmJGemTLrN4UJmXrHVMp3hxrpJzRUwNS7G4GZ7a0w2/61jqk0e/3KULtIHi/XrHmFCZlqx1oADn/TwF7Xr9S7PUitYzDuSmDWvMLsLjVyrKXe7k69g7wpR7AzK6rChAzUP9ZSa3fn+Vd21D2LlHoEO7MiKlTI1DPUbs3GbdsbOk3t8XLNmtdXITPU7g6wT8AMdaraI9iZNacwB34bMdTB4VMnHrZPwPjWrmat0dNbMhu3bef4Bd9jdwSjJM5/5yS+OPvtQ85fvrtT2qI5deJh/N0nf3evXaSRdKI0s7319JbMC795jd2RDeiyO4Jv/vQZvrDssZrLzJ4+gY/POA7IdpEqAwZ8qtqslXo6ZKpZfN+zNd9vpC+Sb+1q1jqFC5nSlk01jXZ29K1dzVqnp4/JNKMUMKdOPIxHnt3GCZd/f8hT0D5VbdY6ihr/83e7A8dPifFz/2qf6R8789i9DgCXB8y6X77Mq7v2vP7emIFRHjbTrAZJD0bE4HCXL9zuEsC3fvrM68/Ld5G2vrxjr4ABd3A0S62QIVPaNqs8BrP5xVerzu+zRmbpFDJkoPpBXp81Mmu/QobMAaNU9SySzxqZtV8hzy69tjuqnqb2WSOz9itkyFT2RSrnDo5m7VXI3aWtL+/wXQXMukQh/yUOdRbJzNqv60JG0tmS1klaL2n+cD7DZ4vMukdXhYykUcBXgQ8AU4HzJU1t5jMGRslni8y6SFeFDHAGsD4inoyI14AlwKxmPuCj75jkA7tmXaSr+i5JOhc4OyL+LH99AfDOiLikbJ55wDwARu1/+gHjjtv7QyL27Hpp6y/2bH/phTaVXelI4PkOfXc1rqe2bqsHuq+mEyPikOEu3G2nsFVl2l4pGBELgYUAklbu2PzEsDtupSBp5Ug6k7Wa66mt2+qB7qtJ0sqRLN9tu0sbgEllrycCmzpUi5m1QLeFzAPAFEmTJR0AzAGWd7gmMxuBrtpdiohdki4B7gRGATdFxJoaiyxsT2VN6baaXE9t3VYPdF9NI6qnqw78mlnxdNvukpkVjEPGzJLq2ZBpRfeDFtTwtKTHJK0qneaTdISkFZKeyB8PT/j9N0naIml12bQhv1/Sgry91kma2caarpC0MW+nVZI+2I6aJE2SdI+ktZLWSPp0Pr1jbVSjpk610WhJ90t6JK/nynx669ooInruh+yg8M+BtwAHAI8AUztQx9PAkRXT/icwP38+H/jLhN//buA0YHW97yfrpvEIcCAwOW+/UW2q6Qrgz6vMm7QmYDxwWv78EOBf8+/sWBvVqKlTbSTg4Pz5AHAfcGYr26hXt2RG3P0goVnAovz5ImB2qi+KiB8BlVc2D/X9s4AlEbEjIp4C1pO1YztqGkrSmiJic0Q8lD9/GVgLTKCDbVSjpqGkbqOIiFfylwP5T9DCNurVkJkAlN8qcgO1/1CpBPCPkh7MuzsAHB0RmyFboYCj2lzTUN/f6Ta7RNKj+e5UadO7bTVJOg6YTvY/dVe0UUVN0KE2kjRK0ipgC7AiIlraRr0aMnW7H7TJjIg4jazX+MWS3t2BGhrVyTb7OnA8MA3YDFzbzpokHQzcAnwmIl6qNWs76hmipo61UUTsjohpZFfYnyHplBqzN11Pr4ZMV3Q/iIhN+eMW4DayzcbnJI0HyB+3tLmsob6/Y20WEc/lK/Ie4Hre2LxOXpOkAbJ/zN+KiFvzyR1to2o1dbKNSiJiG3AvcDYtbKNeDZmOdz+QdJCkQ0rPgfcDq/M65uazzQVub2ddNb5/OTBH0oGSJgNTgPvbUVBpZc2dQ9ZOyWuSJOBGYG1EXFf2VsfaaKiaOthG4ySNzZ+PAd4H/IxWtlErj5y38wf4INmR+Z8Dl3fg+99CdpT9EWBNqQbgt4C7gCfyxyMS1rCYbNN6J9n/MBfW+n7g8ry91gEfaGNNfwM8Bjyar6Tj21ET8Htkm/KPAqvynw92so1q1NSpNvod4OH8e1cD/6PeetxsPe5WYGZJ9erukpn1CIeMmSXlkDGzpBwyZpaUQ8bMknLI9DFJv1XW6/eXFb2AD2jB518h6UsV06ZJWltnmT8f6Xdb9+iq4TetvSLiV2SXsSPpCuCViPhy6X1J+0fErhF8xWLg+8CCsmlzgG+P4DOtx3hLxvYi6WZJ10m6B/jLyi0LSavzjn1I+lg+FskqSd9QdgfQ10XEOmCbpHeWTf4IsETSRZIeyMcxuUXSm6rUcq+kwfz5kZKezp+PknRNvvyjkj6RTx8v6Ud5Pasl/bvWto4Nh0PGqjkBeF9EXDrUDJLeBnyUrJPoNGA38J+qzLqYbOsFSWcCv4qIJ4BbI+IdEXEq2XAHFzZR34XAixHxDuAdwEX5Je7/Ebgzr+dUsqtprcO8u2TVfCcidteZ573A6cADWXccxlC9M+gS4J8lXUoWNovz6adI+iIwFjiY7A4VjXo/8DvK7jgKcBhZH5oHgJvyDojLImJVE59piThkrJrflD3fxd5bvKPzRwGLIqL8eMs+IuLZfDfn94EPA+/K37oZmB0Rj0j6E+CsKouXf/fosukC/ktE7BNM+XAbfwj8jaRrIuKva9Vn6Xl3yep5mmw4TSSdRjbkImSd5s6VdFT+3hGS3jzEZywGvgL8PCI25NMOATbnWx3VdrNK3316/vzcsul3Ap/Ml0XSCXmv+DcDWyLierKezqc184taGg4Zq+cW4Ih85LRPkvV8JyIeB75ANjLgo8AKsvFrq/kOcDLZrlPJfycbEW4F2dAC1XyZLEz+mewm9CU3AI8DDykbsPwbZFvlZwGrJD1MttX0v5r5RS0N98I2s6S8JWNmSTlkzCwph4yZJeWQMbOkHDJmlpRDxsyScsiYWVL/H4KiqtA+qHH3AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEGCAYAAABiq/5QAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAQ9ElEQVR4nO3df6xkZX3H8ffH5YdWUNlyIRskXVRqJLQu9EoRlOLPIv4BNGokja4N7WorRvyVbPUPaf/CFn+ktYGsQlgMYlAhYLEiXRG0oeCFLLC4IqhokQ17lVawNVrWb/+Ys/Vy793d2eWemd153q9kMmeeec4533ky+9lzz5x5JlWFJKkdTxt3AZKk0TL4JakxBr8kNcbgl6TGGPyS1Jj9xl3AMA499NBauXLluMuQpH3KHXfc8ZOqmprfvk8E/8qVK5mZmRl3GZK0T0nyw8XaPdUjSY0x+CWpMQa/JDXG4Jekxhj8ktQYg1+SGmPwS1JjDH5JaozBL0mN2Se+uftUrFx7/VD9Hrzg9T1XIkl7B4/4JakxBr8kNcbgl6TGGPyS1BiDX5IaY/BLUmMMfklqjMEvSY3pLfiTPD3J7UnuSnJvkr/p2pcnuTHJ/d39IX3VIElaqM8j/l8Cr6yqFwOrgNOSnAisBTZU1dHAhu6xJGlEegv+Gvh593D/7lbAGcD6rn09cGZfNUiSFur1HH+SZUk2AluBG6vqNuDwqtoC0N0f1mcNkqQn6zX4q2pbVa0CnguckOTYYddNsibJTJKZ2dnZ3mqUpNaM5Kqeqvov4OvAacAjSVYAdPdbd7DOuqqarqrpqampUZQpSU3o86qeqSTP6ZafAbwa+A5wHbC667YauLavGiRJC/U5H/8KYH2SZQz+g7mqqv45ya3AVUnOAX4EvLHHGiRJ8/QW/FV1N3DcIu0/BV7V134lSTvnN3clqTEGvyQ1xuCXpMYY/JLUGINfkhpj8EtSYwx+SWqMwS9JjTH4JakxBr8kNcbgl6TGGPyS1BiDX5IaY/BLUmMMfklqjMEvSY0x+CWpMQa/JDXG4Jekxhj8ktQYg1+SGmPwS1JjDH5JaozBL0mN6S34kxyZ5KYkm5Pcm+TdXfv5SX6cZGN3O72vGiRJC+3X47afAN5XVXcmORi4I8mN3XMfr6oLe9y3JGkHegv+qtoCbOmWH0+yGTiir/1JkoYzknP8SVYCxwG3dU3nJrk7yaVJDtnBOmuSzCSZmZ2dHUWZktSE3oM/yUHAF4Hzquox4CLg+cAqBn8RfHSx9apqXVVNV9X01NRU32VKUjN6Df4k+zMI/Suq6mqAqnqkqrZV1a+BTwEn9FmDJOnJ+ryqJ8AlwOaq+tic9hVzup0FbOqrBknSQn1e1XMy8BbgniQbu7YPAmcnWQUU8CDw9h5rkCTN0+dVPd8EsshTX+5rn5KkXfObu5LUGINfkhpj8EtSYwx+SWqMwS9JjTH4JakxBr8kNcbgl6TGGPyS1BiDX5IaY/BLUmMMfklqjMEvSY0x+CWpMQa/JDXG4Jekxhj8ktQYg1+SGmPwS1JjDH5JaozBL0mNMfglqTEGvyQ1prfgT3JkkpuSbE5yb5J3d+3Lk9yY5P7u/pC+apAkLdTnEf8TwPuq6kXAicA7kxwDrAU2VNXRwIbusSRpRHoL/qraUlV3dsuPA5uBI4AzgPVdt/XAmX3VIElaaCTn+JOsBI4DbgMOr6otMPjPAThsB+usSTKTZGZ2dnYUZUpSE3oP/iQHAV8Ezquqx4Zdr6rWVdV0VU1PTU31V6AkNabX4E+yP4PQv6Kqru6aH0myont+BbC1zxokSU/W51U9AS4BNlfVx+Y8dR2wulteDVzbVw2SpIX263HbJwNvAe5JsrFr+yBwAXBVknOAHwFv7LEGSdI8vQV/VX0TyA6eflVf+5Uk7Zzf3JWkxhj8ktQYg1+SGjNU8Cc5eZg2SdLeb9gj/n8csk2StJfb6VU9SV4KnARMJXnvnKeeBSzrszBJUj92dTnnAcBBXb+D57Q/Bryhr6IkSf3ZafBX1c3AzUkuq6ofjqgmSVKPhv0C14FJ1gEr565TVa/soyhJUn+GDf7PAxcDnwa29VeOJKlvwwb/E1V1Ua+VSJJGYtjLOb+U5K+SrOh+M3d5kuW9ViZJ6sWwR/zbp1H+wJy2Ap63tOVIkvo2VPBX1VF9FyJJGo2hgj/JWxdrr6rLl7YcSVLfhj3V85I5y09nMJ/+nYDBL0n7mGFP9bxr7uMkzwY+00tFkqRe7em0zP8DHL2UhUiSRmPYc/xfYnAVDwwmZ3sRcFVfRUmS+jPsOf4L5yw/Afywqh7qoR5JUs+GOtXTTdb2HQYzdB4C/KrPoiRJ/Rn2F7jeBNwOvBF4E3BbEqdllqR90LCnej4EvKSqtgIkmQL+FfhCX4VJkvox7FU9T9se+p2f7sa6kqS9yLDh/ZUkNyR5W5K3AdcDX97ZCkkuTbI1yaY5becn+XGSjd3t9D0vXZK0J3b1m7svAA6vqg8k+RPgZUCAW4ErdrHty4BPsvDbvR+vqgsXdpckjcKujvg/ATwOUFVXV9V7q+o9DI72P7GzFavqFuDRJahRkrSEdhX8K6vq7vmNVTXD4GcY98S5Se7uTgUdsqNOSdYkmUkyMzs7u4e7kiTNt6vgf/pOnnvGHuzvIuD5wCpgC/DRHXWsqnVVNV1V01NTU3uwK0nSYnYV/N9K8hfzG5OcA9yxuzurqkeqaltV/Rr4FHDC7m5DkvTU7Oo6/vOAa5L8Kb8J+mngAOCs3d1ZkhVVtaV7eBawaWf9JUlLb6fBX1WPACcleQVwbNd8fVV9bVcbTnIlcCpwaJKHgA8DpyZZxWDCtweBt+9x5ZKkPTLsfPw3ATftzoar6uxFmi/ZnW1Ikpae376VpMYY/JLUGINfkhpj8EtSYwx+SWqMwS9JjTH4JakxBr8kNcbgl6TGGPyS1BiDX5IaY/BLUmMMfklqjMEvSY0x+CWpMQa/JDXG4Jekxhj8ktQYg1+SGmPwS1JjDH5JaozBL0mNMfglqTG9BX+SS5NsTbJpTtvyJDcmub+7P6Sv/UuSFtfnEf9lwGnz2tYCG6rqaGBD91iSNEK9BX9V3QI8Oq/5DGB9t7weOLOv/UuSFjfqc/yHV9UWgO7+sB11TLImyUySmdnZ2ZEVKEmTbq/9cLeq1lXVdFVNT01NjbscSZoYow7+R5KsAOjut454/5LUvFEH/3XA6m55NXDtiPcvSc3r83LOK4FbgRcmeSjJOcAFwGuS3A+8pnssSRqh/fracFWdvYOnXtXXPiVJu7bXfrgrSeqHwS9JjTH4JakxBr8kNcbgl6TGGPyS1BiDX5Ia09t1/PualWuvH6rfgxe8vudKJKlfHvFLUmMMfklqjMEvSY0x+CWpMQa/JDXG4Jekxhj8ktQYg1+SGmPwS1JjDH5JaozBL0mNMfglqTEGvyQ1xuCXpMYY/JLUmLHMx5/kQeBxYBvwRFVNj6MOSWrROH+I5RVV9ZMx7l+SmuSpHklqzLiCv4CvJrkjyZrFOiRZk2Qmyczs7OyIy5OkyTWu4D+5qo4HXge8M8kp8ztU1bqqmq6q6ampqdFXKEkTaizBX1UPd/dbgWuAE8ZRhyS1aOTBn+SZSQ7evgy8Ftg06jokqVXjuKrncOCaJNv3/9mq+soY6pCkJo08+Kvq+8CLR71fSdKAl3NKUmMMfklqjMEvSY0x+CWpMQa/JDXG4Jekxhj8ktQYg1+SGmPwS1JjDH5JaozBL0mNMfglqTEGvyQ1xuCXpMYY/JLUGINfkhpj8EtSYwx+SWqMwS9JjTH4JakxI/+x9X3dyrXXD933wQtev6TbHHZ7kvZufeTI7vCIX5IaY/BLUmMMfklqzFiCP8lpSe5L8kCSteOoQZJaNfLgT7IM+CfgdcAxwNlJjhl1HZLUqnEc8Z8APFBV36+qXwGfA84YQx2S1KRxXM55BPAfcx4/BPzh/E5J1gBruoc/T3LfU9jnocBPnsL6eyQf2Wu3N5bx2Ms5Jgs5JguNfEye4r/731mscRzBn0XaakFD1Tpg3ZLsMJmpquml2NYkcDwWckwWckwWmpQxGcepnoeAI+c8fi7w8BjqkKQmjSP4vwUcneSoJAcAbwauG0MdktSkkZ/qqaonkpwL3AAsAy6tqnt73u2SnDKaII7HQo7JQo7JQhMxJqlacHpdkjTB/OauJDXG4Jekxkx08Lc8NUSSB5Pck2RjkpmubXmSG5Pc390fMqf/X3fjdF+SPx5f5UsnyaVJtibZNKdtt8cgyR90Y/lAkn9IstglyXu9HYzH+Ul+3L1PNiY5fc5zEz0eAEmOTHJTks1J7k3y7q59st8nVTWRNwYfHH8PeB5wAHAXcMy46xrh638QOHRe298Ba7vltcBHuuVjuvE5EDiqG7dl434NSzAGpwDHA5ueyhgAtwMvZfAdlH8BXjfu17aE43E+8P5F+k78eHSvZQVwfLd8MPDd7rVP9Ptkko/4nRpioTOA9d3yeuDMOe2fq6pfVtUPgAcYjN8+rapuAR6d17xbY5BkBfCsqrq1Bv+6L5+zzj5lB+OxIxM/HgBVtaWq7uyWHwc2M5hdYKLfJ5Mc/ItNDXHEmGoZhwK+muSObvoLgMOragsM3vDAYV17S2O1u2NwRLc8v32SnJvk7u5U0PZTGs2NR5KVwHHAbUz4+2SSg3+oqSEm2MlVdTyDWVDfmeSUnfRtfaxgx2Mw6WNzEfB8YBWwBfho197UeCQ5CPgicF5VPbazrou07XPjMsnB3/TUEFX1cHe/FbiGwambR7o/Senut3bdWxqr3R2Dh7rl+e0ToaoeqaptVfVr4FP85hRfM+ORZH8GoX9FVV3dNU/0+2SSg7/ZqSGSPDPJwduXgdcCmxi8/tVdt9XAtd3ydcCbkxyY5CjgaAYfVE2i3RqD7s/8x5Oc2F2l8dY56+zztodb5ywG7xNoZDy613AJsLmqPjbnqcl+n4z70+U+b8DpDD6l/x7woXHXM8LX/TwGVx7cBdy7/bUDvw1sAO7v7pfPWedD3Tjdx158NcJujsOVDE5f/C+DI7Jz9mQMgGkGgfg94JN033jf1247GI/PAPcAdzMItRWtjEf3Wl7G4JTM3cDG7nb6pL9PnLJBkhozyad6JEmLMPglqTEGvyQ1xuCXpMYY/JLUGINfEy3Jtm7WyU1JPp/kt57Cti5L8oZu+dNJjtlJ31OTnDTn8TuSvHVP9y0tJYNfk+4XVbWqqo4FfgW8Y+6TSZbtyUar6s+r6ts76XIq8P/BX1UXV9Xle7IvaakZ/GrJN4AXdEfjNyX5LHBPkmVJ/j7Jt7rJyt4Og291Jvlkkm8nuZ7fTNRFkq8nme6WT0tyZ5K7kmzoJvt6B/Ce7q+Nl3fz3r+/678qyb93+7pm+8Ro3TY/kuT2JN9N8vLRDo9aMfIfW5fGIcl+DCas+0rXdAJwbFX9oJu99GdV9ZIkBwL/luSrDGZqfCHwe8DhwLeBS+dtd4rBHDendNtaXlWPJrkY+HlVXdj1e9Wc1S4H3lVVNyf5W+DDwHndc/tV1QkZ/CDKh4FXL/FQSAa/Jt4zkmzslr/BYF6WkxjMr/KDrv21wO9vP38PPJvBHCynAFdW1Tbg4SRfW2T7JwK3bN9WVe10vvskzwaeU1U3d03rgc/P6bJ9krA7gJVDvUJpNxn8mnS/qKpVcxu6X8T777lNDI7Ab5jX73R2PbVuhuizO37Z3W/Df5/qief4JbgB+Mtuel6S/G43q+ktDGZiXNbNYvmKRda9FfijbqZGkizv2h9n8FN+T1JVPwP+c875+7cAN8/vJ/XJIwoJPs3gtMqd3ZS6swx+Nu8a4JUMZq/8LosEdFXNdp8RXJ3kaQzmbX8N8CXgC0nOAN41b7XVwMXdpaXfB/6sh9ck7ZCzc0pSYzzVI0mNMfglqTEGvyQ1xuCXpMYY/JLUGINfkhpj8EtSY/4P9fLch38zU50AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(1)\n",
    "plt.clf()\n",
    "ax=plt.axes(aspect='equal')\n",
    "plt.scatter(y_valid,predict)\n",
    "plt.xlabel('True Values')\n",
    "plt.ylabel('Predictions')\n",
    "Lims=[0,300]\n",
    "plt.xlim(Lims)\n",
    "plt.ylim(Lims)\n",
    "plt.plot(Lims,Lims)\n",
    "plt.grid(False)\n",
    "    \n",
    "plt.figure(2)\n",
    "plt.clf()\n",
    "plt.hist(predict,bins=30)\n",
    "plt.xlabel('Prediction')\n",
    "plt.ylabel('Count')\n",
    "plt.grid(False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33806898",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
